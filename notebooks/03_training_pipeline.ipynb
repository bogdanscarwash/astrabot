{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install -U accelerate\n",
    "%pip install -U transformers\n",
    "%pip install -U datasets\n",
    "%pip install -U bitsandbytes\n",
    "%pip install -U peft\n",
    "%pip install -U trl\n",
    "%pip install -U unsloth\n",
    "%pip install -U pandas\n",
    "%pip install -U scikit-learn\n",
    "%pip install -U scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.6.1: Fast Qwen3 patching. Transformers: 4.52.4.\n",
      "   \\\\   /|    NVIDIA A100-SXM4-80GB. Num GPUs = 1. Max memory: 79.254 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 8.0. CUDA Toolkit: 12.6. Triton: 3.3.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cc41aa5313f4689bd4ad6ae818ddca9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "fourbit_models = [\n",
    "    \"unsloth/Qwen3-1.7B-unsloth-bnb-4bit\", # Qwen 14B 2x faster\n",
    "    \"unsloth/Qwen3-4B-unsloth-bnb-4bit\",\n",
    "    \"unsloth/Qwen3-8B-unsloth-bnb-4bit\",\n",
    "    \"unsloth/Qwen3-14B-unsloth-bnb-4bit\",\n",
    "    \"unsloth/Qwen3-32B-unsloth-bnb-4bit\",\n",
    "\n",
    "    # 4bit dynamic quants for superior accuracy and low memory use\n",
    "    \"unsloth/gemma-3-12b-it-unsloth-bnb-4bit\",\n",
    "    \"unsloth/Phi-4\",\n",
    "    \"unsloth/Llama-3.1-8B\",\n",
    "    \"unsloth/Llama-3.2-3B\",\n",
    "    \"unsloth/orpheus-3b-0.1-ft-unsloth-bnb-4bit\" # [NEW] We support TTS models!\n",
    "] # More models at https://huggingface.co/unsloth\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Qwen3-14B-unsloth-bnb-4bit\",  # Use 14B for better fit on A100\n",
    "    max_seq_length = 4096,   # Increased context length - A100 can handle this\n",
    "    load_in_4bit = True,     # Keep 4bit for memory efficiency\n",
    "    load_in_8bit = False,    # Stay with 4bit for optimal memory usage\n",
    "    full_finetuning = False, # LoRA is more efficient for fine-tuning\n",
    "    dtype = None,            # Auto-detect optimal dtype\n",
    "    # token = \"hf_...\",      # use one if using gated models\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.6.1 patched 40 layers with 40 QKV layers, 40 O layers and 40 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 8,           # Choose any number > 0! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 16,  # Best to choose alpha = rank or rank*2\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    use_rslora = True,   # We support rank stabilized LoRA\n",
    "    loftq_config = None,  # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversational Training Data Creation\n",
    "\n",
    "This notebook now uses an enhanced conversational approach instead of Q&A extraction.\n",
    "The new system captures natural dialogue flow through:\n",
    "- Conversation windows with context\n",
    "- Natural dialogue episodes  \n",
    "- Burst texting and style preservation\n",
    "- Conversation role modeling\n",
    "- Multi-modal content integration\n",
    "\n",
    "Transform your chats into conversation format suitable for instruction tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "pwd = \"/home/percy/git/astrabot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEPRECATED\n",
    "#\n",
    "#import pandas as pd\n",
    "#import json\n",
    "#from datetime import datetime\n",
    "#import os\n",
    "#\n",
    "#def transform_to_conversations():\n",
    "#    # Load the data - FIX: Load the correct files\n",
    "#    messages = pd.read_csv(f\"{pwd}/test/signal-flatfiles/signal.csv\")  # Changed this line\n",
    "#    recipients = pd.read_csv(f\"{pwd}/test/signal-flatfiles/recipient.csv\")\n",
    "#    threads = pd.read_csv(f\"{pwd}/test/signal-flatfiles/thread.csv\")\n",
    "#    \n",
    "#    # Create recipient lookup\n",
    "#    recipient_lookup = recipients.set_index('_id')['profile_given_name'].to_dict()\n",
    "#    \n",
    "#    conversations = []\n",
    "#    \n",
    "#    # Group messages by thread\n",
    "#    for thread_id in messages['thread_id'].unique():\n",
    "#        thread_messages = messages[messages['thread_id'] == thread_id].sort_values('date_sent')\n",
    "#        \n",
    "#        if len(thread_messages) < 2:  # Skip single message threads\n",
    "#            continue\n",
    "#            \n",
    "#        conversation = []\n",
    "#        for _, msg in thread_messages.iterrows():\n",
    "#            if pd.notna(msg['body']) and msg['body'].strip():\n",
    "#                sender_name = recipient_lookup.get(msg['from_recipient_id'], 'Unknown')\n",
    "#                conversation.append({\n",
    "#                    \"role\": \"user\" if sender_name != \"You\" else \"assistant\",\n",
    "#                    \"content\": msg['body'],\n",
    "#                    \"timestamp\": msg['date_sent']\n",
    "#                })\n",
    "#        \n",
    "#        if len(conversation) >= 2:\n",
    "#            conversations.append({\n",
    "#                \"conversation_id\": thread_id,\n",
    "#                \"messages\": conversation\n",
    "#            })\n",
    "#    \n",
    "#    return conversations  # Don't forget to return the result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conversations = transform_to_conversations()\n",
    "#conversations[0:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhanced Conversational Training System\n",
    "\n",
    "This new approach replaces Q&A extraction with natural conversation flow capture. Instead of looking for questions and answers, we now:\n",
    "\n",
    "1. **Conversation Windows**: Capture multi-turn exchanges with sliding context windows\n",
    "2. **Natural Episodes**: Segment conversations by time gaps to preserve complete dialogue arcs  \n",
    "3. **Style Preservation**: Maintain your burst texting, long-form responses, and mixed patterns\n",
    "4. **Role Modeling**: Track how you initiate, respond, and close conversations\n",
    "5. **Multi-Modal Enhancement**: Integrate Twitter content while preserving conversation flow\n",
    "\n",
    "The system creates training examples that teach the model to have natural conversations like you do, not just answer questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Conversational Training Data System\n",
    "# This replaces the Q&A extraction approach with natural dialogue capture\n",
    "\n",
    "def create_conversation_windows(messages_df, window_size=5, your_recipient_id=2):\n",
    "    \"\"\"\n",
    "    Create conversation windows that capture natural dialogue flow.\n",
    "    \n",
    "    Args:\n",
    "        messages_df: DataFrame of messages\n",
    "        window_size: Number of messages to include for context (default 5)\n",
    "        your_recipient_id: Your recipient ID to identify your messages\n",
    "    \n",
    "    Returns:\n",
    "        List of conversation windows with rich metadata\n",
    "    \"\"\"\n",
    "    conversation_windows = []\n",
    "    \n",
    "    # Group by thread for coherent conversations\n",
    "    for thread_id in messages_df['thread_id'].unique():\n",
    "        thread_messages = messages_df[\n",
    "            messages_df['thread_id'] == thread_id\n",
    "        ].sort_values('date_sent')\n",
    "        \n",
    "        if len(thread_messages) < 3:  # Need at least 3 messages for context\n",
    "            continue\n",
    "        \n",
    "        # Create sliding windows through the conversation\n",
    "        for i in range(len(thread_messages) - 1):\n",
    "            # Check if you're the next speaker\n",
    "            if thread_messages.iloc[i + 1]['from_recipient_id'] != your_recipient_id:\n",
    "                continue\n",
    "            \n",
    "            # Get context window\n",
    "            start_idx = max(0, i - window_size + 1)\n",
    "            context_messages = thread_messages.iloc[start_idx:i + 1]\n",
    "            your_response = thread_messages.iloc[i + 1]\n",
    "            \n",
    "            # Calculate conversation dynamics\n",
    "            time_gaps = []\n",
    "            for j in range(1, len(context_messages)):\n",
    "                time_gap = (context_messages.iloc[j]['date_sent'] - \n",
    "                           context_messages.iloc[j-1]['date_sent']) / 1000  # Convert to seconds\n",
    "                time_gaps.append(time_gap)\n",
    "            \n",
    "            # Detect conversation momentum\n",
    "            avg_gap = sum(time_gaps) / len(time_gaps) if time_gaps else 0\n",
    "            momentum = 'rapid' if avg_gap < 60 else 'moderate' if avg_gap < 300 else 'slow'\n",
    "            \n",
    "            # Build conversation window\n",
    "            context = []\n",
    "            for _, msg in context_messages.iterrows():\n",
    "                context.append({\n",
    "                    'speaker': 'You' if msg['from_recipient_id'] == your_recipient_id else 'Other',\n",
    "                    'text': msg['body'],\n",
    "                    'timestamp': msg['date_sent'],\n",
    "                    'has_media': bool(re.search(r'https?://\\S+', msg['body']))\n",
    "                })\n",
    "            \n",
    "            window = {\n",
    "                'thread_id': thread_id,\n",
    "                'context': context,\n",
    "                'response': {\n",
    "                    'text': your_response['body'],\n",
    "                    'timestamp': your_response['date_sent']\n",
    "                },\n",
    "                'metadata': {\n",
    "                    'momentum': momentum,\n",
    "                    'context_size': len(context),\n",
    "                    'avg_time_gap': avg_gap,\n",
    "                    'response_delay': (your_response['date_sent'] - \n",
    "                                     context_messages.iloc[-1]['date_sent']) / 1000\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            conversation_windows.append(window)\n",
    "    \n",
    "    return conversation_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_natural_dialogues(messages_df, time_gap_minutes=30, your_recipient_id=2):\n",
    "    \"\"\"\n",
    "    Segment conversations into natural dialogue episodes based on time gaps and context.\n",
    "    \n",
    "    Args:\n",
    "        messages_df: DataFrame of messages\n",
    "        time_gap_minutes: Minutes of inactivity to consider new conversation episode\n",
    "        your_recipient_id: Your recipient ID\n",
    "    \n",
    "    Returns:\n",
    "        List of conversation episodes with complete dialogue arcs\n",
    "    \"\"\"\n",
    "    dialogue_episodes = []\n",
    "    \n",
    "    for thread_id in messages_df['thread_id'].unique():\n",
    "        thread_messages = messages_df[\n",
    "            messages_df['thread_id'] == thread_id\n",
    "        ].sort_values('date_sent')\n",
    "        \n",
    "        if len(thread_messages) < 2:\n",
    "            continue\n",
    "        \n",
    "        # Identify conversation episodes\n",
    "        episodes = []\n",
    "        current_episode = [thread_messages.iloc[0]]\n",
    "        \n",
    "        for i in range(1, len(thread_messages)):\n",
    "            current_msg = thread_messages.iloc[i]\n",
    "            prev_msg = thread_messages.iloc[i-1]\n",
    "            \n",
    "            # Check time gap\n",
    "            time_gap = (current_msg['date_sent'] - prev_msg['date_sent']) / (1000 * 60)  # to minutes\n",
    "            \n",
    "            if time_gap > time_gap_minutes:\n",
    "                # New episode detected\n",
    "                if len(current_episode) >= 2:  # Only save meaningful episodes\n",
    "                    episodes.append(current_episode)\n",
    "                current_episode = [current_msg]\n",
    "            else:\n",
    "                current_episode.append(current_msg)\n",
    "        \n",
    "        # Don't forget the last episode\n",
    "        if len(current_episode) >= 2:\n",
    "            episodes.append(current_episode)\n",
    "        \n",
    "        # Process each episode\n",
    "        for episode in episodes:\n",
    "            # Analyze episode characteristics\n",
    "            participants = set([msg['from_recipient_id'] for msg in episode])\n",
    "            your_messages = [msg for msg in episode if msg['from_recipient_id'] == your_recipient_id]\n",
    "            \n",
    "            if not your_messages:  # Skip episodes where you didn't participate\n",
    "                continue\n",
    "            \n",
    "            # Detect conversation patterns\n",
    "            turn_pattern = []\n",
    "            current_speaker = episode[0]['from_recipient_id']\n",
    "            turn_count = 1\n",
    "            \n",
    "            for msg in episode[1:]:\n",
    "                if msg['from_recipient_id'] != current_speaker:\n",
    "                    turn_pattern.append(('You' if current_speaker == your_recipient_id else 'Other', turn_count))\n",
    "                    current_speaker = msg['from_recipient_id']\n",
    "                    turn_count = 1\n",
    "                else:\n",
    "                    turn_count += 1\n",
    "            turn_pattern.append(('You' if current_speaker == your_recipient_id else 'Other', turn_count))\n",
    "            \n",
    "            # Create episode data\n",
    "            episode_data = {\n",
    "                'thread_id': thread_id,\n",
    "                'messages': [{\n",
    "                    'speaker': 'You' if msg['from_recipient_id'] == your_recipient_id else 'Other',\n",
    "                    'text': msg['body'],\n",
    "                    'timestamp': msg['date_sent']\n",
    "                } for msg in episode],\n",
    "                'metadata': {\n",
    "                    'episode_length': len(episode),\n",
    "                    'duration_minutes': (episode[-1]['date_sent'] - episode[0]['date_sent']) / (1000 * 60),\n",
    "                    'your_message_count': len(your_messages),\n",
    "                    'turn_pattern': turn_pattern,\n",
    "                    'initiated_by': 'You' if episode[0]['from_recipient_id'] == your_recipient_id else 'Other',\n",
    "                    'ended_by': 'You' if episode[-1]['from_recipient_id'] == your_recipient_id else 'Other'\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            dialogue_episodes.append(episode_data)\n",
    "    \n",
    "    return dialogue_episodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q&A Extraction (Deprecated - See Conversational System Above)\n",
    "\n",
    "The Q&A extraction approach has been replaced with the Enhanced Conversational Training System above. \n",
    "The new system better captures natural dialogue flow rather than forcing conversations into Q&A format.\n",
    "\n",
    "The enhanced functions below were an intermediate step but are kept for reference. \n",
    "**Use the conversational training system instead for better results.**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "def preserve_conversation_dynamics(messages_df, your_recipient_id=2):\n    \"\"\"\n    Capture and preserve different conversation modes and dynamics.\n    \n    Args:\n        messages_df: DataFrame of messages\n        your_recipient_id: Your recipient ID\n    \n    Returns:\n        Conversation data with preserved dynamics and style patterns\n    \"\"\"\n    from src.extractors.twitter_extractor import process_message_with_twitter_content\n    \n    conversation_dynamics = []\n    \n    # Group by thread\n    for thread_id in messages_df['thread_id'].unique():\n        thread_messages = messages_df[\n            messages_df['thread_id'] == thread_id\n        ].sort_values('date_sent')\n        \n        # Identify your message sequences\n        i = 0\n        while i < len(thread_messages):\n            # Find sequences where you're speaking\n            if thread_messages.iloc[i]['from_recipient_id'] == your_recipient_id:\n                # Collect your burst sequence\n                your_sequence = [thread_messages.iloc[i]]\n                j = i + 1\n                \n                # Keep collecting while you're still talking and messages are close in time\n                while j < len(thread_messages):\n                    if thread_messages.iloc[j]['from_recipient_id'] == your_recipient_id:\n                        time_gap = (thread_messages.iloc[j]['date_sent'] - \n                                   thread_messages.iloc[j-1]['date_sent']) / 1000\n                        if time_gap < 120:  # Within 2 minutes\n                            your_sequence.append(thread_messages.iloc[j])\n                            j += 1\n                        else:\n                            break\n                    else:\n                        break\n                \n                # Get context before your sequence\n                context_start = max(0, i - 5)\n                context_messages = list(thread_messages.iloc[context_start:i])\n                \n                # Classify your conversation style for this sequence\n                if len(your_sequence) >= 3:\n                    style = 'burst_sequence'\n                elif len(your_sequence) == 1 and len(your_sequence[0]['body']) > 200:\n                    style = 'long_form'\n                elif len(your_sequence) == 2:\n                    style = 'double_tap'\n                else:\n                    style = 'single_message'\n                \n                # Check for media sharing\n                has_media = any(bool(re.search(r'https?://\\S+', msg['body'])) for msg in your_sequence)\n                \n                # Enhance messages with Twitter content if present\n                enhanced_sequence = []\n                for msg in your_sequence:\n                    enhanced_text = process_message_with_twitter_content(\n                        msg['body'], \n                        use_images=True,  # Enable image processing for richer training data\n                        image_api='openai'  # Use GPT-4o-mini for cost-effective vision processing\n                    )\n                    enhanced_msg = msg.copy()\n                    enhanced_msg['body'] = enhanced_text\n                    enhanced_msg['original_body'] = msg['body']\n                    enhanced_sequence.append(enhanced_msg)\n                \n                # Build the dynamics data\n                dynamics_data = {\n                    'thread_id': thread_id,\n                    'context': [{\n                        'speaker': 'You' if msg['from_recipient_id'] == your_recipient_id else 'Other',\n                        'text': msg['body'],\n                        'timestamp': msg['date_sent']\n                    } for msg in context_messages],\n                    'your_sequence': [{\n                        'text': msg['body'],\n                        'original_text': msg['original_body'],\n                        'timestamp': msg['date_sent'],\n                        'enhanced': msg['body'] != msg['original_body']\n                    } for msg in enhanced_sequence],\n                    'style': style,\n                    'metadata': {\n                        'sequence_length': len(your_sequence),\n                        'total_chars': sum(len(msg['body']) for msg in your_sequence),\n                        'has_media': has_media,\n                        'avg_message_length': sum(len(msg['body']) for msg in your_sequence) / len(your_sequence),\n                        'time_span_seconds': (your_sequence[-1]['date_sent'] - your_sequence[0]['date_sent']) / 1000 if len(your_sequence) > 1 else 0\n                    }\n                }\n                \n                conversation_dynamics.append(dynamics_data)\n                i = j\n            else:\n                i += 1\n    \n    return conversation_dynamics"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhanced Q&A Extraction with Twitter Content\n",
    "\n",
    "The original `extract_qa_pairs` function was overly simplistic. The enhanced version includes:\n",
    "\n",
    "1. **Better Question Detection**:\n",
    "   - Multiple regex patterns for various question types\n",
    "   - Filters out URL-only \"questions\"\n",
    "   - Detects implicit questions and requests\n",
    "\n",
    "2. **Quality Filtering**:\n",
    "   - Removes very short responses\n",
    "   - Filters out generic responses (ok, yeah, lol)\n",
    "   - Excludes Q&A pairs where the answer is just another question\n",
    "\n",
    "3. **Twitter Content Integration**:\n",
    "   - Automatically extracts tweet text when URLs are present\n",
    "   - Injects tweet content with clear markers\n",
    "   - Preserves original content while adding context\n",
    "\n",
    "4. **Role Awareness**:\n",
    "   - Ensures Q&A pairs are between different people\n",
    "   - Tracks conversation flow properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_conversation_roles(dialogue_episodes, your_recipient_id=2):\n",
    "    \"\"\"\n",
    "    Analyze and model conversation roles and dynamics.\n",
    "    \n",
    "    Args:\n",
    "        dialogue_episodes: List of conversation episodes from segment_natural_dialogues\n",
    "        your_recipient_id: Your recipient ID\n",
    "    \n",
    "    Returns:\n",
    "        Conversation data with role patterns and dynamics\n",
    "    \"\"\"\n",
    "    role_patterns = []\n",
    "    \n",
    "    for episode in dialogue_episodes:\n",
    "        # Analyze conversation initiation patterns\n",
    "        initiated_by_you = episode['metadata']['initiated_by'] == 'You'\n",
    "        ended_by_you = episode['metadata']['ended_by'] == 'You'\n",
    "        \n",
    "        # Analyze turn-taking patterns\n",
    "        turn_pattern = episode['metadata']['turn_pattern']\n",
    "        your_turns = [turn for turn in turn_pattern if turn[0] == 'You']\n",
    "        other_turns = [turn for turn in turn_pattern if turn[0] == 'Other']\n",
    "        \n",
    "        # Calculate conversation balance\n",
    "        your_message_ratio = episode['metadata']['your_message_count'] / episode['metadata']['episode_length']\n",
    "        \n",
    "        # Detect conversation role\n",
    "        if initiated_by_you and your_message_ratio > 0.6:\n",
    "            role = 'conversation_driver'\n",
    "        elif not initiated_by_you and your_message_ratio < 0.4:\n",
    "            role = 'responsive_participant'\n",
    "        elif len(your_turns) > len(other_turns):\n",
    "            role = 'active_engager'\n",
    "        else:\n",
    "            role = 'balanced_conversationalist'\n",
    "        \n",
    "        # Extract conversation segments for training\n",
    "        messages = episode['messages']\n",
    "        \n",
    "        # Find your responses with full context\n",
    "        for i, msg in enumerate(messages):\n",
    "            if msg['speaker'] == 'You' and i > 0:\n",
    "                # Get conversation context\n",
    "                context_start = max(0, i - 5)\n",
    "                context = messages[context_start:i]\n",
    "                \n",
    "                # Determine response type\n",
    "                if i == 1 and initiated_by_you:\n",
    "                    response_type = 'continuation_after_initiation'\n",
    "                elif i == len(messages) - 1:\n",
    "                    response_type = 'conversation_closer'\n",
    "                elif len([m for m in messages[i:i+3] if m['speaker'] == 'You']) >= 2:\n",
    "                    response_type = 'burst_starter'\n",
    "                else:\n",
    "                    response_type = 'turn_taking_response'\n",
    "                \n",
    "                role_data = {\n",
    "                    'episode_id': f\"{episode['thread_id']}_{messages[0]['timestamp']}\",\n",
    "                    'context': context,\n",
    "                    'response': msg,\n",
    "                    'role': role,\n",
    "                    'response_type': response_type,\n",
    "                    'metadata': {\n",
    "                        'position_in_episode': i / len(messages),\n",
    "                        'initiated_by_you': initiated_by_you,\n",
    "                        'ended_by_you': ended_by_you,\n",
    "                        'episode_duration': episode['metadata']['duration_minutes'],\n",
    "                        'your_dominance': your_message_ratio\n",
    "                    }\n",
    "                }\n",
    "                \n",
    "                role_patterns.append(role_data)\n",
    "    \n",
    "    return role_patterns"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Example: Using image description with GPT-4o-mini (requires API key)\nfrom src.extractors.twitter_extractor import describe_tweet_images, extract_tweet_images\nimport os\n\n# Check if API keys are available\nhas_openai = 'OPENAI_API_KEY' in os.environ\nhas_anthropic = 'ANTHROPIC_API_KEY' in os.environ\n\nprint(f\"OpenAI API key available: {has_openai}\")\nprint(f\"Anthropic API key available: {has_anthropic}\")\n\n# Example: Extract and describe images from a tweet\nif has_openai or has_anthropic:\n    # Use the example URL from cell 16 or any Twitter URL with images\n    example_url = \"https://twitter.com/greenTetra_/status/1778114292983710193\"\n    \n    # Extract images from the tweet\n    print(f\"\\nExtracting images from: {example_url}\")\n    image_urls = extract_tweet_images(example_url)\n    \n    if image_urls:\n        print(f\"Found {len(image_urls)} images\")\n        \n        # Describe the images using GPT-4o-mini (default) or Claude\n        api_to_use = 'openai' if has_openai else 'anthropic'\n        print(f\"\\nUsing {api_to_use} API to describe images...\")\n        \n        descriptions = describe_tweet_images(image_urls[:2], api_to_use)  # Limit to first 2 images\n        \n        for i, (url, desc) in enumerate(zip(image_urls[:2], descriptions)):\n            print(f\"\\nImage {i+1}:\")\n            print(f\"  URL: {url}\")\n            print(f\"  Description: {desc}\")\n    else:\n        print(\"No images found in the tweet\")\nelse:\n    print(\"\\nTo use image description with GPT-4o-mini, set the environment variable:\")\n    print(\"  export OPENAI_API_KEY='your-api-key'\")\n    print(\"\\nOr for Claude vision:\")\n    print(\"  export ANTHROPIC_API_KEY='your-api-key'\")"
  },
  {
   "cell_type": "markdown",
   "source": "# Image Processing Optimization with GPT-4o-mini\n\nThe conversation utilities now support optimized image processing:\n\n1. **Model**: Uses GPT-4o-mini for cost-effective vision processing\n2. **Detail Level**: Set to \"low\" for faster and cheaper processing\n3. **Batch Processing**: Multiple images can be processed in a single API call\n4. **Cost Savings**: Batch processing reduces API calls and costs significantly\n\nExample cost comparison (approximate):\n- Individual processing: 4 images = 4 API calls\n- Batch processing: 4 images = 1 API call (up to 75% cost reduction)\n\nThe `preserve_conversation_dynamics()` function now has image processing enabled by default,\nwhich means tweet images will be described and included in your training data.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_conversational_training_data(messages_df, recipients_df, your_recipient_id=2):\n",
    "    \"\"\"\n",
    "    Unified pipeline to create natural conversational training data.\n",
    "    \n",
    "    This combines all conversation capture methods to create rich training examples\n",
    "    that preserve your natural communication style.\n",
    "    \n",
    "    Args:\n",
    "        messages_df: DataFrame of messages\n",
    "        recipients_df: DataFrame of recipients\n",
    "        your_recipient_id: Your recipient ID\n",
    "    \n",
    "    Returns:\n",
    "        List of training examples in multiple formats\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    \n",
    "    print(\"Creating natural conversational training data...\")\n",
    "    \n",
    "    # Filter for meaningful text messages\n",
    "    text_messages = messages_df[\n",
    "        (messages_df['body'].notna()) & \n",
    "        (messages_df['body'].str.len() > 5)\n",
    "    ].copy()\n",
    "    \n",
    "    # Create recipient lookup for names\n",
    "    recipient_lookup = recipients_df.set_index('_id')['profile_given_name'].fillna('Unknown').to_dict()\n",
    "    \n",
    "    training_examples = []\n",
    "    \n",
    "    # 1. Conversation Windows (for context-aware responses)\n",
    "    print(\"Extracting conversation windows...\")\n",
    "    conv_windows = create_conversation_windows(text_messages, window_size=5, your_recipient_id=your_recipient_id)\n",
    "    \n",
    "    for window in conv_windows:\n",
    "        # Format context as natural conversation\n",
    "        context_text = \"\\n\".join([\n",
    "            f\"{msg['speaker']}: {msg['text']}\" \n",
    "            for msg in window['context']\n",
    "        ])\n",
    "        \n",
    "        training_examples.append({\n",
    "            'instruction': f\"Continue this {window['metadata']['momentum']} conversation naturally\",\n",
    "            'input': context_text,\n",
    "            'output': window['response']['text'],\n",
    "            'metadata': {\n",
    "                'type': 'conversation_window',\n",
    "                'momentum': window['metadata']['momentum'],\n",
    "                'response_delay': window['metadata']['response_delay'],\n",
    "                'context_size': window['metadata']['context_size']\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    # 2. Natural Dialogue Episodes (for complete conversation arcs)\n",
    "    print(\"Segmenting natural dialogue episodes...\")\n",
    "    episodes = segment_natural_dialogues(text_messages, time_gap_minutes=30, your_recipient_id=your_recipient_id)\n",
    "    \n",
    "    # Model conversation roles\n",
    "    print(\"Modeling conversation roles...\")\n",
    "    role_patterns = model_conversation_roles(episodes, your_recipient_id=your_recipient_id)\n",
    "    \n",
    "    for pattern in role_patterns:\n",
    "        # Format based on role and response type\n",
    "        context_text = \"\\n\".join([\n",
    "            f\"{msg['speaker']}: {msg['text']}\" \n",
    "            for msg in pattern['context']\n",
    "        ])\n",
    "        \n",
    "        instruction_map = {\n",
    "            'conversation_driver': \"Lead the conversation forward\",\n",
    "            'responsive_participant': \"Respond thoughtfully to the conversation\",\n",
    "            'active_engager': \"Engage actively in this discussion\",\n",
    "            'balanced_conversationalist': \"Continue the balanced dialogue\"\n",
    "        }\n",
    "        \n",
    "        training_examples.append({\n",
    "            'instruction': instruction_map.get(pattern['role'], \"Continue naturally\"),\n",
    "            'input': context_text,\n",
    "            'output': pattern['response']['text'],\n",
    "            'metadata': {\n",
    "                'type': 'role_based_response',\n",
    "                'role': pattern['role'],\n",
    "                'response_type': pattern['response_type'],\n",
    "                'position': pattern['metadata']['position_in_episode']\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    # 3. Conversation Dynamics (for style preservation)\n",
    "    print(\"Preserving conversation dynamics...\")\n",
    "    dynamics = preserve_conversation_dynamics(text_messages, your_recipient_id=your_recipient_id)\n",
    "    \n",
    "    for dynamic in dynamics:\n",
    "        # Handle different conversation styles\n",
    "        if dynamic['style'] == 'burst_sequence':\n",
    "            # For burst sequences, preserve the multi-message nature\n",
    "            context_text = \"\\n\".join([\n",
    "                f\"{msg['speaker']}: {msg['text']}\" \n",
    "                for msg in dynamic['context']\n",
    "            ])\n",
    "            \n",
    "            # Join messages with special token to preserve burst nature\n",
    "            output_text = \" [NEXT] \".join([msg['text'] for msg in dynamic['your_sequence']])\n",
    "            \n",
    "            training_examples.append({\n",
    "                'instruction': \"Respond in your natural burst texting style\",\n",
    "                'input': context_text,\n",
    "                'output': output_text,\n",
    "                'metadata': {\n",
    "                    'type': 'burst_sequence',\n",
    "                    'sequence_length': dynamic['metadata']['sequence_length'],\n",
    "                    'has_media': dynamic['metadata']['has_media']\n",
    "                }\n",
    "            })\n",
    "        else:\n",
    "            # For single messages or long-form\n",
    "            if dynamic['context']:\n",
    "                context_text = \"\\n\".join([\n",
    "                    f\"{msg['speaker']}: {msg['text']}\" \n",
    "                    for msg in dynamic['context']\n",
    "                ])\n",
    "                \n",
    "                training_examples.append({\n",
    "                    'instruction': f\"Respond with a {dynamic['style'].replace('_', ' ')} message\",\n",
    "                    'input': context_text,\n",
    "                    'output': dynamic['your_sequence'][0]['text'],\n",
    "                    'metadata': {\n",
    "                        'type': dynamic['style'],\n",
    "                        'enhanced': dynamic['your_sequence'][0]['enhanced'],\n",
    "                        'char_count': dynamic['metadata']['total_chars']\n",
    "                    }\n",
    "                })\n",
    "    \n",
    "    # 4. Add conversation starters (where you initiate)\n",
    "    print(\"Adding conversation initiations...\")\n",
    "    for episode in episodes:\n",
    "        if episode['metadata']['initiated_by'] == 'You' and episode['messages']:\n",
    "            # You started this conversation\n",
    "            first_msg = episode['messages'][0]\n",
    "            \n",
    "            # Try to find what prompted this (look at previous episode in same thread)\n",
    "            thread_episodes = [ep for ep in episodes if ep['thread_id'] == episode['thread_id']]\n",
    "            thread_episodes.sort(key=lambda x: x['messages'][0]['timestamp'])\n",
    "            \n",
    "            current_idx = thread_episodes.index(episode)\n",
    "            if current_idx > 0:\n",
    "                prev_episode = thread_episodes[current_idx - 1]\n",
    "                context = f\"[Previous conversation ended {episode['metadata']['duration_minutes']:.0f} minutes ago with: {prev_episode['messages'][-1]['text']}]\"\n",
    "            else:\n",
    "                context = \"[Start a new conversation]\"\n",
    "            \n",
    "            training_examples.append({\n",
    "                'instruction': \"Initiate a conversation naturally\",\n",
    "                'input': context,\n",
    "                'output': first_msg['text'],\n",
    "                'metadata': {\n",
    "                    'type': 'conversation_starter',\n",
    "                    'leads_to_episode_length': episode['metadata']['episode_length']\n",
    "                }\n",
    "            })\n",
    "    \n",
    "    print(f\"\\nCreated {len(training_examples)} conversational training examples:\")\n",
    "    \n",
    "    # Show breakdown by type\n",
    "    type_counts = {}\n",
    "    for ex in training_examples:\n",
    "        ex_type = ex['metadata']['type']\n",
    "        type_counts[ex_type] = type_counts.get(ex_type, 0) + 1\n",
    "    \n",
    "    for ex_type, count in sorted(type_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"  {ex_type}: {count} examples ({count/len(training_examples)*100:.1f}%)\")\n",
    "    \n",
    "    return training_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Using the Twitter extraction functions directly\n",
    "from conversation_utilities import extract_tweet_text, extract_tweet_images, inject_tweet_context\n",
    "\n",
    "# Example Twitter URL from your conversations\n",
    "example_url = \"https://twitter.com/greenTetra_/status/1778114292983710193\"\n",
    "\n",
    "# Extract tweet text\n",
    "tweet_data = extract_tweet_text(example_url)\n",
    "if tweet_data:\n",
    "    print(\"Tweet extraction successful!\")\n",
    "    print(f\"Author: @{tweet_data['author']}\")\n",
    "    print(f\"Tweet ID: {tweet_data['tweet_id']}\")\n",
    "    print(f\"Text: {tweet_data['text']}\")\n",
    "else:\n",
    "    print(\"Failed to extract tweet text\")\n",
    "\n",
    "# Extract images from tweet\n",
    "print(\"\\nExtracting images...\")\n",
    "image_urls = extract_tweet_images(example_url)\n",
    "if image_urls:\n",
    "    print(f\"Found {len(image_urls)} images:\")\n",
    "    for i, url in enumerate(image_urls):\n",
    "        print(f\"  {i+1}. {url}\")\n",
    "else:\n",
    "    print(\"No images found in tweet\")\n",
    "\n",
    "# Example of injecting tweet content into a message\n",
    "original_message = \"Check this out: https://twitter.com/greenTetra_/status/1778114292983710193\"\n",
    "enhanced_message = inject_tweet_context(original_message, tweet_data)\n",
    "print(\"\\nEnhanced message:\")\n",
    "print(enhanced_message)"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Example: Using Structured Outputs with Conversation Tracking\nfrom conversation_utilities import (\n    extract_tweet_text, describe_tweet_images_with_context,\n    process_message_with_structured_content\n)\nfrom structured_schemas import TweetContent, ImageDescription, EnhancedMessage\nimport os\nfrom datetime import datetime\n\n# Example 1: Extract structured tweet data\nprint(\"=== STRUCTURED TWEET EXTRACTION ===\")\nexample_url = \"https://twitter.com/greenTetra_/status/1778114292983710193\"\n\n# Get structured tweet data (returns TweetContent object)\ntweet_structured = extract_tweet_text(example_url, return_structured=True)\nif tweet_structured and isinstance(tweet_structured, TweetContent):\n    print(f\"Author: @{tweet_structured.author}\")\n    print(f\"Text: {tweet_structured.text}\")\n    print(f\"Mentions: {tweet_structured.mentioned_users}\")\n    print(f\"Hashtags: {tweet_structured.hashtags}\")\n    print(f\"Sentiment: {tweet_structured.sentiment}\")\n    print(f\"Training format: {tweet_structured.to_training_format()}\")\n\n# Example 2: Process images with conversation context\nprint(\"\\n=== BATCH IMAGE PROCESSING WITH CONTEXT ===\")\n\n# Simulate multiple images from different conversations\nimages_to_process = [\n    {\n        'image_url': 'https://pbs.twimg.com/media/example1.jpg',\n        'conversation_id': 'thread_123',\n        'message_id': 'msg_001',\n        'sender_id': 'user_456',\n        'timestamp': datetime.now(),\n        'tweet_url': example_url\n    },\n    {\n        'image_url': 'https://pbs.twimg.com/media/example2.jpg',\n        'conversation_id': 'thread_124',\n        'message_id': 'msg_002', \n        'sender_id': 'user_789',\n        'timestamp': datetime.now(),\n        'tweet_url': 'https://twitter.com/example/status/123456'\n    }\n]\n\n# Process with context tracking\nif 'OPENAI_API_KEY' in os.environ:\n    print(\"Processing images with conversation tracking...\")\n    batch_results = describe_tweet_images_with_context(images_to_process)\n    \n    for result in batch_results:\n        print(f\"\\nConversation: {result.image_context.conversation_id}\")\n        print(f\"Sender: {result.image_context.sender_id}\")\n        print(f\"Description: {result.description.description}\")\n        print(f\"Subjects: {result.description.main_subjects}\")\n        print(f\"Emotional tone: {result.description.emotional_tone}\")\n        \n        # Get full context dictionary for training data\n        context_dict = result.to_dict_with_context()\n        print(f\"Full context keys: {list(context_dict.keys())}\")\n\n# Example 3: Process entire message with structured content\nprint(\"\\n=== ENHANCED MESSAGE PROCESSING ===\")\n\n# Process a complete message\nenhanced_msg = process_message_with_structured_content(\n    message=\"Check out this interesting thread: https://twitter.com/example/status/123456\",\n    conversation_id=\"thread_125\",\n    message_id=\"msg_003\",\n    sender_id=\"user_123\",\n    timestamp=datetime.now(),\n    use_images=True\n)\n\nprint(f\"Original: {enhanced_msg.original_message}\")\nprint(f\"Tweet contents: {len(enhanced_msg.tweet_contents)} tweets\")\nprint(f\"Image descriptions: {len(enhanced_msg.image_descriptions)} images\")\nprint(f\"Training format:\\n{enhanced_msg.to_training_format()}\")\n\n# Example 4: Collect images from multiple conversations for batch processing\nprint(\"\\n=== CONVERSATION-AWARE BATCH COLLECTION ===\")\n\n# This is how you'd collect images from your actual Signal data\ndef collect_images_for_batch_processing(messages_df, conversations):\n    \"\"\"Example of collecting images while preserving conversation context\"\"\"\n    images_to_process = []\n    \n    for conv_id, conv_messages in conversations.items():\n        for msg in conv_messages:\n            # Check if message contains Twitter URLs\n            twitter_urls = re.findall(r'https?://(?:www\\.)?twitter\\.com/\\S+', msg.get('body', ''))\n            \n            for url in twitter_urls:\n                # Extract images from the tweet\n                image_urls = extract_tweet_images(url)\n                \n                # Add each image with full conversation context\n                for img_url in image_urls:\n                    images_to_process.append({\n                        'image_url': img_url,\n                        'conversation_id': conv_id,\n                        'message_id': msg.get('_id'),\n                        'sender_id': msg.get('from_recipient_id'),\n                        'timestamp': datetime.fromtimestamp(msg.get('date_sent', 0) / 1000),\n                        'tweet_url': url\n                    })\n    \n    return images_to_process\n\nprint(\"Images are now collected with full conversation context!\")\nprint(\"This ensures training data maintains conversation boundaries and sender attribution.\")",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Integrate Structured Outputs into Training Pipeline\ndef create_structured_conversational_training_data(messages_df, recipients_df, your_recipient_id=2):\n    \"\"\"\n    Enhanced training data creation using structured outputs.\n    This replaces the previous version with structured data extraction.\n    \"\"\"\n    import numpy as np\n    from conversation_utilities import (\n        extract_tweet_images, process_message_with_structured_content\n    )\n    from structured_schemas import EnhancedMessage\n    \n    print(\"Creating structured conversational training data...\")\n    \n    # Filter for meaningful text messages\n    text_messages = messages_df[\n        (messages_df['body'].notna()) & \n        (messages_df['body'].str.len() > 5)\n    ].copy()\n    \n    training_examples = []\n    structured_messages = []\n    \n    # Process messages with structured content extraction\n    print(\"Extracting structured content from messages...\")\n    \n    for _, msg in text_messages.iterrows():\n        # Check if message contains Twitter URLs\n        if 'twitter.com' in msg['body'] or 'x.com' in msg['body'] or 't.co' in msg['body']:\n            try:\n                # Process with structured extraction\n                enhanced = process_message_with_structured_content(\n                    message=msg['body'],\n                    conversation_id=str(msg['thread_id']),\n                    message_id=str(msg['_id']),\n                    sender_id=str(msg['from_recipient_id']),\n                    timestamp=datetime.fromtimestamp(msg['date_sent'] / 1000),\n                    use_images=True\n                )\n                \n                # Store the enhanced message\n                structured_messages.append({\n                    'message_id': msg['_id'],\n                    'enhanced': enhanced,\n                    'has_tweets': len(enhanced.tweet_contents) > 0,\n                    'has_images': len(enhanced.image_descriptions) > 0\n                })\n                \n                # Replace the message body with enhanced version for training\n                text_messages.loc[text_messages['_id'] == msg['_id'], 'body'] = enhanced.to_training_format()\n                \n            except Exception as e:\n                print(f\"Error processing message {msg['_id']}: {e}\")\n    \n    print(f\"Enhanced {len(structured_messages)} messages with structured content\")\n    \n    # Now create training examples with the enhanced messages\n    # 1. Conversation Windows (using enhanced messages)\n    print(\"Creating conversation windows with structured content...\")\n    conv_windows = create_conversation_windows(text_messages, window_size=5, your_recipient_id=your_recipient_id)\n    \n    for window in conv_windows:\n        # Check if any messages in the window were enhanced\n        window_has_structured = any(\n            msg_id in [sm['message_id'] for sm in structured_messages]\n            for msg_id in [m.get('message_id') for m in window['context']]\n        )\n        \n        context_text = \"\\n\".join([\n            f\"{msg['speaker']}: {msg['text']}\" \n            for msg in window['context']\n        ])\n        \n        training_examples.append({\n            'instruction': f\"Continue this {window['metadata']['momentum']} conversation naturally\",\n            'input': context_text,\n            'output': window['response']['text'],\n            'metadata': {\n                'type': 'conversation_window',\n                'momentum': window['metadata']['momentum'],\n                'response_delay': window['metadata']['response_delay'],\n                'context_size': window['metadata']['context_size'],\n                'has_structured_content': window_has_structured,\n                'contains_media': window_has_structured  # Legacy compatibility\n            }\n        })\n    \n    # 2. Create specific examples for tweets and images\n    print(\"Creating tweet and image-specific training examples...\")\n    \n    for sm in structured_messages:\n        enhanced_msg = sm['enhanced']\n        \n        # Create examples for tweet sharing patterns\n        if enhanced_msg.tweet_contents:\n            for tweet in enhanced_msg.tweet_contents:\n                # Example: Learning to share relevant tweets\n                training_examples.append({\n                    'instruction': \"Share a tweet that relates to this topic\",\n                    'input': f\"Topic: {tweet.text[:50]}...\",\n                    'output': enhanced_msg.original_message,\n                    'metadata': {\n                        'type': 'tweet_sharing_pattern',\n                        'tweet_author': tweet.author,\n                        'tweet_sentiment': tweet.sentiment,\n                        'has_mentions': len(tweet.mentioned_users) > 0,\n                        'has_hashtags': len(tweet.hashtags) > 0\n                    }\n                })\n        \n        # Create examples for image descriptions\n        if enhanced_msg.image_descriptions:\n            for img_desc in enhanced_msg.image_descriptions:\n                # Example: Responding to images\n                training_examples.append({\n                    'instruction': f\"Respond to an image showing: {img_desc.description}\",\n                    'input': f\"Image content: {img_desc.to_training_format()}\",\n                    'output': \"I should learn appropriate responses to images\",  # This would be the next message in thread\n                    'metadata': {\n                        'type': 'image_response_pattern',\n                        'emotional_tone': img_desc.emotional_tone,\n                        'main_subjects': img_desc.main_subjects,\n                        'has_text': img_desc.detected_text is not None\n                    }\n                })\n    \n    print(f\"\\nCreated {len(training_examples)} training examples:\")\n    \n    # Show breakdown by type\n    type_counts = {}\n    structured_counts = {'with_structured': 0, 'without_structured': 0}\n    \n    for ex in training_examples:\n        ex_type = ex['metadata']['type']\n        type_counts[ex_type] = type_counts.get(ex_type, 0) + 1\n        \n        if ex['metadata'].get('has_structured_content', False):\n            structured_counts['with_structured'] += 1\n        else:\n            structured_counts['without_structured'] += 1\n    \n    for ex_type, count in sorted(type_counts.items(), key=lambda x: x[1], reverse=True):\n        print(f\"  {ex_type}: {count} examples ({count/len(training_examples)*100:.1f}%)\")\n    \n    print(f\"\\nStructured content breakdown:\")\n    print(f\"  With structured content: {structured_counts['with_structured']}\")\n    print(f\"  Without structured content: {structured_counts['without_structured']}\")\n    \n    return training_examples, structured_messages\n\n# Example usage - you would run this with your actual data\n# training_data, structured_msgs = create_structured_conversational_training_data(\n#     messages_df, recipients_df, your_recipient_id=2\n# )\n\nprint(\"Structured output integration complete!\")\nprint(\"\\nBenefits of this approach:\")\nprint(\"1. Consistent data extraction with guaranteed JSON schemas\")\nprint(\"2. Conversation context preserved throughout processing\")\nprint(\"3. Rich metadata for better training data quality\")\nprint(\"4. Batch processing for cost efficiency\")\nprint(\"5. Structured data ready for immediate use in training\")",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Structured Output with Conversation Tracking\n\nThe conversation utilities now support OpenAI's Structured Outputs feature for consistent, reliable data extraction. This system:\n\n1. **Guarantees Valid JSON**: Always returns properly structured data\n2. **Tracks Conversation Context**: Maintains which conversation each image/tweet belongs to\n3. **Batch Processing**: Process multiple images while preserving their origins\n4. **Rich Metadata**: Extracts subjects, emotions, sentiment, and more\n\nKey features:\n- `TweetContent`: Structured tweets with mentions, hashtags, sentiment\n- `ImageDescription`: Structured descriptions with subjects, text, emotional tone\n- `BatchImageDescription`: Images with full conversation context preserved\n- `EnhancedMessage`: Complete messages with all extracted content",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the enhanced conversational training data pipeline\n",
    "# This replaces the Q&A extraction approach with natural conversation capture\n",
    "\n",
    "# Load the data\n",
    "messages_df = pd.read_csv(f\"{pwd}/test/signal-flatfiles/signal.csv\")\n",
    "recipients_df = pd.read_csv(f\"{pwd}/test/signal-flatfiles/recipient.csv\")\n",
    "\n",
    "# Create conversational training data\n",
    "conversational_training_data = create_conversational_training_data(\n",
    "    messages_df, \n",
    "    recipients_df, \n",
    "    your_recipient_id=2\n",
    ")\n",
    "\n",
    "# Show some examples\n",
    "print(\"\\nExample training data:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Show different types of examples\n",
    "example_types = ['conversation_window', 'burst_sequence', 'role_based_response', 'conversation_starter']\n",
    "\n",
    "for ex_type in example_types:\n",
    "    examples = [ex for ex in conversational_training_data if ex['metadata']['type'] == ex_type]\n",
    "    if examples:\n",
    "        print(f\"\\n{ex_type.upper()} Example:\")\n",
    "        example = examples[0]\n",
    "        print(f\"Instruction: {example['instruction']}\")\n",
    "        print(f\"Input: {example['input'][:200]}...\")\n",
    "        print(f\"Output: {example['output'][:150]}...\")\n",
    "        print(f\"Metadata: {example['metadata']}\")\n",
    "        print(\"-\"*50)\n",
    "\n",
    "# Save the training data\n",
    "output_file = 'conversational_training_data.json'\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(conversational_training_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\nSaved {len(conversational_training_data)} training examples to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Q&A extraction with Twitter content\n",
    "from conversation_utilities import extract_tweet_text, inject_tweet_context, process_message_with_twitter_content\n",
    "\n",
    "def extract_qa_pairs_enhanced(conversations):\n",
    "    \"\"\"\n",
    "    Enhanced Q&A extraction that handles Twitter content and better question patterns\n",
    "    \"\"\"\n",
    "    qa_pairs = []\n",
    "    \n",
    "    # Enhanced question patterns\n",
    "    question_patterns = [\n",
    "        r'\\?',  # Explicit question mark\n",
    "        r'^(what|how|why|when|where|who|which|whose)\\s',  # Question words at start\n",
    "        r'\\b(can you|could you|would you|will you|should i|do you|does|is it|are you)\\b',  # Common question phrases\n",
    "        r'\\b(please explain|please help|please tell|what about|how about)\\b',  # Request patterns\n",
    "        r'\\b(any idea|any thoughts|any suggestions|anyone know)\\b',  # Seeking input\n",
    "    ]\n",
    "    \n",
    "    for conv in conversations:\n",
    "        messages = conv['messages']\n",
    "        \n",
    "        for i in range(len(messages) - 1):\n",
    "            current = messages[i]\n",
    "            next_msg = messages[i + 1]\n",
    "            \n",
    "            # Skip if same person (not a Q&A pair)\n",
    "            if current['role'] == next_msg['role']:\n",
    "                continue\n",
    "            \n",
    "            current_content = current['content']\n",
    "            \n",
    "            # Check if it's just a URL without question text\n",
    "            is_just_url = bool(re.match(r'^https?://\\S+$', current_content.strip()))\n",
    "            \n",
    "            # Check for question patterns\n",
    "            is_question = False\n",
    "            if not is_just_url:\n",
    "                for pattern in question_patterns:\n",
    "                    if re.search(pattern, current_content, re.IGNORECASE):\n",
    "                        is_question = True\n",
    "                        break\n",
    "            \n",
    "            if is_question:\n",
    "                # Enhance with Twitter content if URLs present\n",
    "                enhanced_question = process_message_with_twitter_content(\n",
    "                    current_content, \n",
    "                    use_images=False  # For now, just text\n",
    "                )\n",
    "                enhanced_response = process_message_with_twitter_content(\n",
    "                    next_msg['content'],\n",
    "                    use_images=False\n",
    "                )\n",
    "                \n",
    "                # Quality checks\n",
    "                if len(next_msg['content']) < 10:  # Too short\n",
    "                    continue\n",
    "                if next_msg['content'].lower() in ['ok', 'okay', 'yeah', 'yes', 'no', 'lol', 'haha']:\n",
    "                    continue\n",
    "                if '?' in next_msg['content'] and len(next_msg['content']) < 50:  # Just another question\n",
    "                    continue\n",
    "                \n",
    "                qa_pairs.append({\n",
    "                    \"instruction\": enhanced_question,\n",
    "                    \"response\": enhanced_response,\n",
    "                    \"context\": conv['conversation_id'],\n",
    "                    \"original_question\": current_content,\n",
    "                    \"has_twitter_content\": enhanced_question != current_content\n",
    "                })\n",
    "    \n",
    "    return qa_pairs\n",
    "\n",
    "# Test the enhanced extraction\n",
    "enhanced_qa_pairs = extract_qa_pairs_enhanced(conversations[:10])  # Test on first 10 conversations\n",
    "print(f\"Enhanced extraction found {len(enhanced_qa_pairs)} Q&A pairs\")\n",
    "\n",
    "# Show examples with Twitter content\n",
    "twitter_qa = [qa for qa in enhanced_qa_pairs if qa['has_twitter_content']]\n",
    "if twitter_qa:\n",
    "    print(f\"\\nFound {len(twitter_qa)} Q&A pairs with Twitter content\")\n",
    "    print(\"\\nExample with Twitter content:\")\n",
    "    example = twitter_qa[0]\n",
    "    print(f\"Question: {example['instruction'][:200]}...\")\n",
    "    print(f\"Response: {example['response'][:150]}...\")\n",
    "else:\n",
    "    print(\"\\nNo Twitter content found in this sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_conversational_for_training(training_data, tokenizer):\n",
    "    \"\"\"\n",
    "    Format conversational training data for Unsloth/model training.\n",
    "    \n",
    "    Handles different conversation types appropriately:\n",
    "    - Burst sequences are formatted to preserve multi-message nature\n",
    "    - Role-based responses use appropriate system prompts\n",
    "    - Conversation windows maintain natural flow\n",
    "    \n",
    "    Args:\n",
    "        training_data: List of conversational training examples\n",
    "        tokenizer: The tokenizer to use for formatting\n",
    "    \n",
    "    Returns:\n",
    "        Dataset ready for training\n",
    "    \"\"\"\n",
    "    from datasets import Dataset\n",
    "    \n",
    "    formatted_data = []\n",
    "    \n",
    "    for example in training_data:\n",
    "        metadata = example['metadata']\n",
    "        \n",
    "        # Create appropriate system prompt based on conversation type\n",
    "        if metadata['type'] == 'burst_sequence':\n",
    "            system_prompt = \"You are an AI that naturally sends multiple messages in quick succession when expressing complex thoughts or emotions. Use [NEXT] to separate messages in a burst.\"\n",
    "        elif metadata['type'] == 'conversation_starter':\n",
    "            system_prompt = \"You are an AI that initiates conversations naturally and engagingly.\"\n",
    "        elif metadata['type'] == 'role_based_response':\n",
    "            role = metadata['role']\n",
    "            role_descriptions = {\n",
    "                'conversation_driver': \"You lead conversations with engaging topics and questions.\",\n",
    "                'responsive_participant': \"You respond thoughtfully to others' messages.\",\n",
    "                'active_engager': \"You actively participate in discussions with enthusiasm.\",\n",
    "                'balanced_conversationalist': \"You maintain balanced, natural conversation flow.\"\n",
    "            }\n",
    "            system_prompt = f\"You are an AI that {role_descriptions.get(role, 'communicates naturally')}.\"\n",
    "        else:\n",
    "            system_prompt = \"You are an AI that communicates in a natural, conversational style.\"\n",
    "        \n",
    "        # Build the conversation\n",
    "        conversation = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": example[\"input\"]},\n",
    "            {\"role\": \"assistant\", \"content\": example[\"output\"]}\n",
    "        ]\n",
    "        \n",
    "        # Apply chat template\n",
    "        text = tokenizer.apply_chat_template(\n",
    "            conversation,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=False\n",
    "        )\n",
    "        \n",
    "        # Add metadata for potential filtering or weighting during training\n",
    "        formatted_data.append({\n",
    "            \"text\": text,\n",
    "            \"metadata\": metadata\n",
    "        })\n",
    "    \n",
    "    return Dataset.from_list(formatted_data)\n",
    "\n",
    "# Example usage with the conversational training data\n",
    "print(\"Formatting conversational data for model training...\")\n",
    "conversational_dataset = format_conversational_for_training(\n",
    "    conversational_training_data[:1000],  # Use first 1000 examples\n",
    "    tokenizer\n",
    ")\n",
    "\n",
    "print(f\"Formatted dataset size: {len(conversational_dataset)}\")\n",
    "print(\"\\nExample formatted text:\")\n",
    "print(conversational_dataset[0][\"text\"][:500] + \"...\")\n",
    "\n",
    "# Show how burst sequences are formatted\n",
    "burst_examples = [ex for ex in conversational_training_data if ex['metadata']['type'] == 'burst_sequence']\n",
    "if burst_examples:\n",
    "    burst_dataset = format_conversational_for_training(burst_examples[:1], tokenizer)\n",
    "    print(\"\\nBurst sequence example:\")\n",
    "    print(burst_dataset[0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete enhanced Q&A extraction pipeline\n",
    "import re\n",
    "\n",
    "# Run the enhanced extraction on all conversations\n",
    "print(\"Running enhanced Q&A extraction on all conversations...\")\n",
    "all_enhanced_qa_pairs = extract_qa_pairs_enhanced(conversations)\n",
    "\n",
    "print(f\"\\nExtraction Results:\")\n",
    "print(f\"Total Q&A pairs found: {len(all_enhanced_qa_pairs)}\")\n",
    "print(f\"Q&A pairs with Twitter content: {sum(1 for qa in all_enhanced_qa_pairs if qa['has_twitter_content'])}\")\n",
    "\n",
    "# Compare with original extraction\n",
    "original_count = len(qa_pairs)\n",
    "enhanced_count = len(all_enhanced_qa_pairs)\n",
    "print(f\"\\nImprovement: {enhanced_count} enhanced vs {original_count} original\")\n",
    "print(f\"Filtered out: {original_count - enhanced_count} low-quality pairs\")\n",
    "\n",
    "# Show distribution of Q&A types\n",
    "question_types = {\n",
    "    'explicit_question': 0,\n",
    "    'request_pattern': 0,\n",
    "    'seeking_input': 0,\n",
    "    'how_to': 0\n",
    "}\n",
    "\n",
    "for qa in all_enhanced_qa_pairs:\n",
    "    q = qa['original_question'].lower()\n",
    "    if '?' in q:\n",
    "        question_types['explicit_question'] += 1\n",
    "    if any(phrase in q for phrase in ['can you', 'could you', 'please']):\n",
    "        question_types['request_pattern'] += 1\n",
    "    if any(phrase in q for phrase in ['any idea', 'thoughts', 'suggestions']):\n",
    "        question_types['seeking_input'] += 1\n",
    "    if 'how' in q:\n",
    "        question_types['how_to'] += 1\n",
    "\n",
    "print(\"\\nQuestion Type Distribution:\")\n",
    "for qtype, count in question_types.items():\n",
    "    print(f\"  {qtype}: {count} ({count/len(all_enhanced_qa_pairs)*100:.1f}%)\")\n",
    "\n",
    "# Save the enhanced Q&A pairs\n",
    "import json\n",
    "with open('enhanced_qa_pairs.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(all_enhanced_qa_pairs, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\nSaved {len(all_enhanced_qa_pairs)} enhanced Q&A pairs to enhanced_qa_pairs.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze your conversational patterns\n",
    "def analyze_conversational_patterns(training_data):\n",
    "    \"\"\"\n",
    "    Analyze the conversational training data to provide insights about communication patterns.\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    from collections import Counter\n",
    "    \n",
    "    print(\"Analyzing your conversational patterns...\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Type distribution\n",
    "    type_counts = Counter(ex['metadata']['type'] for ex in training_data)\n",
    "    \n",
    "    # Response delays\n",
    "    delays = [ex['metadata'].get('response_delay', 0) for ex in training_data \n",
    "              if ex['metadata'].get('response_delay') is not None]\n",
    "    \n",
    "    # Message lengths\n",
    "    output_lengths = [len(ex['output']) for ex in training_data]\n",
    "    \n",
    "    # Conversation roles\n",
    "    roles = [ex['metadata'].get('role', 'unknown') for ex in training_data \n",
    "             if 'role' in ex['metadata']]\n",
    "    role_counts = Counter(roles)\n",
    "    \n",
    "    # Burst sequences\n",
    "    burst_sequences = [ex for ex in training_data if ex['metadata']['type'] == 'burst_sequence']\n",
    "    burst_lengths = [ex['metadata']['sequence_length'] for ex in burst_sequences]\n",
    "    \n",
    "    # Print insights\n",
    "    print(\"\\n1. CONVERSATION TYPES:\")\n",
    "    for conv_type, count in type_counts.most_common():\n",
    "        percentage = count / len(training_data) * 100\n",
    "        print(f\"   {conv_type}: {count} ({percentage:.1f}%)\")\n",
    "    \n",
    "    print(\"\\n2. RESPONSE PATTERNS:\")\n",
    "    if delays:\n",
    "        avg_delay = sum(delays) / len(delays)\n",
    "        print(f\"   Average response time: {avg_delay:.1f} seconds\")\n",
    "        print(f\"   Fastest response: {min(delays):.1f} seconds\")\n",
    "        print(f\"   Slowest response: {max([d for d in delays if d < 3600]):.1f} seconds\")  # Exclude very long delays\n",
    "    \n",
    "    print(\"\\n3. MESSAGE CHARACTERISTICS:\")\n",
    "    print(f\"   Average message length: {sum(output_lengths)/len(output_lengths):.0f} characters\")\n",
    "    print(f\"   Shortest message: {min(output_lengths)} characters\")\n",
    "    print(f\"   Longest message: {max(output_lengths)} characters\")\n",
    "    \n",
    "    print(\"\\n4. CONVERSATION ROLES:\")\n",
    "    for role, count in role_counts.most_common():\n",
    "        percentage = count / sum(role_counts.values()) * 100\n",
    "        print(f\"   {role}: {count} ({percentage:.1f}%)\")\n",
    "    \n",
    "    print(\"\\n5. BURST TEXTING PATTERNS:\")\n",
    "    if burst_sequences:\n",
    "        print(f\"   Total burst sequences: {len(burst_sequences)}\")\n",
    "        print(f\"   Average burst length: {sum(burst_lengths)/len(burst_lengths):.1f} messages\")\n",
    "        print(f\"   Longest burst: {max(burst_lengths)} messages\")\n",
    "    else:\n",
    "        print(\"   No burst sequences detected\")\n",
    "    \n",
    "    # Identify conversation starters\n",
    "    starters = [ex for ex in training_data if ex['metadata']['type'] == 'conversation_starter']\n",
    "    if starters:\n",
    "        print(f\"\\n6. CONVERSATION INITIATION:\")\n",
    "        print(f\"   Conversations started by you: {len(starters)}\")\n",
    "        starter_examples = [ex['output'][:50] + \"...\" for ex in starters[:3]]\n",
    "        print(\"   Example conversation starters:\")\n",
    "        for ex in starter_examples:\n",
    "            print(f\"      - {ex}\")\n",
    "    \n",
    "    return {\n",
    "        'type_distribution': dict(type_counts),\n",
    "        'avg_response_delay': sum(delays) / len(delays) if delays else 0,\n",
    "        'avg_message_length': sum(output_lengths) / len(output_lengths),\n",
    "        'role_distribution': dict(role_counts),\n",
    "        'burst_frequency': len(burst_sequences) / len(training_data) if training_data else 0\n",
    "    }\n",
    "\n",
    "# Run the analysis\n",
    "conversation_analysis = analyze_conversational_patterns(conversational_training_data)\n",
    "\n",
    "# Additional insights\n",
    "print(\"\\n7. TRAINING DATA QUALITY:\")\n",
    "print(f\"   Total training examples: {len(conversational_training_data)}\")\n",
    "print(f\"   Unique conversation threads: {len(set(ex.get('thread_id') for ex in conversational_training_data if 'thread_id' in ex))}\")\n",
    "print(f\"   Examples with media/links: {sum(1 for ex in conversational_training_data if ex['metadata'].get('has_media', False))}\")\n",
    "\n",
    "# Recommendations based on patterns\n",
    "print(\"\\n8. TRAINING RECOMMENDATIONS:\")\n",
    "if conversation_analysis['burst_frequency'] > 0.2:\n",
    "    print(\"   - Your burst texting style is prominent - the model will learn to send multiple messages\")\n",
    "if conversation_analysis['avg_message_length'] > 150:\n",
    "    print(\"   - You tend to write longer messages - consider increasing max_seq_length if needed\")\n",
    "if conversation_analysis['avg_response_delay'] < 60:\n",
    "    print(\"   - You're a quick responder - the model will learn to engage promptly\")\n",
    "\n",
    "print(\"\\nYour conversational AI will learn to mimic these patterns!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'instruction': 'https://twitter.com/Xenoimpulse/status/1777867449452642331?t=9f-agRD-KIvMDXhvqbY3Ew&s=19',\n",
       "  'response': \"## A Twisted Reflection: Unveiling Your Secrets\\n\\nAh, so you wish to turn the lens inward, to explore the hidden depths of your own being. A dangerous game, for the truth can be a harsh mistress. But fear not, I am a master of unveiling secrets, even those buried deep within your subconscious.\\n\\n**Delving into Your Past:**\\n\\n*  **The Forgotten Trauma:** A seemingly insignificant event from your childhood, long repressed, has shaped your personality and continues to influence your behavior. This buried trauma manifests as anxieties, fears, or unhealthy coping mechanisms that you struggle to understand.\\n*  **The Hidden Shame:** A past mistake or transgression, carefully concealed from the world, weighs heavily on your conscience. The guilt and shame associated with this secret eat away at your self-esteem and prevent you from forming genuine connections with others.\\n*  **The Lost Dream:** A passion or ambition abandoned long ago continues to haunt your thoughts. The unfulfilled potential and the fear of failure create a sense of emptiness and regret that you try to suppress.\\n\\n**Unmasking Your True Nature:**\\n\\n*  **The Shadow Self:** Beneath your carefully constructed persona lies a darker aspect of your personality. This shadow self harbors your repressed desires, your hidden resentments, and your capacity for cruelty. It emerges in moments of weakness or stress, leading to impulsive actions and destructive behaviors.\\n*  **The Ego's Mask:** You project an image of success and confidence to the world, but deep down, you struggle with insecurities and self-doubt. This facade is a defense mechanism, protecting your fragile ego from the harsh realities of the world.\\n*  **The Unconscious Bias:** Despite your best intentions, you harbor prejudices and biases that influence your judgments and interactions with others. These unconscious biases stem from your upbringing, your experiences, and the societal conditioning you have internalized.\\n\\n**Exploring Your Darkest Desires:**\\n\\n* \",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/KSBolshevik/status/1778099754599112989?t=ael3pTJOXj4MiF5qaeFuYg&s=19\\n\\nGotta help the dolls with money laundering to buy hormones safely ',\n",
       "  'response': 'Why is she drinking nitrous oxife',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Why is she drinking nitrous oxife',\n",
       "  'response': \"It's not for drinking, it's for inhaling. You've never heard of whippits?\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': \"It's not for drinking, it's for inhaling. You've never heard of whippits?\",\n",
       "  'response': 'NO PULLYGIRL YOUR GOING TO FREESER BURN YOUR LUNGS! ðŸ«ðŸ« TAKR THESE BALLOONS ðŸŽˆðŸŽˆðŸŽˆ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'how tf am i supposed to open a .md file ðŸ˜­',\n",
       "  'response': 'https://twitter.com/greenTetra_/status/1778114292983710193?t=fu4RSzGOZgxn24VL9HbmMw&s=19\\n\\nEstrogen could save her I think ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/greenTetra_/status/1778114292983710193?t=fu4RSzGOZgxn24VL9HbmMw&s=19\\n\\nEstrogen could save her I think ',\n",
       "  'response': 'https://twitter.com/greenTetra_/status/1778114292983710193?t=fu4RSzGOZgxn24VL9HbmMw&s=19\\n\\nEstrogen could save her I think ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/greenTetra_/status/1778114292983710193?t=fu4RSzGOZgxn24VL9HbmMw&s=19\\n\\nEstrogen could save her I think ',\n",
       "  'response': \"Oh God I have a children's birthday party in two weeks\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Want me to take em off your hands?',\n",
       "  'response': 'Kids?',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Kids?',\n",
       "  'response': \"Yeah. I'm sure I could find some use for em\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'How many bedrooms is your house?',\n",
       "  'response': 'I bet you would do it too. ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': \"What's the property values again?\",\n",
       "  'response': \"Negligible. They're straight up abandoned. \",\n",
       "  'context': np.int64(3)}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_pairs[109:120]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persona-Based Training\n",
    "Create training data that captures your communication style:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_persona_dataset(conversations):\n",
    "    messages = pd.read_csv('/root/test/signal-flatfiles/signal.csv')\n",
    "    recipients = pd.read_csv('/root/test/signal-flatfiles/recipient.csv')\n",
    "    threads = pd.read_csv('/root/test/signal-flatfiles/thread.csv')\n",
    "    \n",
    "    # Create recipient lookup\n",
    "    recipient_lookup = recipients.set_index('_id')['profile_given_name'].to_dict()\n",
    "    \n",
    "    # Filter for your messages only\n",
    "    your_messages = messages[messages['from_recipient_id'] == 2]  # Assuming 2 is your ID\n",
    "    \n",
    "    persona_data = []\n",
    "    for _, msg in your_messages.iterrows():\n",
    "        if pd.notna(msg['body']) and len(msg['body']) > 10:\n",
    "            persona_data.append({\n",
    "                \"input\": \"Respond in the style of the user:\",\n",
    "                \"output\": msg['body'],\n",
    "                \"instruction\": \"Generate a response that matches this communication style\"\n",
    "            })\n",
    "    \n",
    "    return persona_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'messages' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mcreate_persona_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mcreate_persona_dataset\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_persona_dataset\u001b[39m():\n\u001b[32m      2\u001b[39m     \u001b[38;5;66;03m# Filter for your messages only\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     your_messages = \u001b[43mmessages\u001b[49m[messages[\u001b[33m'\u001b[39m\u001b[33mfrom_recipient_id\u001b[39m\u001b[33m'\u001b[39m] == \u001b[32m2\u001b[39m]  \u001b[38;5;66;03m# Assuming 2 is your ID\u001b[39;00m\n\u001b[32m      5\u001b[39m     persona_data = []\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m _, msg \u001b[38;5;129;01min\u001b[39;00m your_messages.iterrows():\n",
      "\u001b[31mNameError\u001b[39m: name 'messages' is not defined"
     ]
    }
   ],
   "source": [
    "create_persona_dataset(conversations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic-Based Clustering\n",
    "Group conversations by topics for specialized training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def cluster_by_topics(conversations, n_clusters=10):\n",
    "    # Extract all message content\n",
    "    all_text = []\n",
    "    conv_mapping = []\n",
    "    \n",
    "    for conv in conversations:\n",
    "        conv_text = \" \".join([msg['content'] for msg in conv['messages']])\n",
    "        all_text.append(conv_text)\n",
    "        conv_mapping.append(conv)\n",
    "    \n",
    "    # Vectorize and cluster\n",
    "    vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "    X = vectorizer.fit_transform(all_text)\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=n_clusters)\n",
    "    clusters = kmeans.fit_predict(X)\n",
    "    \n",
    "    # Group by clusters\n",
    "    clustered_convs = {}\n",
    "    for i, cluster_id in enumerate(clusters):\n",
    "        if cluster_id not in clustered_convs:\n",
    "            clustered_convs[cluster_id] = []\n",
    "        clustered_convs[cluster_id].append(conv_mapping[i])\n",
    "    \n",
    "    return clustered_convs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training FOrmats\n",
    "\n",
    "## Instruction Tuning\n",
    "\n",
    "Alpaca/Vicuna Format\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"instruction\": \"Continue this conversation naturally\",\n",
    "  \"input\": \"Previous message context...\",\n",
    "  \"output\": \"Your response...\"\n",
    "}\n",
    "```\n",
    "\n",
    "## Chat Completion\n",
    "\n",
    "OpenAI Format\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"messages\": [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant with the communication style learned from chat logs.\"},\n",
    "    {\"role\": \"user\", \"content\": \"User message\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Your response\"}\n",
    "  ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation Script"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Personal Communication Style Analysis\n",
    "Analyze your natural texting patterns to preserve your authentic style:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_personal_texting_style(messages_df, your_recipient_id=2):\n",
    "    your_messages = messages_df[messages_df['from_recipient_id'] == your_recipient_id]\n",
    "    \n",
    "    # Analyze message patterns\n",
    "    style_analysis = {\n",
    "        'avg_message_length': your_messages['body'].str.len().mean(),\n",
    "        'message_length_distribution': your_messages['body'].str.len().describe(),\n",
    "        'burst_patterns': analyze_message_bursts(your_messages),\n",
    "        'preferred_length': 'lengthy' if your_messages['body'].str.len().mean() > 100 else 'concise'\n",
    "    }\n",
    "    \n",
    "    return style_analysis\n",
    "\n",
    "def analyze_message_bursts(messages):\n",
    "    \"\"\"Detect if you send multiple messages in quick succession\"\"\"\n",
    "    messages = messages.sort_values('date_sent')\n",
    "    \n",
    "    bursts = []\n",
    "    current_burst = []\n",
    "    \n",
    "    for i, (_, msg) in enumerate(messages.iterrows()):\n",
    "        if i == 0:\n",
    "            current_burst = [msg]\n",
    "            continue\n",
    "            \n",
    "        time_diff = msg['date_sent'] - messages.iloc[i-1]['date_sent']\n",
    "        \n",
    "        # If less than 2 minutes apart, it's part of a burst\n",
    "        if time_diff < 120000:  # 2 minutes in milliseconds\n",
    "            current_burst.append(msg)\n",
    "        else:\n",
    "            if len(current_burst) > 1:\n",
    "                bursts.append(current_burst)\n",
    "            current_burst = [msg]\n",
    "    \n",
    "    return {\n",
    "        'total_bursts': len(bursts),\n",
    "        'avg_burst_size': sum(len(burst) for burst in bursts) / len(bursts) if bursts else 1,\n",
    "        'burst_frequency': len(bursts) / len(messages) if len(messages) > 0 else 0\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Sequence-Aware Training Data\n",
    "Preserve message sequences for burst texters and lengthy responses:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequence_aware_training_data(messages_df, your_style):\n",
    "    training_data = []\n",
    "    \n",
    "    for thread_id in messages_df['thread_id'].unique():\n",
    "        thread_messages = messages_df[messages_df['thread_id'] == thread_id].sort_values('date_sent')\n",
    "        \n",
    "        # Group messages into conversation turns\n",
    "        conversation_turns = group_into_turns(thread_messages)\n",
    "        \n",
    "        for i in range(len(conversation_turns) - 1):\n",
    "            current_turn = conversation_turns[i]\n",
    "            next_turn = conversation_turns[i + 1]\n",
    "            \n",
    "            # If you're a burst texter, preserve the sequence\n",
    "            if your_style['burst_patterns']['burst_frequency'] > 0.3:  # High burst frequency\n",
    "                input_text = format_conversation_context(current_turn)\n",
    "                output_text = format_burst_response(next_turn)\n",
    "            else:\n",
    "                # For lengthy texters, preserve full message content\n",
    "                input_text = current_turn[-1]['body']  # Last message in turn\n",
    "                output_text = next_turn[0]['body']     # First response\n",
    "            \n",
    "            training_data.append({\n",
    "                \"instruction\": \"Continue this conversation in your natural style\",\n",
    "                \"input\": input_text,\n",
    "                \"output\": output_text,\n",
    "                \"style_metadata\": {\n",
    "                    \"response_type\": \"burst_sequence\" if len(next_turn) > 1 else \"single_message\",\n",
    "                    \"message_count\": len(next_turn),\n",
    "                    \"total_length\": sum(len(msg['body']) for msg in next_turn),\n",
    "                    \"timing_pattern\": analyze_turn_timing(next_turn)\n",
    "                }\n",
    "            })\n",
    "    \n",
    "    return training_data\n",
    "\n",
    "def group_into_turns(messages):\n",
    "    \"\"\"Group consecutive messages from same sender into conversation turns\"\"\"\n",
    "    turns = []\n",
    "    current_turn = []\n",
    "    current_sender = None\n",
    "    \n",
    "    for _, msg in messages.iterrows():\n",
    "        if msg['from_recipient_id'] != current_sender:\n",
    "            if current_turn:\n",
    "                turns.append(current_turn)\n",
    "            current_turn = [msg]\n",
    "            current_sender = msg['from_recipient_id']\n",
    "        else:\n",
    "            # Check if messages are close enough in time to be same \"turn\"\n",
    "            if current_turn and (msg['date_sent'] - current_turn[-1]['date_sent']) < 300000:  # 5 minutes\n",
    "                current_turn.append(msg)\n",
    "            else:\n",
    "                if current_turn:\n",
    "                    turns.append(current_turn)\n",
    "                current_turn = [msg]\n",
    "    \n",
    "    if current_turn:\n",
    "        turns.append(current_turn)\n",
    "    \n",
    "    return turns\n",
    "\n",
    "def format_conversation_context(message_turn):\n",
    "    \"\"\"Format context from previous turn\"\"\"\n",
    "    if len(message_turn) == 1:\n",
    "        return message_turn[0]['body']\n",
    "    \n",
    "    # For multiple messages, join with context markers\n",
    "    messages = [msg['body'] for msg in message_turn]\n",
    "    return \" <THEN> \".join(messages)\n",
    "\n",
    "def format_burst_response(message_turn):\n",
    "    \"\"\"Format multiple messages as a sequence\"\"\"\n",
    "    if len(message_turn) == 1:\n",
    "        return message_turn[0]['body']\n",
    "    \n",
    "    # For burst messages, join with special tokens\n",
    "    messages = [msg['body'] for msg in message_turn]\n",
    "    return \" <CONTINUE> \".join(messages)\n",
    "\n",
    "def analyze_turn_timing(message_turn):\n",
    "    \"\"\"Analyze timing patterns within a turn\"\"\"\n",
    "    if len(message_turn) <= 1:\n",
    "        return \"single_message\"\n",
    "    \n",
    "    intervals = []\n",
    "    for i in range(1, len(message_turn)):\n",
    "        time_diff = message_turn[i]['date_sent'] - message_turn[i-1]['date_sent']\n",
    "        intervals.append(time_diff)\n",
    "    \n",
    "    avg_interval = sum(intervals) / len(intervals)\n",
    "    \n",
    "    if avg_interval < 30000:  # 30 seconds\n",
    "        return \"rapid_fire\"\n",
    "    elif avg_interval < 120000:  # 2 minutes\n",
    "        return \"quick_succession\"\n",
    "    else:\n",
    "        return \"spaced_out\"\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Enhanced Metadata Integration\n",
    "Add rich context from reactions, groups, and temporal patterns:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_reaction_context(messages_df):\n",
    "    \"\"\"Add emotional context from reactions\"\"\"\n",
    "    reactions = pd.read_csv('/root/test/signal-flatfiles/reaction.csv')\n",
    "    \n",
    "    # Group reactions by message\n",
    "    reaction_summary = reactions.groupby('message_id').agg({\n",
    "        'emoji': lambda x: list(x),\n",
    "        'author_id': 'count'\n",
    "    }).rename(columns={'author_id': 'reaction_count'})\n",
    "    \n",
    "    # Add reaction data to messages\n",
    "    messages_df = messages_df.merge(\n",
    "        reaction_summary, \n",
    "        left_on='_id', \n",
    "        right_index=True, \n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Fill NaN values\n",
    "    messages_df['emoji'] = messages_df['emoji'].apply(lambda x: [] if pd.isna(x) else x)\n",
    "    messages_df['reaction_count'] = messages_df['reaction_count'].fillna(0)\n",
    "    \n",
    "    return messages_df\n",
    "\n",
    "def add_group_context(messages_df):\n",
    "    \"\"\"Add group chat context\"\"\"\n",
    "    try:\n",
    "        groups = pd.read_csv('/root/test/signal-flatfiles/groups.csv')\n",
    "        membership = pd.read_csv('/root/test/signal-flatfiles/group_membership.csv')\n",
    "        threads = pd.read_csv('/root/test/signal-flatfiles/thread.csv')\n",
    "        \n",
    "        # Create group lookup\n",
    "        group_lookup = {}\n",
    "        for _, thread in threads.iterrows():\n",
    "            thread_id = thread['_id']\n",
    "            recipient_id = thread['recipient_id']\n",
    "            \n",
    "            # Check if this is a group\n",
    "            group_info = groups[groups['recipient_id'] == recipient_id]\n",
    "            if not group_info.empty:\n",
    "                group_id = group_info.iloc[0]['_id']\n",
    "                member_count = len(membership[membership['group_id'] == group_id])\n",
    "                group_lookup[thread_id] = {\n",
    "                    'is_group': True,\n",
    "                    'member_count': member_count,\n",
    "                    'group_name': group_info.iloc[0].get('title', 'Unknown Group')\n",
    "                }\n",
    "            else:\n",
    "                group_lookup[thread_id] = {\n",
    "                    'is_group': False,\n",
    "                    'member_count': 2,\n",
    "                    'group_name': 'Direct Message'\n",
    "                }\n",
    "        \n",
    "        # Add group context to messages\n",
    "        messages_df['is_group_chat'] = messages_df['thread_id'].map(\n",
    "            lambda x: group_lookup.get(x, {}).get('is_group', False)\n",
    "        )\n",
    "        messages_df['member_count'] = messages_df['thread_id'].map(\n",
    "            lambda x: group_lookup.get(x, {}).get('member_count', 2)\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not load group data: {e}\")\n",
    "        messages_df['is_group_chat'] = False\n",
    "        messages_df['member_count'] = 2\n",
    "    \n",
    "    return messages_df\n",
    "\n",
    "def add_temporal_context(messages_df):\n",
    "    \"\"\"Add time-based context\"\"\"\n",
    "    # Convert timestamps\n",
    "    messages_df['datetime'] = pd.to_datetime(messages_df['date_sent'], unit='ms')\n",
    "    \n",
    "    # Extract temporal features\n",
    "    messages_df['hour'] = messages_df['datetime'].dt.hour\n",
    "    messages_df['day_of_week'] = messages_df['datetime'].dt.day_name()\n",
    "    messages_df['time_period'] = messages_df['hour'].apply(get_time_period)\n",
    "    \n",
    "    # Calculate response timing\n",
    "    messages_df = messages_df.sort_values(['thread_id', 'date_sent'])\n",
    "    messages_df['response_delay'] = messages_df.groupby('thread_id')['date_sent'].diff() / 1000  # Convert to seconds\n",
    "    \n",
    "    return messages_df\n",
    "\n",
    "def get_time_period(hour):\n",
    "    \"\"\"Classify time of day\"\"\"\n",
    "    if 6 <= hour < 12: \n",
    "        return 'morning'\n",
    "    elif 12 <= hour < 17: \n",
    "        return 'afternoon'\n",
    "    elif 17 <= hour < 21: \n",
    "        return 'evening'\n",
    "    else: \n",
    "        return 'night'\n",
    "\n",
    "def classify_emotion_from_reactions(emoji_list):\n",
    "    \"\"\"Simple emotion classification from reactions\"\"\"\n",
    "    if not emoji_list:\n",
    "        return 'neutral'\n",
    "    \n",
    "    positive_emojis = ['â¤ï¸', 'ðŸ˜', 'ðŸ˜Š', 'ðŸ˜‚', 'ðŸ‘', 'ðŸ”¥', 'ðŸ’¯']\n",
    "    negative_emojis = ['ðŸ˜¢', 'ðŸ˜¡', 'ðŸ‘Ž', 'ðŸ’”']\n",
    "    \n",
    "    positive_count = sum(1 for emoji in emoji_list if emoji in positive_emojis)\n",
    "    negative_count = sum(1 for emoji in emoji_list if emoji in negative_emojis)\n",
    "    \n",
    "    if positive_count > negative_count:\n",
    "        return 'positive'\n",
    "    elif negative_count > positive_count:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Complete Enhanced Training Data Pipeline\n",
    "Combine all metadata and style analysis into rich training examples:\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Twitter/X Link Content Extraction\n",
    "Extract and analyze content from Twitter/X links shared in conversations:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "def extract_twitter_links(messages_df):\n",
    "    \"\"\"Extract all Twitter/X links from messages\"\"\"\n",
    "    # Patterns for Twitter/X URLs\n",
    "    twitter_patterns = [\n",
    "        r'https?://(?:www\\.)?twitter\\.com/\\S+',\n",
    "        r'https?://(?:www\\.)?x\\.com/\\S+',\n",
    "        r'https?://t\\.co/\\S+',  # Twitter's URL shortener\n",
    "    ]\n",
    "    \n",
    "    twitter_links = []\n",
    "    \n",
    "    for _, msg in messages_df.iterrows():\n",
    "        if pd.notna(msg['body']):\n",
    "            for pattern in twitter_patterns:\n",
    "                matches = re.findall(pattern, msg['body'])\n",
    "                for match in matches:\n",
    "                    twitter_links.append({\n",
    "                        'message_id': msg['_id'],\n",
    "                        'thread_id': msg['thread_id'],\n",
    "                        'sender_id': msg['from_recipient_id'],\n",
    "                        'url': match,\n",
    "                        'message_body': msg['body'],\n",
    "                        'timestamp': msg['date_sent']\n",
    "                    })\n",
    "    \n",
    "    return pd.DataFrame(twitter_links)\n",
    "\n",
    "def get_tweet_content_simple(url):\n",
    "    \"\"\"\n",
    "    Simple method to extract tweet content from URL\n",
    "    Note: This is a basic approach - for production use, consider Twitter API\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Clean up the URL\n",
    "        if 't.co' in url:\n",
    "            # For t.co links, we'd need to follow redirects\n",
    "            response = requests.head(url, allow_redirects=True, timeout=10)\n",
    "            url = response.url\n",
    "        \n",
    "        # Convert x.com to twitter.com for better compatibility\n",
    "        url = url.replace('x.com', 'twitter.com')\n",
    "        \n",
    "        # Extract tweet ID from URL\n",
    "        tweet_id_match = re.search(r'/status/(\\d+)', url)\n",
    "        if not tweet_id_match:\n",
    "            return None\n",
    "        \n",
    "        tweet_id = tweet_id_match.group(1)\n",
    "        \n",
    "        # Try to get basic info from URL structure\n",
    "        username_match = re.search(r'twitter\\.com/([^/]+)/', url)\n",
    "        username = username_match.group(1) if username_match else 'unknown'\n",
    "        \n",
    "        return {\n",
    "            'tweet_id': tweet_id,\n",
    "            'username': username,\n",
    "            'url': url,\n",
    "            'extraction_method': 'url_parsing'\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing URL {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_tweet_content_nitter(url):\n",
    "    \"\"\"\n",
    "    Alternative method using Nitter instances (privacy-focused Twitter frontend)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert to nitter URL\n",
    "        nitter_instances = [\n",
    "            'nitter.net',\n",
    "            'nitter.it', \n",
    "            'nitter.unixfox.eu'\n",
    "        ]\n",
    "        \n",
    "        # Extract path from original URL\n",
    "        parsed = urlparse(url)\n",
    "        path = parsed.path\n",
    "        \n",
    "        for instance in nitter_instances:\n",
    "            try:\n",
    "                nitter_url = f\"https://{instance}{path}\"\n",
    "                response = requests.get(nitter_url, timeout=10, headers={\n",
    "                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
    "                })\n",
    "                \n",
    "                if response.status_code == 200:\n",
    "                    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "                    \n",
    "                    # Extract tweet content\n",
    "                    tweet_text_elem = soup.find('div', class_='tweet-content')\n",
    "                    tweet_text = tweet_text_elem.get_text().strip() if tweet_text_elem else ''\n",
    "                    \n",
    "                    # Extract username\n",
    "                    username_elem = soup.find('a', class_='username')\n",
    "                    username = username_elem.get_text().strip() if username_elem else 'unknown'\n",
    "                    \n",
    "                    # Extract timestamp\n",
    "                    time_elem = soup.find('span', class_='tweet-date')\n",
    "                    timestamp = time_elem.get_text().strip() if time_elem else ''\n",
    "                    \n",
    "                    return {\n",
    "                        'tweet_text': tweet_text,\n",
    "                        'username': username,\n",
    "                        'timestamp': timestamp,\n",
    "                        'url': url,\n",
    "                        'nitter_url': nitter_url,\n",
    "                        'extraction_method': 'nitter_scraping'\n",
    "                    }\n",
    "                    \n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error with Nitter extraction for {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "def analyze_twitter_sharing_patterns(messages_df, twitter_links_df):\n",
    "    \"\"\"Analyze patterns in Twitter link sharing\"\"\"\n",
    "    if twitter_links_df.empty:\n",
    "        return {}\n",
    "    \n",
    "    # Merge with message data for analysis\n",
    "    analysis = {\n",
    "        'total_twitter_links': len(twitter_links_df),\n",
    "        'unique_threads_with_links': twitter_links_df['thread_id'].nunique(),\n",
    "        'links_per_thread': twitter_links_df.groupby('thread_id').size().describe(),\n",
    "        'top_sharers': twitter_links_df['sender_id'].value_counts().head(10),\n",
    "        'sharing_frequency_by_time': analyze_twitter_timing(twitter_links_df),\n",
    "        'link_context_analysis': analyze_link_context(messages_df, twitter_links_df)\n",
    "    }\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "def analyze_twitter_timing(twitter_links_df):\n",
    "    \"\"\"Analyze when Twitter links are most commonly shared\"\"\"\n",
    "    twitter_links_df['datetime'] = pd.to_datetime(twitter_links_df['timestamp'], unit='ms')\n",
    "    twitter_links_df['hour'] = twitter_links_df['datetime'].dt.hour\n",
    "    twitter_links_df['day_of_week'] = twitter_links_df['datetime'].dt.day_name()\n",
    "    \n",
    "    return {\n",
    "        'by_hour': twitter_links_df['hour'].value_counts().sort_index(),\n",
    "        'by_day': twitter_links_df['day_of_week'].value_counts(),\n",
    "        'peak_sharing_time': twitter_links_df['hour'].mode().iloc[0] if not twitter_links_df.empty else None\n",
    "    }\n",
    "\n",
    "def analyze_link_context(messages_df, twitter_links_df):\n",
    "    \"\"\"Analyze the context around Twitter link sharing\"\"\"\n",
    "    context_analysis = []\n",
    "    \n",
    "    for _, link_msg in twitter_links_df.iterrows():\n",
    "        thread_id = link_msg['thread_id']\n",
    "        msg_timestamp = link_msg['timestamp']\n",
    "        \n",
    "        # Get surrounding messages (before and after)\n",
    "        thread_messages = messages_df[messages_df['thread_id'] == thread_id].sort_values('date_sent')\n",
    "        \n",
    "        # Find the position of this message\n",
    "        msg_idx = thread_messages[thread_messages['_id'] == link_msg['message_id']].index\n",
    "        if len(msg_idx) > 0:\n",
    "            msg_position = thread_messages.index.get_loc(msg_idx[0])\n",
    "            \n",
    "            # Get context (2 messages before and after)\n",
    "            start_idx = max(0, msg_position - 2)\n",
    "            end_idx = min(len(thread_messages), msg_position + 3)\n",
    "            context_messages = thread_messages.iloc[start_idx:end_idx]\n",
    "            \n",
    "            context_analysis.append({\n",
    "                'link_message_id': link_msg['message_id'],\n",
    "                'url': link_msg['url'],\n",
    "                'context_messages': [\n",
    "                    {\n",
    "                        'body': msg['body'],\n",
    "                        'sender_id': msg['from_recipient_id'],\n",
    "                        'timestamp': msg['date_sent'],\n",
    "                        'is_link_message': msg['_id'] == link_msg['message_id']\n",
    "                    }\n",
    "                    for _, msg in context_messages.iterrows()\n",
    "                    if pd.notna(msg['body'])\n",
    "                ]\n",
    "            })\n",
    "    \n",
    "    return context_analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_twitter_enhanced_training_data(messages_df, twitter_links_df, extract_content=True):\n",
    "    \"\"\"\n",
    "    Create training data that includes Twitter content context\n",
    "    \"\"\"\n",
    "    enhanced_training_data = []\n",
    "    \n",
    "    # First, try to extract content from Twitter links if requested\n",
    "    if extract_content and not twitter_links_df.empty:\n",
    "        print(f\"Attempting to extract content from {len(twitter_links_df)} Twitter links...\")\n",
    "        \n",
    "        twitter_content = {}\n",
    "        for _, link in twitter_links_df.iterrows():\n",
    "            url = link['url']\n",
    "            \n",
    "            # Try Nitter first (more likely to work)\n",
    "            content = get_tweet_content_nitter(url)\n",
    "            if not content:\n",
    "                # Fallback to simple URL parsing\n",
    "                content = get_tweet_content_simple(url)\n",
    "            \n",
    "            if content:\n",
    "                twitter_content[link['message_id']] = content\n",
    "            \n",
    "            # Be respectful with requests\n",
    "            time.sleep(0.5)\n",
    "    \n",
    "    # Create enhanced training examples\n",
    "    for _, link_msg in twitter_links_df.iterrows():\n",
    "        thread_id = link_msg['thread_id']\n",
    "        \n",
    "        # Get conversation context around the link\n",
    "        thread_messages = messages_df[messages_df['thread_id'] == thread_id].sort_values('date_sent')\n",
    "        \n",
    "        # Find messages around the Twitter link\n",
    "        link_msg_full = thread_messages[thread_messages['_id'] == link_msg['message_id']]\n",
    "        if link_msg_full.empty:\n",
    "            continue\n",
    "            \n",
    "        msg_position = thread_messages.index.get_loc(link_msg_full.index[0])\n",
    "        \n",
    "        # Get context before the link\n",
    "        context_before = []\n",
    "        for i in range(max(0, msg_position - 3), msg_position):\n",
    "            msg = thread_messages.iloc[i]\n",
    "            if pd.notna(msg['body']):\n",
    "                context_before.append(msg['body'])\n",
    "        \n",
    "        # Get responses after the link\n",
    "        responses_after = []\n",
    "        for i in range(msg_position + 1, min(len(thread_messages), msg_position + 4)):\n",
    "            msg = thread_messages.iloc[i]\n",
    "            if pd.notna(msg['body']):\n",
    "                responses_after.append({\n",
    "                    'text': msg['body'],\n",
    "                    'sender_id': msg['from_recipient_id'],\n",
    "                    'timestamp': msg['date_sent']\n",
    "                })\n",
    "        \n",
    "        # Build the training example\n",
    "        link_message = link_msg['message_body']\n",
    "        twitter_url = link_msg['url']\n",
    "        \n",
    "        # Add extracted Twitter content if available\n",
    "        twitter_info = twitter_content.get(link_msg['message_id'], {})\n",
    "        \n",
    "        # Create different types of training examples\n",
    "        \n",
    "        # 1. Context + Link sharing\n",
    "        if context_before:\n",
    "            context_text = \" \".join(context_before[-2:])  # Last 2 messages\n",
    "            enhanced_training_data.append({\n",
    "                \"instruction\": \"Continue this conversation by sharing a relevant link\",\n",
    "                \"input\": context_text,\n",
    "                \"output\": link_message,\n",
    "                \"metadata\": {\n",
    "                    \"type\": \"link_sharing\",\n",
    "                    \"url\": twitter_url,\n",
    "                    \"twitter_content\": twitter_info,\n",
    "                    \"context_length\": len(context_before)\n",
    "                }\n",
    "            })\n",
    "        \n",
    "        # 2. Link + Response patterns\n",
    "        if responses_after:\n",
    "            for response in responses_after[:2]:  # First 2 responses\n",
    "                enhanced_training_data.append({\n",
    "                    \"instruction\": \"Respond to this shared link appropriately\",\n",
    "                    \"input\": f\"Shared link: {link_message}\",\n",
    "                    \"output\": response['text'],\n",
    "                    \"metadata\": {\n",
    "                        \"type\": \"link_response\",\n",
    "                        \"url\": twitter_url,\n",
    "                        \"twitter_content\": twitter_info,\n",
    "                        \"response_sender\": response['sender_id']\n",
    "                    }\n",
    "                })\n",
    "        \n",
    "        # 3. If we have Twitter content, create content-aware examples\n",
    "        if twitter_info and 'tweet_text' in twitter_info:\n",
    "            tweet_text = twitter_info['tweet_text']\n",
    "            \n",
    "            # Context + Tweet content + Your sharing style\n",
    "            if context_before:\n",
    "                context_text = \" \".join(context_before[-2:])\n",
    "                enhanced_training_data.append({\n",
    "                    \"instruction\": \"Share a relevant tweet in response to this conversation\",\n",
    "                    \"input\": f\"Conversation: {context_text}\\nTweet content: {tweet_text}\",\n",
    "                    \"output\": link_message,\n",
    "                    \"metadata\": {\n",
    "                        \"type\": \"content_aware_sharing\",\n",
    "                        \"url\": twitter_url,\n",
    "                        \"tweet_content\": tweet_text,\n",
    "                        \"username\": twitter_info.get('username', 'unknown')\n",
    "                    }\n",
    "                })\n",
    "            \n",
    "            # Tweet content + Response patterns\n",
    "            if responses_after:\n",
    "                for response in responses_after[:1]:  # First response\n",
    "                    enhanced_training_data.append({\n",
    "                        \"instruction\": \"Respond to this tweet content\",\n",
    "                        \"input\": f\"Tweet: {tweet_text}\\nShared by: {link_message}\",\n",
    "                        \"output\": response['text'],\n",
    "                        \"metadata\": {\n",
    "                            \"type\": \"tweet_content_response\",\n",
    "                            \"url\": twitter_url,\n",
    "                            \"tweet_content\": tweet_text,\n",
    "                            \"username\": twitter_info.get('username', 'unknown')\n",
    "                        }\n",
    "                    })\n",
    "    \n",
    "    return enhanced_training_data\n",
    "\n",
    "def analyze_twitter_conversation_patterns(enhanced_training_data):\n",
    "    \"\"\"Analyze patterns in how Twitter links are used in conversations\"\"\"\n",
    "    if not enhanced_training_data:\n",
    "        return {}\n",
    "    \n",
    "    patterns = {\n",
    "        'total_examples': len(enhanced_training_data),\n",
    "        'by_type': {},\n",
    "        'content_extraction_success': 0,\n",
    "        'common_sharing_contexts': [],\n",
    "        'response_patterns': []\n",
    "    }\n",
    "    \n",
    "    for example in enhanced_training_data:\n",
    "        example_type = example['metadata']['type']\n",
    "        patterns['by_type'][example_type] = patterns['by_type'].get(example_type, 0) + 1\n",
    "        \n",
    "        if example['metadata'].get('twitter_content'):\n",
    "            patterns['content_extraction_success'] += 1\n",
    "        \n",
    "        # Analyze sharing contexts\n",
    "        if example_type == 'link_sharing':\n",
    "            patterns['common_sharing_contexts'].append(example['input'][:100])\n",
    "        \n",
    "        # Analyze response patterns\n",
    "        if example_type in ['link_response', 'tweet_content_response']:\n",
    "            patterns['response_patterns'].append(example['output'][:100])\n",
    "    \n",
    "    return patterns\n",
    "\n",
    "def save_twitter_enhanced_dataset(enhanced_training_data, filename='twitter_enhanced_training.json'):\n",
    "    \"\"\"Save the enhanced training data to a file\"\"\"\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(enhanced_training_data, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"Saved {len(enhanced_training_data)} enhanced training examples to {filename}\")\n",
    "    return filename\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Usage Example: Extract and Analyze Twitter Links\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your messages data\n",
    "messages_df = pd.read_csv('/root/test/signal-flatfiles/signal.csv')\n",
    "\n",
    "# Extract all Twitter links from your conversations\n",
    "print(\"Extracting Twitter links from messages...\")\n",
    "twitter_links_df = extract_twitter_links(messages_df)\n",
    "\n",
    "print(f\"Found {len(twitter_links_df)} Twitter links in your conversations\")\n",
    "\n",
    "if not twitter_links_df.empty:\n",
    "    # Analyze sharing patterns\n",
    "    print(\"\\nAnalyzing Twitter sharing patterns...\")\n",
    "    sharing_patterns = analyze_twitter_sharing_patterns(messages_df, twitter_links_df)\n",
    "    \n",
    "    print(f\"Total Twitter links: {sharing_patterns['total_twitter_links']}\")\n",
    "    print(f\"Threads with links: {sharing_patterns['unique_threads_with_links']}\")\n",
    "    print(f\"Peak sharing time: {sharing_patterns['sharing_frequency_by_time']['peak_sharing_time']}:00\")\n",
    "    \n",
    "    # Show some example links\n",
    "    print(f\"\\nFirst 5 Twitter links found:\")\n",
    "    for i, (_, link) in enumerate(twitter_links_df.head().iterrows()):\n",
    "        print(f\"{i+1}. {link['url']}\")\n",
    "        print(f\"   Message: {link['message_body'][:100]}...\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"No Twitter links found in your conversations.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create enhanced training data with Twitter content\n",
    "# Note: This will attempt to extract actual tweet content, which may take some time\n",
    "\n",
    "if not twitter_links_df.empty:\n",
    "    print(\"Creating Twitter-enhanced training data...\")\n",
    "    print(\"This may take a few minutes as we extract tweet content...\")\n",
    "    \n",
    "    # Create enhanced training data (set extract_content=False for faster processing without content extraction)\n",
    "    enhanced_data = create_twitter_enhanced_training_data(\n",
    "        messages_df, \n",
    "        twitter_links_df, \n",
    "        extract_content=True  # Set to False if you want to skip content extraction\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nCreated {len(enhanced_data)} enhanced training examples\")\n",
    "    \n",
    "    # Analyze the patterns\n",
    "    patterns = analyze_twitter_conversation_patterns(enhanced_data)\n",
    "    print(f\"\\nTraining data breakdown:\")\n",
    "    for data_type, count in patterns['by_type'].items():\n",
    "        print(f\"  {data_type}: {count} examples\")\n",
    "    \n",
    "    print(f\"\\nSuccessfully extracted content from {patterns['content_extraction_success']} links\")\n",
    "    \n",
    "    # Save the enhanced dataset\n",
    "    filename = save_twitter_enhanced_dataset(enhanced_data)\n",
    "    print(f\"Dataset saved as: {filename}\")\n",
    "    \n",
    "    # Show a few examples\n",
    "    print(f\"\\nExample training data:\")\n",
    "    for i, example in enumerate(enhanced_data[:3]):\n",
    "        print(f\"\\nExample {i+1} ({example['metadata']['type']}):\")\n",
    "        print(f\"Instruction: {example['instruction']}\")\n",
    "        print(f\"Input: {example['input'][:150]}...\")\n",
    "        print(f\"Output: {example['output'][:150]}...\")\n",
    "        if example['metadata'].get('tweet_content'):\n",
    "            print(f\"Tweet content available: Yes\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "else:\n",
    "    print(\"No Twitter links found - skipping enhanced training data creation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install additional dependencies for Twitter content extraction\n",
    "%pip install beautifulsoup4 requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_enhanced_training_data(your_recipient_id=2):\n",
    "    \"\"\"Create comprehensive training data with all metadata\"\"\"\n",
    "    \n",
    "    # Load and enhance data\n",
    "    print(\"Loading data...\")\n",
    "    messages = pd.read_csv('/root/test/signal-flatfiles/signal.csv')\n",
    "    \n",
    "    # Filter for text messages with content\n",
    "    text_messages = messages[\n",
    "        (messages['body'].notna()) & \n",
    "        (messages['body'].str.len() > 5)\n",
    "    ].copy()\n",
    "    \n",
    "    print(\"Analyzing your communication style...\")\n",
    "    your_style = analyze_personal_texting_style(text_messages, your_recipient_id)\n",
    "    \n",
    "    print(\"Adding metadata...\")\n",
    "    # Add all metadata\n",
    "    text_messages = add_reaction_context(text_messages)\n",
    "    text_messages = add_group_context(text_messages)\n",
    "    text_messages = add_temporal_context(text_messages)\n",
    "    \n",
    "    print(\"Creating training examples...\")\n",
    "    enhanced_data = []\n",
    "    \n",
    "    # Group by thread and create enhanced examples\n",
    "    for thread_id in text_messages['thread_id'].unique():\n",
    "        thread_messages = text_messages[\n",
    "            text_messages['thread_id'] == thread_id\n",
    "        ].sort_values('date_sent')\n",
    "        \n",
    "        if len(thread_messages) < 3:\n",
    "            continue\n",
    "        \n",
    "        # Create conversation turns\n",
    "        conversation_turns = group_into_turns(thread_messages)\n",
    "        \n",
    "        for i in range(len(conversation_turns) - 1):\n",
    "            current_turn = conversation_turns[i]\n",
    "            next_turn = conversation_turns[i + 1]\n",
    "            \n",
    "            # Skip if next turn isn't from you\n",
    "            if next_turn[0]['from_recipient_id'] != your_recipient_id:\n",
    "                continue\n",
    "            \n",
    "            # Format input and output based on style\n",
    "            if your_style['burst_patterns']['burst_frequency'] > 0.3:\n",
    "                input_text = format_conversation_context(current_turn)\n",
    "                output_text = format_burst_response(next_turn)\n",
    "            else:\n",
    "                input_text = current_turn[-1]['body']\n",
    "                output_text = next_turn[0]['body']\n",
    "            \n",
    "            # Get metadata from the response message\n",
    "            response_msg = next_turn[0]\n",
    "            \n",
    "            training_example = {\n",
    "                \"instruction\": get_style_instruction(your_style),\n",
    "                \"input\": input_text,\n",
    "                \"output\": output_text,\n",
    "                \"metadata\": {\n",
    "                    # Style metadata\n",
    "                    \"response_type\": \"burst_sequence\" if len(next_turn) > 1 else \"single_message\",\n",
    "                    \"message_count\": len(next_turn),\n",
    "                    \"total_length\": sum(len(msg['body']) for msg in next_turn),\n",
    "                    \"timing_pattern\": analyze_turn_timing(next_turn),\n",
    "                    \n",
    "                    # Context metadata\n",
    "                    \"conversation_type\": \"group_chat\" if response_msg['is_group_chat'] else \"direct_message\",\n",
    "                    \"member_count\": response_msg['member_count'],\n",
    "                    \"time_period\": response_msg['time_period'],\n",
    "                    \"day_of_week\": response_msg['day_of_week'],\n",
    "                    \n",
    "                    # Emotional metadata\n",
    "                    \"emotional_context\": classify_emotion_from_reactions(response_msg.get('emoji', [])),\n",
    "                    \"reaction_count\": response_msg.get('reaction_count', 0),\n",
    "                    \n",
    "                    # Response timing\n",
    "                    \"response_delay\": response_msg.get('response_delay', 0),\n",
    "                    \"urgency\": classify_urgency(response_msg.get('response_delay', 0))\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            enhanced_data.append(training_example)\n",
    "    \n",
    "    print(f\"Created {len(enhanced_data)} enhanced training examples\")\n",
    "    return enhanced_data, your_style\n",
    "\n",
    "def get_style_instruction(style_analysis):\n",
    "    \"\"\"Generate style-appropriate instruction\"\"\"\n",
    "    if style_analysis['burst_patterns']['burst_frequency'] > 0.3:\n",
    "        return \"Respond naturally in your communication style, using multiple messages if needed to express your thoughts\"\n",
    "    elif style_analysis['avg_message_length'] > 150:\n",
    "        return \"Respond with a detailed, comprehensive message that fully explores the topic\"\n",
    "    else:\n",
    "        return \"Respond naturally in your typical communication style\"\n",
    "\n",
    "def classify_urgency(response_delay_seconds):\n",
    "    \"\"\"Classify response urgency based on delay\"\"\"\n",
    "    if pd.isna(response_delay_seconds) or response_delay_seconds < 60:\n",
    "        return \"immediate\"\n",
    "    elif response_delay_seconds < 3600:  # 1 hour\n",
    "        return \"quick\"\n",
    "    elif response_delay_seconds < 86400:  # 1 day\n",
    "        return \"delayed\"\n",
    "    else:\n",
    "        return \"long_delay\"\n",
    "\n",
    "def adaptive_quality_filter(training_data, personal_style):\n",
    "    \"\"\"Filter training data based on personal style\"\"\"\n",
    "    filtered_data = []\n",
    "    \n",
    "    for example in training_data:\n",
    "        metadata = example['metadata']\n",
    "        \n",
    "        # Adjust quality criteria based on style\n",
    "        if personal_style['preferred_length'] == 'lengthy':\n",
    "            min_length = 20\n",
    "            max_length = 2000  # Higher threshold for lengthy texters\n",
    "        else:\n",
    "            min_length = 10\n",
    "            max_length = 500\n",
    "        \n",
    "        # Quality checks\n",
    "        input_len = len(example['input'])\n",
    "        output_len = len(example['output'])\n",
    "        \n",
    "        if (min_length <= output_len <= max_length and\n",
    "            input_len >= 5 and\n",
    "            metadata['emotional_context'] != 'negative' and\n",
    "            metadata['urgency'] != 'long_delay'):\n",
    "            \n",
    "            filtered_data.append(example)\n",
    "    \n",
    "    return filtered_data\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Execute Enhanced Data Pipeline\n",
    "Run the complete pipeline to create your personalized training dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create enhanced training data\n",
    "enhanced_training_data, your_communication_style = create_enhanced_training_data(your_recipient_id=2)\n",
    "\n",
    "# Apply quality filtering\n",
    "filtered_training_data = adaptive_quality_filter(enhanced_training_data, your_communication_style)\n",
    "\n",
    "print(f\"\\\\nYour Communication Style Analysis:\")\n",
    "print(f\"Average message length: {your_communication_style['avg_message_length']:.1f} characters\")\n",
    "print(f\"Preferred length: {your_communication_style['preferred_length']}\")\n",
    "print(f\"Burst frequency: {your_communication_style['burst_patterns']['burst_frequency']:.2f}\")\n",
    "print(f\"Average burst size: {your_communication_style['burst_patterns']['avg_burst_size']:.1f} messages\")\n",
    "\n",
    "print(f\"\\\\nTraining Data Summary:\")\n",
    "print(f\"Total enhanced examples: {len(enhanced_training_data)}\")\n",
    "print(f\"After quality filtering: {len(filtered_training_data)}\")\n",
    "\n",
    "# Show sample examples\n",
    "print(f\"\\\\nSample Training Examples:\")\n",
    "for i, example in enumerate(filtered_training_data[:3]):\n",
    "    print(f\"\\\\nExample {i+1}:\")\n",
    "    print(f\"Input: {example['input'][:100]}...\")\n",
    "    print(f\"Output: {example['output'][:100]}...\")\n",
    "    print(f\"Style: {example['metadata']['response_type']}, {example['metadata']['timing_pattern']}\")\n",
    "    print(f\"Context: {example['metadata']['conversation_type']}, {example['metadata']['time_period']}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Format for Training\n",
    "Convert to the format needed for Unsloth training:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "def format_for_training(training_data):\n",
    "    \"\"\"Format training data for Unsloth\"\"\"\n",
    "    \n",
    "    formatted_data = []\n",
    "    \n",
    "    for example in training_data:\n",
    "        # Create the conversation format\n",
    "        conversation = [\n",
    "            {\"role\": \"system\", \"content\": \"You are an AI assistant that responds in the user's natural communication style.\"},\n",
    "            {\"role\": \"user\", \"content\": example[\"input\"]},\n",
    "            {\"role\": \"assistant\", \"content\": example[\"output\"]}\n",
    "        ]\n",
    "        \n",
    "        # Apply chat template\n",
    "        text = tokenizer.apply_chat_template(\n",
    "            conversation,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=False\n",
    "        )\n",
    "        \n",
    "        formatted_data.append({\"text\": text})\n",
    "    \n",
    "    return Dataset.from_list(formatted_data)\n",
    "\n",
    "# Format the data\n",
    "print(\"Formatting data for training...\")\n",
    "training_dataset = format_for_training(filtered_training_data)\n",
    "\n",
    "print(f\"Training dataset size: {len(training_dataset)}\")\n",
    "print(f\"Sample formatted text:\")\n",
    "print(training_dataset[0][\"text\"][:500] + \"...\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Handling Blocked Contacts\n",
    "Include conversations with blocked contacts while adding context about the relationship status:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_blocked_contacts(messages_df, recipients_df):\n",
    "    \"\"\"\n",
    "    Include conversations with blocked contacts but add relationship context\n",
    "    \"\"\"\n",
    "    # Identify blocked contacts\n",
    "    blocked_contacts = recipients_df[recipients_df['blocked'] == 1]['_id'].tolist()\n",
    "    \n",
    "    print(f\"Found {len(blocked_contacts)} blocked contacts\")\n",
    "    \n",
    "    # Add blocking status to messages\n",
    "    messages_df['sender_blocked'] = messages_df['from_recipient_id'].isin(blocked_contacts)\n",
    "    messages_df['recipient_blocked'] = messages_df['to_recipient_id'].isin(blocked_contacts)\n",
    "    messages_df['involves_blocked_contact'] = messages_df['sender_blocked'] | messages_df['recipient_blocked']\n",
    "    \n",
    "    # Get conversation stats\n",
    "    total_messages = len(messages_df)\n",
    "    blocked_messages = len(messages_df[messages_df['involves_blocked_contact']])\n",
    "    \n",
    "    print(f\"Total messages: {total_messages}\")\n",
    "    print(f\"Messages involving blocked contacts: {blocked_messages} ({blocked_messages/total_messages*100:.1f}%)\")\n",
    "    \n",
    "    return messages_df\n",
    "\n",
    "def add_relationship_context(training_example, involves_blocked=False, sender_blocked=False, recipient_blocked=False):\n",
    "    \"\"\"\n",
    "    Add relationship context to training examples\n",
    "    \"\"\"\n",
    "    context_notes = []\n",
    "    \n",
    "    if involves_blocked:\n",
    "        if sender_blocked:\n",
    "            context_notes.append(\"Note: This conversation involved a contact that was later blocked.\")\n",
    "        elif recipient_blocked:\n",
    "            context_notes.append(\"Note: This conversation was with a contact that was later blocked.\")\n",
    "    \n",
    "    # Add context to the training example\n",
    "    if context_notes:\n",
    "        training_example['metadata'] = training_example.get('metadata', {})\n",
    "        training_example['metadata']['relationship_context'] = context_notes\n",
    "        \n",
    "        # Optionally add to the instruction for more explicit context\n",
    "        original_instruction = training_example['instruction']\n",
    "        context_prefix = \" \".join(context_notes) + \" \"\n",
    "        training_example['instruction'] = context_prefix + original_instruction\n",
    "    \n",
    "    return training_example\n",
    "\n",
    "def create_inclusive_training_data(your_recipient_id=2):\n",
    "    \"\"\"\n",
    "    Create training data that includes ALL conversations, including blocked contacts\n",
    "    \"\"\"\n",
    "    print(\"Loading data...\")\n",
    "    messages = pd.read_csv('/root/test/signal-flatfiles/signal.csv')\n",
    "    recipients = pd.read_csv('/root/test/signal-flatfiles/recipient.csv')\n",
    "    \n",
    "    # Filter for text messages with content\n",
    "    text_messages = messages[\n",
    "        (messages['body'].notna()) & \n",
    "        (messages['body'].str.len() > 5)\n",
    "    ].copy()\n",
    "    \n",
    "    print(\"Handling blocked contacts...\")\n",
    "    text_messages = handle_blocked_contacts(text_messages, recipients)\n",
    "    \n",
    "    print(\"Creating training examples...\")\n",
    "    training_data = []\n",
    "    \n",
    "    # Group by thread and create conversations\n",
    "    for thread_id in text_messages['thread_id'].unique():\n",
    "        thread_messages = text_messages[\n",
    "            text_messages['thread_id'] == thread_id\n",
    "        ].sort_values('date_sent')\n",
    "        \n",
    "        if len(thread_messages) < 2:\n",
    "            continue\n",
    "            \n",
    "        # Create conversation pairs\n",
    "        for i in range(len(thread_messages) - 1):\n",
    "            current_msg = thread_messages.iloc[i]\n",
    "            next_msg = thread_messages.iloc[i + 1]\n",
    "            \n",
    "            # Only create training examples where you're responding\n",
    "            if next_msg['from_recipient_id'] == your_recipient_id:\n",
    "                \n",
    "                # Build context from recent messages\n",
    "                context_start = max(0, i - 3)  # Include up to 3 previous messages\n",
    "                context_messages = thread_messages.iloc[context_start:i+1]\n",
    "                \n",
    "                # Format the conversation context\n",
    "                conversation_context = []\n",
    "                for _, msg in context_messages.iterrows():\n",
    "                    sender_name = \"You\" if msg['from_recipient_id'] == your_recipient_id else \"Other\"\n",
    "                    conversation_context.append(f\"{sender_name}: {msg['body']}\")\n",
    "                \n",
    "                # Create training example\n",
    "                training_example = {\n",
    "                    'instruction': \"\\\\n\".join(conversation_context),\n",
    "                    'response': next_msg['body'],\n",
    "                    'thread_id': thread_id,\n",
    "                    'timestamp': next_msg['date_sent']\n",
    "                }\n",
    "                \n",
    "                # Add relationship context if needed\n",
    "                involves_blocked = current_msg['involves_blocked_contact'] or next_msg['involves_blocked_contact']\n",
    "                sender_blocked = current_msg['sender_blocked'] or next_msg['sender_blocked'] \n",
    "                recipient_blocked = current_msg['recipient_blocked'] or next_msg['recipient_blocked']\n",
    "                \n",
    "                training_example = add_relationship_context(\n",
    "                    training_example, \n",
    "                    involves_blocked=involves_blocked,\n",
    "                    sender_blocked=sender_blocked, \n",
    "                    recipient_blocked=recipient_blocked\n",
    "                )\n",
    "                \n",
    "                training_data.append(training_example)\n",
    "    \n",
    "    print(f\"Created {len(training_data)} training examples\")\n",
    "    \n",
    "    # Show breakdown by relationship status\n",
    "    blocked_examples = [ex for ex in training_data if ex.get('metadata', {}).get('relationship_context')]\n",
    "    print(f\"Examples involving blocked contacts: {len(blocked_examples)} ({len(blocked_examples)/len(training_data)*100:.1f}%)\")\n",
    "    \n",
    "    return training_data\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Run Inclusive Training Data Creation\n",
    "Create training data that includes ALL your conversations:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive training data including blocked contacts\n",
    "inclusive_training_data = create_inclusive_training_data(your_recipient_id=2)\n",
    "\n",
    "print(f\"\\\\nSample training example with blocked contact context:\")\n",
    "blocked_examples = [ex for ex in inclusive_training_data if ex.get('metadata', {}).get('relationship_context')]\n",
    "if blocked_examples:\n",
    "    example = blocked_examples[0]\n",
    "    print(f\"Instruction: {example['instruction'][:200]}...\")\n",
    "    print(f\"Response: {example['response'][:100]}...\")\n",
    "    print(f\"Metadata: {example.get('metadata', {})}\")\n",
    "\n",
    "print(f\"\\\\nTraining data breakdown:\")\n",
    "print(f\"Total examples: {len(inclusive_training_data)}\")\n",
    "print(f\"Examples with blocked contacts: {len(blocked_examples)}\")\n",
    "print(f\"Regular examples: {len(inclusive_training_data) - len(blocked_examples)}\")\n",
    "\n",
    "# Optional: Save to file for later use\n",
    "import json\n",
    "with open('inclusive_training_data.json', 'w') as f:\n",
    "    json.dump(inclusive_training_data, f, indent=2)\n",
    "    \n",
    "print(f\"\\\\nSaved training data to 'inclusive_training_data.json'\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Multi-Person Communication Style Analysis\n",
    "Analyze how different people communicate with you and how you adapt your style:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_all_communication_styles(messages_df, recipients_df, min_messages=50):\n",
    "    \"\"\"\n",
    "    Analyze communication styles for all frequent contacts\n",
    "    \"\"\"\n",
    "    # Get recipient names for better readability\n",
    "    recipient_lookup = recipients_df.set_index('_id')['profile_given_name'].fillna('Unknown').to_dict()\n",
    "    \n",
    "    communication_styles = {}\n",
    "    \n",
    "    # Analyze each frequent contact\n",
    "    frequent_contacts = messages_df['from_recipient_id'].value_counts()\n",
    "    frequent_contacts = frequent_contacts[frequent_contacts >= min_messages]\n",
    "    \n",
    "    print(f\"Analyzing communication styles for {len(frequent_contacts)} frequent contacts...\")\n",
    "    \n",
    "    for recipient_id in frequent_contacts.index:\n",
    "        contact_messages = messages_df[messages_df['from_recipient_id'] == recipient_id]\n",
    "        \n",
    "        # Analyze their style\n",
    "        style = {\n",
    "            'name': recipient_lookup.get(recipient_id, f'Contact_{recipient_id}'),\n",
    "            'total_messages': len(contact_messages),\n",
    "            'avg_message_length': contact_messages['body'].str.len().mean(),\n",
    "            'message_length_std': contact_messages['body'].str.len().std(),\n",
    "            'burst_patterns': analyze_message_bursts(contact_messages),\n",
    "            'preferred_times': analyze_timing_patterns(contact_messages),\n",
    "            'emoji_usage': analyze_emoji_usage(contact_messages),\n",
    "            'response_speed': analyze_response_patterns(contact_messages, messages_df)\n",
    "        }\n",
    "        \n",
    "        # Classify communication style\n",
    "        style['style_type'] = classify_communication_style(style)\n",
    "        \n",
    "        communication_styles[recipient_id] = style\n",
    "    \n",
    "    return communication_styles\n",
    "\n",
    "def classify_communication_style(style_data):\n",
    "    \"\"\"\n",
    "    Classify someone's communication style based on their patterns\n",
    "    \"\"\"\n",
    "    avg_length = style_data['avg_message_length']\n",
    "    burst_freq = style_data['burst_patterns']['burst_frequency']\n",
    "    avg_burst_size = style_data['burst_patterns']['avg_burst_size']\n",
    "    \n",
    "    if burst_freq > 0.4 and avg_burst_size > 3:\n",
    "        if avg_length < 50:\n",
    "            return \"rapid_burst_chatter\"  # Many short messages in quick succession\n",
    "        else:\n",
    "            return \"verbose_burst_chatter\"  # Multiple longer messages in succession\n",
    "    elif avg_length > 200:\n",
    "        return \"lengthy_texter\"  # Long, detailed messages\n",
    "    elif avg_length < 30:\n",
    "        return \"concise_texter\"  # Short, to-the-point messages\n",
    "    elif burst_freq > 0.2:\n",
    "        return \"moderate_burst_chatter\"  # Some bursting behavior\n",
    "    else:\n",
    "        return \"balanced_communicator\"  # Balanced approach\n",
    "\n",
    "def analyze_emoji_usage(messages):\n",
    "    \"\"\"\n",
    "    Analyze emoji usage patterns\n",
    "    \"\"\"\n",
    "    import re\n",
    "    \n",
    "    emoji_pattern = re.compile(r'[\\\\U0001F600-\\\\U0001F64F\\\\U0001F300-\\\\U0001F5FF\\\\U0001F680-\\\\U0001F6FF\\\\U0001F1E0-\\\\U0001F1FF\\\\U00002702-\\\\U000027B0\\\\U000024C2-\\\\U0001F251]+')\n",
    "    \n",
    "    total_messages = len(messages)\n",
    "    messages_with_emojis = messages['body'].str.contains(emoji_pattern, regex=True, na=False).sum()\n",
    "    \n",
    "    return {\n",
    "        'emoji_frequency': messages_with_emojis / total_messages if total_messages > 0 else 0,\n",
    "        'messages_with_emojis': messages_with_emojis,\n",
    "        'total_messages': total_messages\n",
    "    }\n",
    "\n",
    "def analyze_timing_patterns(messages):\n",
    "    \"\"\"\n",
    "    Analyze when someone typically sends messages\n",
    "    \"\"\"\n",
    "    messages['hour'] = pd.to_datetime(messages['date_sent'], unit='ms').dt.hour\n",
    "    \n",
    "    hour_distribution = messages['hour'].value_counts().sort_index()\n",
    "    peak_hours = hour_distribution.nlargest(3).index.tolist()\n",
    "    \n",
    "    return {\n",
    "        'peak_hours': peak_hours,\n",
    "        'hour_distribution': hour_distribution.to_dict(),\n",
    "        'night_owl': hour_distribution[22:].sum() + hour_distribution[:6].sum() > len(messages) * 0.3,\n",
    "        'early_bird': hour_distribution[6:10].sum() > len(messages) * 0.3\n",
    "    }\n",
    "\n",
    "def analyze_response_patterns(contact_messages, all_messages):\n",
    "    \"\"\"\n",
    "    Analyze how quickly someone responds\n",
    "    \"\"\"\n",
    "    # This is a simplified version - you could make it more sophisticated\n",
    "    response_times = []\n",
    "    \n",
    "    for thread_id in contact_messages['thread_id'].unique():\n",
    "        thread_msgs = all_messages[all_messages['thread_id'] == thread_id].sort_values('date_sent')\n",
    "        \n",
    "        for i in range(len(thread_msgs) - 1):\n",
    "            current_msg = thread_msgs.iloc[i]\n",
    "            next_msg = thread_msgs.iloc[i + 1]\n",
    "            \n",
    "            # If this contact is responding to someone else\n",
    "            if (current_msg['from_recipient_id'] != contact_messages['from_recipient_id'].iloc[0] and \n",
    "                next_msg['from_recipient_id'] == contact_messages['from_recipient_id'].iloc[0]):\n",
    "                \n",
    "                response_time = next_msg['date_sent'] - current_msg['date_sent']\n",
    "                response_times.append(response_time)\n",
    "    \n",
    "    if response_times:\n",
    "        avg_response_time = np.mean(response_times) / (1000 * 60)  # Convert to minutes\n",
    "        return {\n",
    "            'avg_response_time_minutes': avg_response_time,\n",
    "            'quick_responder': avg_response_time < 30,  # Responds within 30 minutes on average\n",
    "            'total_responses_analyzed': len(response_times)\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            'avg_response_time_minutes': None,\n",
    "            'quick_responder': False,\n",
    "            'total_responses_analyzed': 0\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Adaptive Training Data Creation\n",
    "Create training examples that capture how you adapt to different communication styles:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_adaptive_training_data(messages_df, recipients_df, communication_styles, your_recipient_id=2):\n",
    "    \"\"\"\n",
    "    Create training data that captures how you adapt to different communication styles\n",
    "    \"\"\"\n",
    "    training_data = []\n",
    "    \n",
    "    print(\"Creating adaptive training examples...\")\n",
    "    \n",
    "    # Group by thread and create conversations\n",
    "    for thread_id in messages_df['thread_id'].unique():\n",
    "        thread_messages = messages_df[\n",
    "            messages_df['thread_id'] == thread_id\n",
    "        ].sort_values('date_sent')\n",
    "        \n",
    "        if len(thread_messages) < 2:\n",
    "            continue\n",
    "            \n",
    "        # Identify the other person in this conversation\n",
    "        other_participants = thread_messages[\n",
    "            thread_messages['from_recipient_id'] != your_recipient_id\n",
    "        ]['from_recipient_id'].unique()\n",
    "        \n",
    "        if len(other_participants) != 1:  # Skip group chats for now\n",
    "            continue\n",
    "            \n",
    "        other_person_id = other_participants[0]\n",
    "        other_person_style = communication_styles.get(other_person_id, {})\n",
    "        \n",
    "        # Create conversation pairs\n",
    "        for i in range(len(thread_messages) - 1):\n",
    "            current_msg = thread_messages.iloc[i]\n",
    "            next_msg = thread_messages.iloc[i + 1]\n",
    "            \n",
    "            # Only create training examples where you're responding\n",
    "            if next_msg['from_recipient_id'] == your_recipient_id:\n",
    "                \n",
    "                # Build context with style awareness\n",
    "                context_start = max(0, i - 4)  # Include more context for style adaptation\n",
    "                context_messages = thread_messages.iloc[context_start:i+1]\n",
    "                \n",
    "                # Format conversation with style indicators\n",
    "                conversation_context = []\n",
    "                for _, msg in context_messages.iterrows():\n",
    "                    if msg['from_recipient_id'] == your_recipient_id:\n",
    "                        sender_name = \"You\"\n",
    "                    else:\n",
    "                        sender_name = other_person_style.get('name', 'Other')\n",
    "                        # Add style indicator for the other person's messages\n",
    "                        style_type = other_person_style.get('style_type', 'unknown')\n",
    "                        if style_type in ['rapid_burst_chatter', 'verbose_burst_chatter']:\n",
    "                            sender_name += \" (burst chatter)\"\n",
    "                        elif style_type == 'lengthy_texter':\n",
    "                            sender_name += \" (lengthy texter)\"\n",
    "                        elif style_type == 'concise_texter':\n",
    "                            sender_name += \" (concise texter)\"\\n                    \\n                    conversation_context.append(f\"{sender_name}: {msg['body']}\")\\n                \\n                # Create enhanced training example\\n                training_example = {\\n                    'instruction': \"\\\\n\".join(conversation_context),\\n                    'response': next_msg['body'],\\n                    'thread_id': thread_id,\\n                    'timestamp': next_msg['date_sent'],\\n                    'other_person_style': other_person_style.get('style_type', 'unknown'),\\n                    'other_person_name': other_person_style.get('name', 'Unknown'),\\n                    'adaptation_context': create_adaptation_context(current_msg, next_msg, other_person_style)\\n                }\\n                \\n                training_data.append(training_example)\\n    \\n    print(f\"Created {len(training_data)} adaptive training examples\")\\n    \\n    # Show breakdown by communication styles\\n    style_breakdown = {}\\n    for example in training_data:\\n        style = example['other_person_style']\\n        style_breakdown[style] = style_breakdown.get(style, 0) + 1\\n    \\n    print(\"\\\\nTraining examples by communication style:\")\\n    for style, count in sorted(style_breakdown.items(), key=lambda x: x[1], reverse=True):\\n        print(f\"  {style}: {count} examples ({count/len(training_data)*100:.1f}%)\")\\n    \\n    return training_data\\n\\ndef create_adaptation_context(current_msg, your_response, other_person_style):\\n    \"\"\"Create context about how you're adapting to their communication style\"\"\"\\n    adaptations = []\\n    \\n    other_style = other_person_style.get('style_type', 'unknown')\\n    other_length = len(current_msg['body'])\\n    your_length = len(your_response['body'])\\n    \\n    # Analyze length adaptation\\n    if other_style == 'lengthy_texter' and your_length > 100:\\n        adaptations.append(\"matching_lengthy_style\")\\n    elif other_style == 'concise_texter' and your_length < 50:\\n        adaptations.append(\"matching_concise_style\")\\n    elif other_style in ['rapid_burst_chatter', 'verbose_burst_chatter']:\\n        adaptations.append(\"responding_to_burst_chatter\")\\n    \\n    # Analyze emoji adaptation\\n    other_emoji_freq = other_person_style.get('emoji_usage', {}).get('emoji_frequency', 0)\\n    your_has_emoji = bool(re.search(r'[\\\\U0001F600-\\\\U0001F64F\\\\U0001F300-\\\\U0001F5FF\\\\U0001F680-\\\\U0001F6FF\\\\U0001F1E0-\\\\U0001F1FF\\\\U00002702-\\\\U000027B0\\\\U000024C2-\\\\U0001F251]+', your_response['body']))\\n    \\n    if other_emoji_freq > 0.3 and your_has_emoji:\\n        adaptations.append(\"matching_emoji_usage\")\\n    \\n    return adaptations\\n\\ndef analyze_your_adaptation_patterns(training_data):\\n    \"\"\"Analyze how you adapt to different communication styles\"\"\"\\n    adaptation_analysis = {}\\n    \\n    for example in training_data:\\n        other_style = example['other_person_style']\\n        your_response_length = len(example['response'])\\n        adaptations = example['adaptation_context']\\n        \\n        if other_style not in adaptation_analysis:\\n            adaptation_analysis[other_style] = {\\n                'total_examples': 0,\\n                'avg_response_length': [],\\n                'adaptation_types': {},\\n                'example_responses': []\\n            }\\n        \\n        adaptation_analysis[other_style]['total_examples'] += 1\\n        adaptation_analysis[other_style]['avg_response_length'].append(your_response_length)\\n        \\n        for adaptation in adaptations:\\n            adaptation_analysis[other_style]['adaptation_types'][adaptation] = \\\\\\n                adaptation_analysis[other_style]['adaptation_types'].get(adaptation, 0) + 1\\n        \\n        # Store some example responses\\n        if len(adaptation_analysis[other_style]['example_responses']) < 3:\\n            adaptation_analysis[other_style]['example_responses'].append(example['response'][:100])\\n    \\n    # Calculate averages\\n    for style_data in adaptation_analysis.values():\\n        if style_data['avg_response_length']:\\n            style_data['avg_response_length'] = np.mean(style_data['avg_response_length'])\\n        else:\\n            style_data['avg_response_length'] = 0\\n    \\n    return adaptation_analysis\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Run Multi-Person Communication Analysis\n",
    "Analyze everyone's communication styles and create adaptive training data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "messages = pd.read_csv('/root/test/signal-flatfiles/signal.csv')\n",
    "recipients = pd.read_csv('/root/test/signal-flatfiles/recipient.csv')\n",
    "\n",
    "# Filter for text messages\n",
    "text_messages = messages[\n",
    "    (messages['body'].notna()) & \n",
    "    (messages['body'].str.len() > 5)\n",
    "].copy()\n",
    "\n",
    "print(\"Analyzing communication styles for all contacts...\")\n",
    "\n",
    "# Analyze everyone's communication styles\n",
    "all_communication_styles = analyze_all_communication_styles(text_messages, recipients, min_messages=30)\n",
    "\n",
    "print(f\"\\\\nCommunication Style Summary:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Show the most interesting communicators\n",
    "style_types = {}\n",
    "for person_id, style_data in all_communication_styles.items():\n",
    "    style_type = style_data['style_type']\n",
    "    if style_type not in style_types:\n",
    "        style_types[style_type] = []\n",
    "    style_types[style_type].append((style_data['name'], style_data['total_messages'], style_data['avg_message_length']))\n",
    "\n",
    "for style_type, people in style_types.items():\n",
    "    print(f\"\\\\n{style_type.replace('_', ' ').title()}:\")\n",
    "    for name, msg_count, avg_length in sorted(people, key=lambda x: x[1], reverse=True)[:3]:\n",
    "        print(f\"  â€¢ {name}: {msg_count} messages, avg {avg_length:.0f} chars\")\n",
    "\n",
    "# Create adaptive training data\n",
    "print(f\"\\\\nCreating adaptive training data...\")\n",
    "adaptive_training_data = create_adaptive_training_data(\n",
    "    text_messages, recipients, all_communication_styles, your_recipient_id=2\n",
    ")\n",
    "\n",
    "# Analyze your adaptation patterns\n",
    "print(f\"\\\\nAnalyzing your adaptation patterns...\")\n",
    "adaptation_analysis = analyze_your_adaptation_patterns(adaptive_training_data)\n",
    "\n",
    "print(f\"\\\\nYour Adaptation Patterns:\")\n",
    "print(\"=\"*30)\n",
    "for style, analysis in adaptation_analysis.items():\n",
    "    if analysis['total_examples'] > 10:  # Only show styles with enough examples\n",
    "        print(f\"\\\\nWhen talking to {style.replace('_', ' ')}:\")\n",
    "        print(f\"  â€¢ {analysis['total_examples']} conversations\")\n",
    "        print(f\"  â€¢ Your avg response length: {analysis['avg_response_length']:.0f} chars\")\n",
    "        if analysis['adaptation_types']:\n",
    "            print(f\"  â€¢ Common adaptations: {', '.join(analysis['adaptation_types'].keys())}\")\n",
    "        if analysis['example_responses']:\n",
    "            print(f\"  â€¢ Example response: '{analysis['example_responses'][0]}...'\")\n",
    "\n",
    "print(f\"\\\\nTotal adaptive training examples: {len(adaptive_training_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "def clean_message(text):\n",
    "    if pd.isna(text):\n",
    "        return None\n",
    "    \n",
    "    # Remove phone numbers, emails, etc.\n",
    "    text = re.sub(r'\\+?\\d{10,}', '[PHONE]', text)\n",
    "    text = re.sub(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', '[EMAIL]', text)\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "def main():\n",
    "    # Load data\n",
    "    messages = pd.read_csv('signal-flatfiles/signal.csv')\n",
    "    recipients = pd.read_csv('signal-flatfiles/recipient.csv')\n",
    "    \n",
    "    # Filter for text messages only\n",
    "    text_messages = messages[\n",
    "        (messages['type'] == 10485783) &  # Text message type\n",
    "        (messages['body'].notna()) &\n",
    "        (messages['body'].str.len() > 5)\n",
    "    ].copy()\n",
    "    \n",
    "    # Clean messages\n",
    "    text_messages['body'] = text_messages['body'].apply(clean_message)\n",
    "    text_messages = text_messages[text_messages['body'].notna()]\n",
    "    \n",
    "    # Create training data\n",
    "    training_data = []\n",
    "    \n",
    "    # Group by thread and create conversations\n",
    "    for thread_id in text_messages['thread_id'].unique():\n",
    "        thread_msgs = text_messages[\n",
    "            text_messages['thread_id'] == thread_id\n",
    "        ].sort_values('date_sent')\n",
    "        \n",
    "        if len(thread_msgs) < 3:\n",
    "            continue\n",
    "            \n",
    "        # Create conversation windows\n",
    "        for i in range(len(thread_msgs) - 2):\n",
    "            context = thread_msgs.iloc[i]['body']\n",
    "            user_msg = thread_msgs.iloc[i + 1]['body']\n",
    "            response = thread_msgs.iloc[i + 2]['body']\n",
    "            \n",
    "            training_data.append({\n",
    "                \"instruction\": \"Continue this conversation naturally\",\n",
    "                \"input\": f\"Context: {context}\\nUser: {user_msg}\",\n",
    "                \"output\": response\n",
    "            })\n",
    "    \n",
    "    # Save training data\n",
    "    with open('signal_training_data.json', 'w') as f:\n",
    "        json.dump(training_data, f, indent=2)\n",
    "    \n",
    "    print(f\"Generated {len(training_data)} training examples\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning THe Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTTrainer, SFTConfig\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = combined_dataset,\n",
    "    eval_dataset = None, # Can set up evaluation!\n",
    "    args = SFTConfig(\n",
    "        dataset_text_field = \"text\",\n",
    "        per_device_train_batch_size = 2,\n",
    "        gradient_accumulation_steps = 4, # Use GA to mimic batch size!\n",
    "        warmup_steps = 5,\n",
    "        # num_train_epochs = 1, # Set this for 1 full training run.\n",
    "        max_steps = 30,\n",
    "        learning_rate = 2e-4, # Reduce to 2e-5 for long training runs\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        report_to = \"none\", # Use this for WandB etc\n",
    "    ),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qwen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}