"""Tests for configuration management functionality.

This module tests the configuration system following the TDD approach
established in the project.
"""

from unittest.mock import patch

import pytest

from src.utils.config import Config


@pytest.mark.unit
class TestConfig:
    """Test the Config class functionality."""

    @pytest.fixture
    def clean_env(self, monkeypatch):
        """Clean environment for testing."""
        # Remove any existing environment variables
        env_vars_to_remove = [
            "OPENAI_API_KEY",
            "ANTHROPIC_API_KEY",
            "YOUR_RECIPIENT_ID",
            "DEBUG",
            "LOG_LEVEL",
            "ENABLE_IMAGE_PROCESSING",
        ]
        for var in env_vars_to_remove:
            monkeypatch.delenv(var, raising=False)
        return monkeypatch

    def test_config_initialization(self, clean_env):
        """Test config initialization with defaults."""
        config = Config()

        # Test that values are loaded (might be from .env or defaults)
        assert isinstance(config.YOUR_RECIPIENT_ID, int)
        assert isinstance(config.DEBUG, bool)
        assert isinstance(config.LOG_LEVEL, str)

    def test_config_get_with_default(self, clean_env):
        """Test getting configuration values with defaults."""
        config = Config()

        # Test with default when env var doesn't exist
        assert config.get("NONEXISTENT_KEY", "default_value") == "default_value"

        # Test with None default
        assert config.get("NONEXISTENT_KEY") is None

    def test_config_get_from_environment(self, clean_env):
        """Test getting values from environment variables."""
        # Config loads values at import time, so we need to test with already loaded values
        config = Config()

        # Test that get() retrieves class attributes
        assert config.get("YOUR_RECIPIENT_ID") == config.YOUR_RECIPIENT_ID
        assert config.get("LOG_LEVEL") == config.LOG_LEVEL

    def test_config_require_existing(self, clean_env):
        """Test require() with existing configuration value."""
        config = Config()

        # Test with values that should exist
        your_id = config.require("YOUR_RECIPIENT_ID")
        log_level = config.require("LOG_LEVEL")

        assert isinstance(your_id, int)
        assert isinstance(log_level, str)

    def test_config_require_missing(self, clean_env):
        """Test require() with missing environment variable raises error."""
        config = Config()

        with pytest.raises(ValueError, match="Required configuration 'MISSING_KEY' is not set"):
            config.require("MISSING_KEY")

    def test_has_openai_true(self, clean_env):
        """Test has_openai() returns True when API key is set."""
        config = Config()

        # Mock the class attribute directly
        with patch.object(Config, "OPENAI_API_KEY", "sk-test123456789"):
            assert config.has_openai() is True

    def test_has_openai_false(self, clean_env):
        """Test has_openai() returns False when API key is not set."""
        config = Config()

        # Mock the class attribute as None
        with patch.object(Config, "OPENAI_API_KEY", None):
            assert config.has_openai() is False

    def test_has_anthropic_true(self, clean_env):
        """Test has_anthropic() returns True when API key is set."""
        config = Config()

        # Mock the class attribute directly
        with patch.object(Config, "ANTHROPIC_API_KEY", "sk-ant-test123456789"):
            assert config.has_anthropic() is True

    def test_has_anthropic_false(self, clean_env):
        """Test has_anthropic() returns False when API key is not set."""
        config = Config()

        assert config.has_anthropic() is False

    def test_validate_creates_directories(self, clean_env, tmp_path):
        """Test that validate() creates necessary directories."""
        config = Config()

        # Mock the directory paths
        with (
            patch.object(Config, "DATA_DIR", tmp_path / "data"),
            patch.object(Config, "OUTPUT_DIR", tmp_path / "output"),
        ):
            config.validate()

            assert (tmp_path / "data").exists()
            assert (tmp_path / "output").exists()

    def test_print_status_masks_sensitive_data(self, clean_env, capsys):
        """Test that print_status() masks sensitive information."""
        config = Config()

        # Mock API keys to test masking
        with (
            patch.object(Config, "OPENAI_API_KEY", "sk-1234567890abcdef"),
            patch.object(Config, "ANTHROPIC_API_KEY", "sk-ant-abcdef123456"),
        ):
            config.print_status()

            captured = capsys.readouterr()

            # Should show configured status, not actual keys
            assert "Configured" in captured.out or "âœ…" in captured.out
            # Should not show full API keys
            assert "sk-1234567890abcdef" not in captured.out
            assert "sk-ant-abcdef123456" not in captured.out

    def test_boolean_conversion(self, clean_env):
        """Test conversion of string environment variables to booleans."""
        config = Config()

        # Test the actual boolean fields in Config
        assert isinstance(config.DEBUG, bool)
        assert isinstance(config.ENABLE_IMAGE_PROCESSING, bool)
        assert isinstance(config.ENABLE_BATCH_PROCESSING, bool)

    def test_integer_conversion(self, clean_env):
        """Test conversion of string environment variables to integers."""
        config = Config()

        # Test the actual integer fields in Config
        assert isinstance(config.YOUR_RECIPIENT_ID, int)
        assert isinstance(config.MAX_BATCH_SIZE, int)
        assert isinstance(config.API_RATE_LIMIT, int)
        assert isinstance(config.API_RATE_WINDOW, int)

    def test_dotenv_file_loading(self, clean_env, tmp_path):
        """Test that dotenv loading is attempted."""
        # The Config module loads dotenv at import time
        # We can only test that the loading mechanism exists
        config = Config()

        # Verify that Config has the expected attributes
        assert hasattr(config, "OPENAI_API_KEY")
        assert hasattr(config, "YOUR_RECIPIENT_ID")
        assert hasattr(config, "DEBUG")

    def test_config_with_missing_dotenv(self, clean_env):
        """Test config behavior when .env file is missing."""
        with patch("src.utils.config.load_dotenv") as mock_load:
            # Simulate missing .env file
            mock_load.side_effect = FileNotFoundError()

            # Should not raise error
            config = Config()
            assert config is not None

    def test_environment_precedence(self, clean_env):
        """Test that environment variables take precedence over .env file."""
        config = Config()

        # The Config class loads values at import time
        # Test that config has expected attributes
        assert hasattr(config, "YOUR_RECIPIENT_ID")
        assert hasattr(config, "LOG_LEVEL")

    def test_configuration_security(self, clean_env, capsys):
        """Test that sensitive configuration is handled securely."""
        # Set sensitive data
        clean_env.setenv("OPENAI_API_KEY", "sk-secret123456789")
        clean_env.setenv("PASSWORD", "super_secret_password")

        config = Config()

        # Ensure sensitive data is not accidentally logged
        config.print_status()
        captured = capsys.readouterr()

        # Should not contain full sensitive values
        assert "sk-secret123456789" not in captured.out
        assert "super_secret_password" not in captured.out

    @pytest.mark.parametrize(
        "key,expected_type",
        [
            ("OPENAI_API_KEY", (str, type(None))),
            ("YOUR_RECIPIENT_ID", int),  # Config converts to int
            ("DEBUG", bool),  # Config converts to bool
            ("LOG_LEVEL", str),
        ],
    )
    def test_configuration_types(self, clean_env, key, expected_type):
        """Test that configuration values have expected types."""
        config = Config()
        value = getattr(config, key, None)

        if isinstance(expected_type, tuple):
            assert isinstance(value, expected_type)
        else:
            assert isinstance(value, expected_type)


@pytest.mark.unit
class TestConfigValidation:
    """Test configuration validation functionality."""

    def test_validate_missing_required_config(self, monkeypatch):
        """Test validation with missing required configuration."""
        # Clear environment
        monkeypatch.delenv("YOUR_RECIPIENT_ID", raising=False)

        config = Config()

        # Validation should complete even with missing optional config
        config.validate()  # Should not raise error

    def test_validate_with_complete_config(self, monkeypatch, tmp_path):
        """Test validation with complete configuration."""
        config = Config()

        # Mock the paths and API key
        with (
            patch.object(Config, "DATA_DIR", tmp_path / "data"),
            patch.object(Config, "OUTPUT_DIR", tmp_path / "output"),
            patch.object(Config, "OPENAI_API_KEY", "sk-test123456789"),
        ):

            status = config.validate()

            # Should create directories
            assert (tmp_path / "data").exists()
            assert (tmp_path / "output").exists()

            # Status should show API is configured
            assert status["openai_configured"] is True

    def test_validate_directory_creation_permissions(self, monkeypatch, tmp_path):
        """Test directory creation with permission issues."""
        # Set directory in read-only location (simulated)
        readonly_dir = tmp_path / "readonly"
        readonly_dir.mkdir()
        readonly_dir.chmod(0o444)  # Read-only

        target_dir = readonly_dir / "data"
        monkeypatch.setenv("DATA_DIR", str(target_dir))

        config = Config()

        # Should handle permission errors gracefully
        try:
            config.validate()
        except PermissionError:
            # This is acceptable behavior
            pass
        finally:
            # Cleanup: restore permissions
            readonly_dir.chmod(0o755)


@pytest.mark.unit
class TestConfigSingleton:
    """Test Config singleton behavior if implemented."""

    def test_config_instance_consistency(self):
        """Test that config instances are consistent."""
        config1 = Config()
        config2 = Config()

        # Should be separate instances but behave consistently
        assert config1 is not config2  # Not a singleton in current implementation

        # But should have same behavior
        assert config1.get("NONEXISTENT", "default") == config2.get("NONEXISTENT", "default")


if __name__ == "__main__":
    pytest.main([__file__])
