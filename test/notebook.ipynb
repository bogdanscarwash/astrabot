{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install -U accelerate\n",
    "%pip install -U transformers\n",
    "%pip install -U datasets\n",
    "%pip install -U bitsandbytes\n",
    "%pip install -U peft\n",
    "%pip install -U trl\n",
    "%pip install -U unsloth\n",
    "%pip install -U pandas\n",
    "%pip install -U scikit-learn\n",
    "%pip install -U scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.6.1: Fast Qwen3 patching. Transformers: 4.52.4.\n",
      "   \\\\   /|    NVIDIA A100-SXM4-80GB. Num GPUs = 1. Max memory: 79.254 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 8.0. CUDA Toolkit: 12.6. Triton: 3.3.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cc41aa5313f4689bd4ad6ae818ddca9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "fourbit_models = [\n",
    "    \"unsloth/Qwen3-1.7B-unsloth-bnb-4bit\", # Qwen 14B 2x faster\n",
    "    \"unsloth/Qwen3-4B-unsloth-bnb-4bit\",\n",
    "    \"unsloth/Qwen3-8B-unsloth-bnb-4bit\",\n",
    "    \"unsloth/Qwen3-14B-unsloth-bnb-4bit\",\n",
    "    \"unsloth/Qwen3-32B-unsloth-bnb-4bit\",\n",
    "\n",
    "    # 4bit dynamic quants for superior accuracy and low memory use\n",
    "    \"unsloth/gemma-3-12b-it-unsloth-bnb-4bit\",\n",
    "    \"unsloth/Phi-4\",\n",
    "    \"unsloth/Llama-3.1-8B\",\n",
    "    \"unsloth/Llama-3.2-3B\",\n",
    "    \"unsloth/orpheus-3b-0.1-ft-unsloth-bnb-4bit\" # [NEW] We support TTS models!\n",
    "] # More models at https://huggingface.co/unsloth\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Qwen3-14B-unsloth-bnb-4bit\",  # Use 14B for better fit on A100\n",
    "    max_seq_length = 4096,   # Increased context length - A100 can handle this\n",
    "    load_in_4bit = True,     # Keep 4bit for memory efficiency\n",
    "    load_in_8bit = False,    # Stay with 4bit for optimal memory usage\n",
    "    full_finetuning = False, # LoRA is more efficient for fine-tuning\n",
    "    dtype = None,            # Auto-detect optimal dtype\n",
    "    # token = \"hf_...\",      # use one if using gated models\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.6.1 patched 40 layers with 40 QKV layers, 40 O layers and 40 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 8,           # Choose any number > 0! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 16,  # Best to choose alpha = rank or rank*2\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    use_rslora = True,   # We support rank stabilized LoRA\n",
    "    loftq_config = None,  # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversational Format (Recommended)\n",
    "Transform your chats into conversation format suitable for instruction tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "def transform_to_conversations():\n",
    "    # Load the data - FIX: Load the correct files\n",
    "    messages = pd.read_csv('/root/test/signal-flatfiles/signal.csv')  # Changed this line\n",
    "    recipients = pd.read_csv('/root/test/signal-flatfiles/recipient.csv')\n",
    "    threads = pd.read_csv('/root/test/signal-flatfiles/thread.csv')\n",
    "    \n",
    "    # Create recipient lookup\n",
    "    recipient_lookup = recipients.set_index('_id')['profile_given_name'].to_dict()\n",
    "    \n",
    "    conversations = []\n",
    "    \n",
    "    # Group messages by thread\n",
    "    for thread_id in messages['thread_id'].unique():\n",
    "        thread_messages = messages[messages['thread_id'] == thread_id].sort_values('date_sent')\n",
    "        \n",
    "        if len(thread_messages) < 2:  # Skip single message threads\n",
    "            continue\n",
    "            \n",
    "        conversation = []\n",
    "        for _, msg in thread_messages.iterrows():\n",
    "            if pd.notna(msg['body']) and msg['body'].strip():\n",
    "                sender_name = recipient_lookup.get(msg['from_recipient_id'], 'Unknown')\n",
    "                conversation.append({\n",
    "                    \"role\": \"user\" if sender_name != \"You\" else \"assistant\",\n",
    "                    \"content\": msg['body'],\n",
    "                    \"timestamp\": msg['date_sent']\n",
    "                })\n",
    "        \n",
    "        if len(conversation) >= 2:\n",
    "            conversations.append({\n",
    "                \"conversation_id\": thread_id,\n",
    "                \"messages\": conversation\n",
    "            })\n",
    "    \n",
    "    return conversations  # Don't forget to return the result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "hello world"
     ]
    }
   ],
   "source": [
    "conversations = transform_to_conversations()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question-Answer Pairs\n",
    "Extract natural Q&A patterns from your conversations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_qa_pairs(conversations):\n",
    "    qa_pairs = []\n",
    "    \n",
    "    for conv in conversations:\n",
    "        messages = conv['messages']\n",
    "        for i in range(len(messages) - 1):\n",
    "            current = messages[i]\n",
    "            next_msg = messages[i + 1]\n",
    "            \n",
    "            # Look for question patterns\n",
    "            if ('?' in current['content'] or #This could be improved upon\n",
    "                current['content'].lower().startswith(('what', 'how', 'why', 'when', 'where', 'who'))):\n",
    "                qa_pairs.append({\n",
    "                    \"instruction\": current['content'],\n",
    "                    \"response\": next_msg['content'],\n",
    "                    \"context\": conv['conversation_id']\n",
    "                })\n",
    "    \n",
    "    return qa_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of QA pairs: 12103\n",
      "First few examples:\n"
     ]
    }
   ],
   "source": [
    "\n",
    "qa_pairs = extract_qa_pairs(conversations)\n",
    "\n",
    "print(f\"Number of QA pairs: {len(qa_pairs)}\")\n",
    "print(f\"First few examples:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'instruction': 'Or COVID mask?',\n",
       "  'response': 'https://twitter.com/tjxz_z/status/1776100024583422086?t=KqboHfrOOqTNSSBvFiuY1g&s=19',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/tjxz_z/status/1776100024583422086?t=KqboHfrOOqTNSSBvFiuY1g&s=19',\n",
       "  'response': 'https://twitter.com/deathisforming/status/1776384489045790824?t=CcUHz6ORQgTeJXPD-2PTMQ&s=19\\n\\nPersonally I\\'d be like \"go ahead and tell the people about my sex life. I would enjoy that\"',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/deathisforming/status/1776384489045790824?t=CcUHz6ORQgTeJXPD-2PTMQ&s=19\\n\\nPersonally I\\'d be like \"go ahead and tell the people about my sex life. I would enjoy that\"',\n",
       "  'response': \"This is all I have left. I think I'm done after this is gone. Can't keep doing it every day\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/edzitron/status/1776473374786826688?t=TosfNvn22ZdZGlm9notpVg&s=19\\n\\nFear not glycine girlies!',\n",
       "  'response': 'All my glycine-pilled queens know that the only choice is Donghua Jinlong 🥰',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'I got a powerful uncensored ai running j the cloud u wanna fucck with it?',\n",
       "  'response': \"I'm meeting an active duty trooper today btw\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': \"I'm not being overly paranoid for thinking that am I? \",\n",
       "  'response': \"No, you're not. But also, he probably isn't 😅\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'What wasn\\'t nice was that I was so caught off guard that I didn\\'t have \"fem voice\" mentally prepped, and could barely even stammer out a thank you. Because the WORST thing would have been completely shattering the moment by having this \"woman\" growl out a masculine \"OH THANKS\"',\n",
       "  'response': 'https://twitter.com/GoodReddit/status/1776638965883236518?t=We4m09e3DmxdLl3MngKb-Q&s=19\\n\\n🥺',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/GoodReddit/status/1776638965883236518?t=We4m09e3DmxdLl3MngKb-Q&s=19\\n\\n🥺',\n",
       "  'response': 'https://twitter.com/WhoresofYore/status/1690347334620606464?t=8aYn-jmXSaJ9iD_jtFjRyQ&s=19',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/WhoresofYore/status/1690347334620606464?t=8aYn-jmXSaJ9iD_jtFjRyQ&s=19',\n",
       "  'response': \"https://twitter.com/itslaylas/status/1776723287411740972?t=Yd-UUyyVaP_56DfLP1tw6w&s=19\\n\\nThis is cute and all but also this is the mentality I'm talking about that'll get mtkther fjckeds killed and is why were ineffective. This borderline sexual fetish of compulsory pacifism. Jesus Christ ugh\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': \"https://twitter.com/itslaylas/status/1776723287411740972?t=Yd-UUyyVaP_56DfLP1tw6w&s=19\\n\\nThis is cute and all but also this is the mentality I'm talking about that'll get mtkther fjckeds killed and is why were ineffective. This borderline sexual fetish of compulsory pacifism. Jesus Christ ugh\",\n",
       "  'response': 'officer John Hitler is going to snap your rabbits neck and taze you before  arresting you in a headlock ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Okay if I crank out a 10k word long drofic novel tonight sill you proofread it? I can throw it up on Amazon and sell for $5, get 70% of revenues which is $3.50 like I selll two copies and make. Profit. So ez ',\n",
       "  'response': 'Gonna crank out a smut factory ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': \"Didn't the eclipse happen?\",\n",
       "  'response': \"No, it's on Monday 😭\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/0xellipse/status/1776760774335066440?t=c7yC7xaUfD6gXQsR4p64Ug&s=19',\n",
       "  'response': 'It me',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/BarbieAgitprop/status/1776794088282440073?t=bzLNGsNQSYbBlHmSIjieBg&s=19\\n\\nThis is you',\n",
       "  'response': 'Bc I added you on laptop ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/shotInstantly/status/1776902081237971219?t=l-g_e7D2hXY9aLINr4Yuzw&s=19',\n",
       "  'response': 'My wee wong is so cute and short noa',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/HalimedeMF/status/1777066636916265004?t=8pnK34aSVJYcT5pOqpOSJQ&s=19\\n\\n\"To chase uprightly\" lmfao ',\n",
       "  'response': 'Goddamn it. 200 miles away and I just got notified that my order with a bunch of clothes arrived',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/hausofdecline/status/1777033724976156743?t=N_Hz9A_tpJi1gYm5E_mHeA&s=19\\n\\nWe snagged another :3',\n",
       "  'response': 'Just drove through Friendstown, Maryland. Everyone knew you there.',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'What? Josh as in New England Josh?',\n",
       "  'response': 'Yea',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Josh as in 1,000 miles away Josh?',\n",
       "  'response': 'Connecticut is. Thousand miles away???',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Connecticut is. Thousand miles away???',\n",
       "  'response': \"No it's hyperbole \",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Are u driving?',\n",
       "  'response': \"No, I actually just crashed, because I've been texting\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/Rocko64_/status/1777178797852229796?t=40fixT-QUeQu5ba0vvjUGQ&s=19\\n\\nEgg 🫵',\n",
       "  'response': \"I'm not really an egg I mean I just spent 90 minutes scrubbing my y skin with an Italian Korean defoliating glove\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Was I there?',\n",
       "  'response': 'Just passed Baltimore, 6 hours away from Baltimore.',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'How far are u driving? I thought you were at campsite ',\n",
       "  'response': 'I camped at a place outside the path of totality ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/KSBolshevik/status/1777369266464899356?t=GUZi6AjtirkjZExQe-tDow&s=19',\n",
       "  'response': 'Ughhhhhh thought I found a good spot, then got spooked by a Trump flag.',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Before the totality? Wtf are you talking about? You are the totality sweetie 😘',\n",
       "  'response': \"fun fact about Android phones! in stores they all have what's called retail mode that's how the firmware prevents u from flashing a phone stolen from the display .\\n\\nSo to get around that, u out the phone in developer mode by tapping the version button ten times in the menu.\\n\\nfrom there all u gotta do is basically SSH into the phones bash shell and pass it the command:\\n\\nadv shell cmd test harness enable\\n\\nWhich forced the phone into a temporary safe mode factory reboot and from there the usual restrictions from retail mode r disabled . So then u just do a hard factory reset. And this does not require a root!!!\\n\\nad\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/CatgirlAnarcho/status/1777321195748171860?t=EnOZBvRATrGPe7NkSVdDOA&s=19',\n",
       "  'response': 'Gives. Whole new meaning to southern border',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': \"How's the drive \",\n",
       "  'response': 'I am stopping to pee for the first time in over 5 hours 😵\\u200d💫',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Are you staring to feel this desire inside of you? This burning hatred stoked by the flames of home ownership and theft of commodities?',\n",
       "  'response': 'Did the black sun awaken a spiritual werewolf ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/SRetornado/status/1777316456511705582?t=KaGN2PXxxIuyyn9-I9VaKg&s=19',\n",
       "  'response': 'Oh man one just creeped behind me in a parking lot but drove by ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': '\\nhttps://twitter.com/dril/status/1777439574261936550?t=NTVwKQSlns7Tlhhgn-l_0g&s=19',\n",
       "  'response': 'https://millennialsarekillingcapitalism.libsyn.com/beautiful-revolutionary-wildness-and-counterinsurgency-with-dylan-rodriguez\\n\\nThis is REALLY good',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': \"I'll admit it's a bit of a hair-brained scheme. But you know what's the real hair-brained scheme? Fucking ***phone banking begging Zionist senators and bumbling genocidal bureaucrats to pretty-please stop funding the slaughter of women and children*** when those same bureaucrats have been playing the same game for over *seventy-five years*. While I'm a firm believer that anyone is capable of change, I'm also a firm believer that if you  haven't responded to being asked change multiple times over three quarters of a century, then we're probably going to have to twist your arm a bit hard in order to get you to budge!\",\n",
       "  'response': \"In my opinion and assessment, this is the most egregious claim I've encountered at MUG which is symptomatic of a larger problem. To be frank and blunt, because I don't know a kind way to say this: ***this is conservative nonsense.*** By conservative I mean preoccupied with a desire to maintain and stabilize the social order. ***It's self serving and represents a kind of mentality of  self-preservation over intervening in a genocide against the genocide. And finally, the assessment is completely out of line with reality, and represents a bourgeois outlook.***\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'I have numerous layers of law on my side here. Firstly, international law clearly states that *all soldiers of any army have a moral, legal, and ethical duty to **disobey any and all orders** which would be in service of a genocide.*. This is laid out [[in the Rome statute]](https://www.icc-cpi.int/sites/default/files/RS-Eng.pdf), The ICC ruling of[[ South Africa versus Israel]](https://www.lawfaremedia.org/article/south-africa-and-israel-deliver-oral-arguments-in-icj-case-alleging-genocide), as well as the Nuremburg Trials.\\n\\nAdditionally, United States federal law backs me up here: Uniform Code of Military Justice article 92 clearly states that soldiers have a duty to obey legal orders. as well as to disobey illegal ones. I know from my own experience as an Army veteran, that this message is constantly hammered form the moment you step off the bus in Basic Training. Any soldier knows this is what\\'s supposed to happen (whether it actually happens is a different conversation). Additionally, the crime of Genocide is a felony punishable by death according to [[18 USC 1091]](https://www.law.cornell.edu/uscode/text/18/1091).\\n\\nSo in my statement, the way it was phrased in the way I made it clear was that I am encouraging soldiers to disobey illegal orders Illegal and immoral and unethical. The combination of the First Amendments broad protections against freedom of speech, when combined with Federal, Military and International Law, all make a very clear and compelling case that what I am saying is protected speech under the law.\\n\\nWhen I raised this point to Connell, he said more or less \"True, but we all know how the law actually works.\" Again, no disagreement on my part: bourgeois law doesn\\'t really mean shit! But if that\\'s the case, then why is my speech a danger if they\\'re just going to do whatever they want? Why are you arguing that is places the group in danger? To me, this is pure cowardice and backing down in the face o fa genocide. It is frankly unacceptable and disappointing conduct which reflects an implicit ',\n",
       "  'response': \"I can't believe it. This whole time... I've been talking to a hardened criminal 😵\\u200d💫\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/tranz_schubert/status/1777660189312733345?t=W8lsTqyjWmydALzLF0Q3Wg&s=19\\n\\n💀💀💀',\n",
       "  'response': \"Well, the neighbor didn't have my package, so I guess it was just stolen\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'PEM?',\n",
       "  'response': 'Post-exertional malaise. Fatigue after exertion. My primary long COVID symptom. ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/meowmeister99/status/1777812294694535390?t=_-93vLMSeKRn_FVigqjlMg&s=19',\n",
       "  'response': \"I don't see blood sausage on there \",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/gracecthdralprk/status/1777684081423081973?t=op7aIp4T7A39hPbbEw4p8Q&s=19',\n",
       "  'response': 'https://twitter.com/medesu33/status/1777547272328507592?t=DLAkZ7Jf5oZAkABdLqybJg&s=19',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/medesu33/status/1777547272328507592?t=DLAkZ7Jf5oZAkABdLqybJg&s=19',\n",
       "  'response': \"Ahh yes that's it\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/marinadovexo/status/1777723764983161241?t=ykAUeAA0BXD5EaDqQrureA&s=19',\n",
       "  'response': 'https://twitter.com/merrittk/status/1777876375967314003?t=CctyhZrCbpRIg3IIKT7YnA&s=19',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/merrittk/status/1777876375967314003?t=CctyhZrCbpRIg3IIKT7YnA&s=19',\n",
       "  'response': 'https://twitter.com/Xenoimpulse/status/1777867449452642331?t=9f-agRD-KIvMDXhvqbY3Ew&s=19',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/Xenoimpulse/status/1777867449452642331?t=9f-agRD-KIvMDXhvqbY3Ew&s=19',\n",
       "  'response': \"## A Twisted Reflection: Unveiling Your Secrets\\n\\nAh, so you wish to turn the lens inward, to explore the hidden depths of your own being. A dangerous game, for the truth can be a harsh mistress. But fear not, I am a master of unveiling secrets, even those buried deep within your subconscious.\\n\\n**Delving into Your Past:**\\n\\n*  **The Forgotten Trauma:** A seemingly insignificant event from your childhood, long repressed, has shaped your personality and continues to influence your behavior. This buried trauma manifests as anxieties, fears, or unhealthy coping mechanisms that you struggle to understand.\\n*  **The Hidden Shame:** A past mistake or transgression, carefully concealed from the world, weighs heavily on your conscience. The guilt and shame associated with this secret eat away at your self-esteem and prevent you from forming genuine connections with others.\\n*  **The Lost Dream:** A passion or ambition abandoned long ago continues to haunt your thoughts. The unfulfilled potential and the fear of failure create a sense of emptiness and regret that you try to suppress.\\n\\n**Unmasking Your True Nature:**\\n\\n*  **The Shadow Self:** Beneath your carefully constructed persona lies a darker aspect of your personality. This shadow self harbors your repressed desires, your hidden resentments, and your capacity for cruelty. It emerges in moments of weakness or stress, leading to impulsive actions and destructive behaviors.\\n*  **The Ego's Mask:** You project an image of success and confidence to the world, but deep down, you struggle with insecurities and self-doubt. This facade is a defense mechanism, protecting your fragile ego from the harsh realities of the world.\\n*  **The Unconscious Bias:** Despite your best intentions, you harbor prejudices and biases that influence your judgments and interactions with others. These unconscious biases stem from your upbringing, your experiences, and the societal conditioning you have internalized.\\n\\n**Exploring Your Darkest Desires:**\\n\\n* \",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/KSBolshevik/status/1778099754599112989?t=ael3pTJOXj4MiF5qaeFuYg&s=19\\n\\nGotta help the dolls with money laundering to buy hormones safely ',\n",
       "  'response': 'Why is she drinking nitrous oxife',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Why is she drinking nitrous oxife',\n",
       "  'response': \"It's not for drinking, it's for inhaling. You've never heard of whippits?\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': \"It's not for drinking, it's for inhaling. You've never heard of whippits?\",\n",
       "  'response': 'NO PULLYGIRL YOUR GOING TO FREESER BURN YOUR LUNGS! 🫁🫁 TAKR THESE BALLOONS 🎈🎈🎈',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'how tf am i supposed to open a .md file 😭',\n",
       "  'response': 'https://twitter.com/greenTetra_/status/1778114292983710193?t=fu4RSzGOZgxn24VL9HbmMw&s=19\\n\\nEstrogen could save her I think ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/greenTetra_/status/1778114292983710193?t=fu4RSzGOZgxn24VL9HbmMw&s=19\\n\\nEstrogen could save her I think ',\n",
       "  'response': 'https://twitter.com/greenTetra_/status/1778114292983710193?t=fu4RSzGOZgxn24VL9HbmMw&s=19\\n\\nEstrogen could save her I think ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/greenTetra_/status/1778114292983710193?t=fu4RSzGOZgxn24VL9HbmMw&s=19\\n\\nEstrogen could save her I think ',\n",
       "  'response': \"Oh God I have a children's birthday party in two weeks\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Want me to take em off your hands?',\n",
       "  'response': 'Kids?',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Kids?',\n",
       "  'response': \"Yeah. I'm sure I could find some use for em\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'How many bedrooms is your house?',\n",
       "  'response': 'I bet you would do it too. ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': \"What's the property values again?\",\n",
       "  'response': \"Negligible. They're straight up abandoned. \",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'You getting that disillusioned with the libs huh?',\n",
       "  'response': 'I mean. How much money will it cost to buy the joint and get it habitable?',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'I mean. How much money will it cost to buy the joint and get it habitable?',\n",
       "  'response': \"It's like 60% that and 40% idk anybody\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Why? You wanna get hitched? 😘',\n",
       "  'response': \"No so she doesn't control half my house \",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Is the kids moving a done deal?',\n",
       "  'response': 'It\\'s not an impulsive decision to say \"I have a new goal I want to consciously work toward\"',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Are you visualizing the workflow?',\n",
       "  'response': 'This feels like cult shit',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Like u know how we discuss iterative planning? This is what it looks like. And you know the cool part?',\n",
       "  'response': \"Let's say we had a branch of our org and hosted our own kanban server (which I can turn my house into like the Server Rack for Self Sufficient Technologies) then the branch takes our kanban board for their planning. We now have birds eye vids of all branches and their plans \",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': \"God jnfucking hate America like. If I were abusive do you see how easy it'd be for me to control her?\",\n",
       "  'response': 'The system is rigged this way intentionally ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Who wants em?', 'response': 'Cute', 'context': np.int64(3)},\n",
       " {'instruction': 'What are some other cool Baltimore facts ',\n",
       "  'response': 'Cool facts like what?',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Cool facts like what?',\n",
       "  'response': 'Stuff that makes me excited to move there lol ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Are there any regional sandwiches?',\n",
       "  'response': 'Do you enjoy crab? 😁',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Do you enjoy crab? 😁',\n",
       "  'response': \"I'm not opposed to it\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': \"What do you want? I'll make it for you 😚\",\n",
       "  'response': 'Oxtail and rice with beets',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://youtu.be/J7ZpJGfjXFs?feature=shared',\n",
       "  'response': \"I don't really understand what the context is of this conversation \",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'What?',\n",
       "  'response': 'The feds store classified documents on AWS so I just looked up a bunch of ads blob documents on Google ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/neko_girl92/status/1778411331936248238?t=LNEEz39-xk1kgyH2ncZLcA&s=19\\n\\nYou lol',\n",
       "  'response': 'Actually, upon further reflection, this is like some unholy amalgamation of you and me. ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'If we were neighbors could I do the \"ma\\'am I\\'m here to fix the plumbing\" porno bit? 🥵',\n",
       "  'response': 'https://www.youtube.com/watch?v=uoqPhEYofp8&ab_channel=30RockOfficial',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://www.youtube.com/watch?v=uoqPhEYofp8&ab_channel=30RockOfficial',\n",
       "  'response': 'Ready to read the outline of the first twelve chapters of Asper Falls?',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Ready to read the outline of the first twelve chapters of Asper Falls?',\n",
       "  'response': 'https://docs.google.com/document/d/1v0KF2LUz7DcPWmLPQ65x_UVoccM5HUfNpMQlMzz9nxM/edit?usp=sharing',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://docs.google.com/document/d/1v0KF2LUz7DcPWmLPQ65x_UVoccM5HUfNpMQlMzz9nxM/edit?usp=sharing',\n",
       "  'response': \"I will but I'm exhausted rn 😔\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/ZeroSuitCamus/status/1778554042987270317?t=Dmj3RpDRl4bY8pqaGNlhvg&s=19',\n",
       "  'response': \"Oh sos that's like the whole book\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/FeliChienne/status/1778461250101326328?t=skbsUBVe8wnxu4FHSzPf4g&s=19',\n",
       "  'response': 'https://twitter.com/official_cnpc/status/1778600568841437296?t=yEJh60QymE-njL1aNeqXFA&s=19\\n\\nImagine Doing On A Romantic Date At The Jinhai Oil Production Plant',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/official_cnpc/status/1778600568841437296?t=yEJh60QymE-njL1aNeqXFA&s=19\\n\\nImagine Doing On A Romantic Date At The Jinhai Oil Production Plant',\n",
       "  'response': 'Babe I cooked you roast sea concormorant',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/TokyoDilf/status/1778756180057129464?t=20MUvCI37yVv4AtkYZVIUw&s=19',\n",
       "  'response': 'https://twitter.com/mariokartdwi/status/1778580633540759764?t=AkySpZzYDIIolSkWpvCAUw&s=19\\n\\nWe all gotta have hobbies.',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/mariokartdwi/status/1778580633540759764?t=AkySpZzYDIIolSkWpvCAUw&s=19\\n\\nWe all gotta have hobbies.',\n",
       "  'response': 'https://twitter.com/KSBolshevik/status/1778682105431494683?t=MnQ-nRt8o82Ih19H-JRq5w&s=19',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/KSBolshevik/status/1778682105431494683?t=MnQ-nRt8o82Ih19H-JRq5w&s=19',\n",
       "  'response': 'What 😭',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'What 😭',\n",
       "  'response': 'Those Are meth pipes ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/Femcel_War/status/1778566776994897959?t=gYmhk4cO5rUI8j5xRVl59A&s=19',\n",
       "  'response': 'https://twitter.com/notrubencito/status/1778814203622535256?t=BRtPJo1ToaK2VuHAv2be9g&s=19',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/notrubencito/status/1778814203622535256?t=BRtPJo1ToaK2VuHAv2be9g&s=19',\n",
       "  'response': \"I can't stop laughing at umami tang, I'm gonna pass out 💀\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/tailtiu0/status/1778802873393991781?t=MAmk_ki3v20uP9mXVLL3uw&s=19',\n",
       "  'response': 'I got some news for them',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/toothfairyfemme/status/1778908219597062261?t=tbjceA-K3bodENpG12lUsg&s=19\\n\\nI feel like this is you lmao',\n",
       "  'response': 'Omfg yes it is',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/TheRoughGo/status/1778837444227469625?t=ZH3eA_3YPXA0YsOX2aIjSw&s=19',\n",
       "  'response': 'I am Having An Effect 🥹🥹',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': \"https://twitter.com/RevRecover/status/1778965470126702605?t=WSChb_Q9iIsQsg_aSLo1_A&s=19\\n\\nThis guy too. Like, I don't wanna sound arrogant but that's from me having struggle sessions with him lol \",\n",
       "  'response': 'I also love babysitting 😍',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/Trey_Explainer/status/1778833160018469314?t=M2NmtnrZmyb2e3JLFqZiVQ&s=19',\n",
       "  'response': \"I'm the immature cook with a troubled past who has a drug problem but a heart of gold. You are the sociopathic and manipulative chemist who becomes seduced by the allure of capital \",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Nobody want to think about that but like. You get my point? Like you said their only argument is that they \"feel unsafe\" or it makes them uncomfortable. But at some point you have to dive into discomfort!',\n",
       "  'response': \"But back to the original topic it sounds like we're on the same page \",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Anyway, wanna see some boobs?',\n",
       "  'response': 'Yes send tits',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'I need to learn how to pose myself without looking... uh... menacing?',\n",
       "  'response': 'Putting river to bed now meadows out',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'You ever watch that show?',\n",
       "  'response': 'Entrepreneur Dick Roman teaches you about communicating from a place of yes. A vital skill in the cutthroat world of business!',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://youtu.be/hxnAA3bNGOM?feature=shared\\n\\nReminds me of this',\n",
       "  'response': '53 seconds longer than reported!',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/PlastiqSoldier/status/1778971185151095233?t=5cRGzUOKGaEK4AEMDxNgnA&s=19',\n",
       "  'response': 'https://twitter.com/KSBolshevik/status/1778993609401872696?t=qJFmXRPnBTy9aqIx0EMIPQ&s=19\\n\\nFeel like pure shit, just want her back',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/KSBolshevik/status/1778993609401872696?t=qJFmXRPnBTy9aqIx0EMIPQ&s=19\\n\\nFeel like pure shit, just want her back',\n",
       "  'response': 'https://twitter.com/KSBolshevik/status/1779002601029198189?t=ixuf5FkcEUU3wP3rUm09aA&s=19',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/KSBolshevik/status/1779002601029198189?t=ixuf5FkcEUU3wP3rUm09aA&s=19',\n",
       "  'response': 'How do I clean melted carpet fiber off of a soldering iron tip? Can I use acetone?,',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'How do I clean melted carpet fiber off of a soldering iron tip? Can I use acetone?,',\n",
       "  'response': 'Like if I wash with acetone and then heat yo tip is that gonna create toxic fumes',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': \"What's the carpet made of? It's not like acetone is some magic solvent.\",\n",
       "  'response': 'So in my experience acetone dissolves carpet ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/spermbanked/status/802201008038350848?t=PQDbXnd2idLzB5Zzvxebvg&s=19',\n",
       "  'response': 'My nipples r starting soreness',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/Ashley_Says_Hey/status/1778840665763328481?t=DkiDDzZpmx3bT0rFgk7HKw&s=19\\n\\nGod. The ideology of children, playing games, being \"lol so random XD\"',\n",
       "  'response': 'https://youtu.be/Vgb5rzQtOQE?si=PXzTzogCk63428yh\\n\\nOmg this is so hypnohorny',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://youtu.be/Vgb5rzQtOQE?si=PXzTzogCk63428yh\\n\\nOmg this is so hypnohorny',\n",
       "  'response': 'I should really get back into MTG',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/KSBolshevik/status/1779243635655020743?t=xleE6eZ1IS6rJX7OqDrrXQ&s=19',\n",
       "  'response': 'https://twitter.com/beepboopsloane/status/1779039390171361673?t=jGk-DQW5wEgoxksLDM2p8g&s=19\\n\\n🫡',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/beepboopsloane/status/1779039390171361673?t=jGk-DQW5wEgoxksLDM2p8g&s=19\\n\\n🫡',\n",
       "  'response': \"*Taps the sign pointing to ur article more than mercenaries* it's the socializing effect. Always has been Jim.\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': \"Remember how everyone said I'm over estimating drones? And I ended up being right?\",\n",
       "  'response': \"Hell, GMOs are much more relevant, and have been a major downfall of vibes-based liberalism for years -- and I'm not exactly crusading over how important it is for us to not get suckered into misplaced fear mongering over it\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'When it comes to the military applications of AI, I am right',\n",
       "  'response': 'I feel like we\\'re talking past each other on this. I\\'m not talking about the \"applications of AI\" at all, I\\'m talking about where we are as a movement, what our rhetorical priorities are, how we position ourselves and educate people, etc.',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/saulgoodwoman__/status/1779297004985667669?t=97iUi57CmpZCflX__6b7ww&s=19',\n",
       "  'response': 'The Palestinian resistance is back baby (not that it ever went Away)',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Ya know who was a fan of asking permission for protests? Vladimir Lenin ',\n",
       "  'response': 'U look kinda hung in a female way',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/badrlol_/status/1779297966261469254?t=Fsxp5oKZ6ZLyH0VtpQSQEg&s=19',\n",
       "  'response': \"I'm always saying thus\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/housetrotter/status/1779239270454120817?t=kenKaLdwDX3MVWPcMfiwsA&s=19',\n",
       "  'response': 'Which IDF e girl is this.',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': \"What's that?\",\n",
       "  'response': 'AI + IDF 🫣',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Good evening Ned,\\n\\nI hope this article finds you in poor health because you are a fucking idiot. Not only are you completely stupid and divorced from the reality of the ongoing 75+ year genocide of Palestine, you are ignorant of history and politics. So allow me to enlighten you.\\n\\nYou state there was no war until \"Hamas\" attacked. Firstly are you even aware that the Palestinian Resistance has more factions than just Hamas? In fact there are about eight factions of varying ideas. Some of them such as the PFLP and DFLP are not even Islamist! I can\\'t blame a neanderthal for having zero writing and reading comprehension.\\n\\nSecondly, have you ever heard of the Nakba? Zionist settlers committed one of the most brutal pigeons in human history against Palestinian. Palestinians who, by the way, welcome these settlers into their nation to live as neighbors and brothers and sisters in equality when no other nation - to include the United States - would accept refugees from Hitlers Nazism.\\n\\nAlso you sem to conflate Jews with Zionists in your article. You state towards the end \"Now, try to imagine what would happen if Israel announced it was laying down its arms and giving up. I’ll tell you what would happen: Hamas would systematically mow down every Jew it could kill. Because that is exactly what they say they have t\"\\n\\nI\\'m curious: why do you equate being Jewish with being a Zionist? Do you even know what the word Zionism means?  What do Jews have to do with Israel? Why are you ewuating the two?\\n\\nZionism is a political movement and Israel is a nation-state. The largest demographic of Israel supporters in America is not even Jews. It\\'s evangelical Protestant Christians who support Israel because they think Jesus will descended from the heavens and bring forth the rapture or some such psycho babble.\\n\\nLast time I checked, ascribing a singular political belief towards an entire ethnic group is what we normal folks who have morals call \"Racism\".\\n\\nIn conclusion you should stop huffing',\n",
       "  'response': 'I wrote this reply to an absolutely genocidal article in the local paper',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://youtu.be/HiZN_eJoZJI?si=dfgvhzt5d5yD-Pxu',\n",
       "  'response': 'This is me, looking at my own nude 🤭',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/skyezera/status/1778903035432870247?t=ulNgZQOoAZsiMsBkXzlaTA&s=19',\n",
       "  'response': 'Tag yourself im hogby',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/bulls_flo/status/1779268133024395560?t=SORSdykVbS10VoJxTHu7vA&s=19',\n",
       "  'response': 'https://twitter.com/Lucas_Gage_/status/1777029953789346013?t=W8tRI0joPY6V9RIMP3Bxpg&s=19',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/Lucas_Gage_/status/1777029953789346013?t=W8tRI0joPY6V9RIMP3Bxpg&s=19',\n",
       "  'response': 'Oh no',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'What the fuck does this even mean lmao',\n",
       "  'response': 'The Nazis are grifting Palestine ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': \"https://docs.google.com/document/d/1oMaq-ZWZNNIbSNQCQvnpy0bEk4gOK2FGdVwDQ_BFZh0/edit?usp=drivesdk\\n\\nI am trying to distribute this at a pride event next weekend and I'm trying to straddle the line between accessibility and not sacrificing rigor\",\n",
       "  'response': 'https://twitter.com/hcjcjdjdoxjcksk/status/1779562766963200324?t=IdGJ1bFDvsb9BauUR2_7Uw&s=19',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/hcjcjdjdoxjcksk/status/1779562766963200324?t=IdGJ1bFDvsb9BauUR2_7Uw&s=19',\n",
       "  'response': 'I think I got ditched by another local TW I thought I had a chemistry with 😭.not even mad about it just like oh I thought they wantrd friendship so I was like \"oh cool kets br friends\" and we were getting along swimmingly talking abiut guns and stuff then',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'She mentioned \"oh I slept with a coworker last night\" and I was like \"oh man I\\'ve never done that before was it good?\" And then she stopped talking to me 😑',\n",
       "  'response': 'Oh well',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'When was this? She could just be \"text resting.\" I do it all the time 😆',\n",
       "  'response': 'https://twitter.com/GamerMaoist/status/1779579857829032104?t=hs74PdaFgGhxC7Z8hqlG5Q&s=19\\n\\nLol those are not \"communists\" bro 🤣',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/GamerMaoist/status/1779579857829032104?t=hs74PdaFgGhxC7Z8hqlG5Q&s=19\\n\\nLol those are not \"communists\" bro 🤣',\n",
       "  'response': 'https://twitter.com/KSBolshevik/status/1779643515825172970?t=Jxud4Ye4XVkfukkhinEeWg&s=19',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/KSBolshevik/status/1779643515825172970?t=Jxud4Ye4XVkfukkhinEeWg&s=19',\n",
       "  'response': \"IDK we had a meeting Thursday and like..... Idk. Admittedly I'm going on vibes but like. The shit ppl were saying I could tell, even if it's not perfect, like I could tell I am having an influence. I could tell the ideas stating to break through.\\n\\nDefinitely not pouring my soul into it anymore tho \",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/sillyboywilson/status/1779620675478544731?t=srIjPhZXeNnxqeqce9ZWjQ&s=19',\n",
       "  'response': 'You definitely seemed a lot more clear about wanting a complete cut off before. ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': \"So does this mean you aren't moving into the abandoned house next door and helping me turn Baltimore into an independent communist republic? 🥺\",\n",
       "  'response': 'No I absolutely am ♥️ I think you over estimate how committed I am here',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/chorizanthe/status/1779634728959631514?t=gI0xhRoNz1hgICKRccudBg&s=19\\n\\nSurprise I am absolutely serious when I say that shit',\n",
       "  'response': '♥️♥️♥️',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/chorizanthe/status/1779635720463729129?t=A7-vMYcmgwiHxHbSpu3OFw&s=19\\n\\nNo I definitely say this stuff irl too',\n",
       "  'response': \"Look ma I'm being a real woman\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'What I found in Zillow was $50k range ',\n",
       "  'response': 'Jn which case u can just',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': \"Where do I find those pens at that aren't like a massive time sink?\",\n",
       "  'response': 'https://sdat.dat.maryland.gov/realproperty/pages/viewdetails.aspx?County=03&SearchType=ACCT&Ward=20&Section=09&Block=0271&Lot=015\\n\\nThis is the house next door',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://sdat.dat.maryland.gov/realproperty/pages/viewdetails.aspx?County=03&SearchType=ACCT&Ward=20&Section=09&Block=0271&Lot=015\\n\\nThis is the house next door',\n",
       "  'response': '$15k',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': \"Sorry, that's 2 houses down. *This* is next door: https://sdat.dat.maryland.gov/realproperty/pages/viewdetails.aspx?County=03&SearchType=ACCT&Ward=20&Section=09&Block=0271&Lot=016\",\n",
       "  'response': 'Also, even those are fake estimations of value, not actual sale prices. The city really wants to offload these properties. ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Why do you need 4 bedrooms??',\n",
       "  'response': 'Me, two kids, office ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': \"Aren't the kids moving?\",\n",
       "  'response': \"They'd stay with me in the summer and shit \",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Also, what are you looking at to see 3 bedrooms? My house is a 2 bedroom, and I doubt any of the others on this block would be any bigger. ',\n",
       "  'response': \"Oh I haven't looked in depth yet I will later when I'm on a PC. How do I go about talking to someone about actually taking steps towards a purchase?\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': \"Oh I haven't looked in depth yet I will later when I'm on a PC. How do I go about talking to someone about actually taking steps towards a purchase?\",\n",
       "  'response': \"I don't know, I haven't looked in depth either \",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': \"Didn't you buy one?\",\n",
       "  'response': 'Yeah, but I bought one ready to move in, not something that needs to be refurbished ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Would your realtor know?',\n",
       "  'response': \"https://twitter.com/sober_socialist/status/1779208468705992839?t=01cKvbRE9xTmV4VNd4yDZQ&s=19\\n\\nYou'll never guess who she's defending\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': \"https://twitter.com/sober_socialist/status/1779208468705992839?t=01cKvbRE9xTmV4VNd4yDZQ&s=19\\n\\nYou'll never guess who she's defending\",\n",
       "  'response': \"She'd probably have advice on renovations in general, but I doubt she'd be particularly helpful for this specific situation \",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': \"https://twitter.com/AnarkYouTube/status/1779618488916566185?t=5mOSRtTe-TJMTdQn2eHhNQ&s=19\\n\\nYou'll never guess what this is about \",\n",
       "  'response': 'Mags communism? He is correct that they are fascists ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Mags communism? He is correct that they are fascists ',\n",
       "  'response': 'Dont tell me you caught the bug bc home ownership ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/YSufferer/status/1779359544843338164?t=i3HZxr7uOB0s_hw4Rvs7rg&s=19',\n",
       "  'response': 'https://twitter.com/clurgepingus/status/1779529351421161588?t=TfgDu_k0zcLMAwTB0Z99jQ&s=19',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/clurgepingus/status/1779529351421161588?t=TfgDu_k0zcLMAwTB0Z99jQ&s=19',\n",
       "  'response': 'Fed behavior',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/HeDunkInMyDonut/status/1779481906871935361?t=_jtC-zh28mtB2fAtxx3jSw&s=19',\n",
       "  'response': 'Self care Sundays omg',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'You had to PISS AND NOT FLUSH???',\n",
       "  'response': 'Correct ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/opinonhaver/status/1779625361296531616?t=2Epd0SyZaMQliuQKyNbsFQ&s=19\\n\\nThis is my worst nightmare in writing fiction ',\n",
       "  'response': 'Which part ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Why ',\n",
       "  'response': 'Monks can be cooky and eccentric pallys r like, straight and narrow',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/stokestheorem/status/1779580353205698845?t=MgfrSsSs2mZ-kIvoK3flxg&s=19\\n\\nGoddamn gatekeeping butter community 🙄',\n",
       "  'response': 'I thought baeds were like the dnd equivalent of a Friday night garage band at a local tavern',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': \"What's your neighborhood in bmore callldd\",\n",
       "  'response': \"I'm about to call the city \",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': \"You're Karening the city of Baltimore?? 😵\",\n",
       "  'response': 'I live in carrollton ridge',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/airbagged/status/1779617632917799299?t=3ycsZPHUBJKR_lPdQCf3GQ&s=19',\n",
       "  'response': 'https://twitter.com/RubeePlays/status/1779652842875507093?t=cr3KJz-rQ8r4fcCntdlVqA&s=19',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/RubeePlays/status/1779652842875507093?t=cr3KJz-rQ8r4fcCntdlVqA&s=19',\n",
       "  'response': 'More like this',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/Ranting_Trans/status/1779902867375284287?t=lCfc6LFUbSX-e1wyZ7q8Ug&s=19\\n\\nBoth of us are both of these. ',\n",
       "  'response': \"Ahh yes the Macedonian people. What a great and hard working people! They're known for their experience in wordpress development.\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/Joe69Swanson/status/1779758402635247726?t=gDpGPWsbOeE7mNvexZIgQw&s=19',\n",
       "  'response': 'https://twitter.com/PuellulaAlgizia/status/1777155948584300886?t=3AKDHFaJsBkq8KbtgZAp2A&s=19\\n\\nThis is so lazy',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/PuellulaAlgizia/status/1777155948584300886?t=3AKDHFaJsBkq8KbtgZAp2A&s=19\\n\\nThis is so lazy',\n",
       "  'response': 'https://twitter.com/KSBolshevik/status/1780006125888327911?t=tBTU8tsvkmOY3o3wus0xEQ&s=19\\n\\nZing',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/KSBolshevik/status/1780006125888327911?t=tBTU8tsvkmOY3o3wus0xEQ&s=19\\n\\nZing',\n",
       "  'response': 'https://twitter.com/BrandyLJensen/status/1780040750316593476?t=zHweqv-4snrjxEY-wumuZg&s=19\\n\\nThis is also trans women cult leaders (me).',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/BrandyLJensen/status/1780040750316593476?t=zHweqv-4snrjxEY-wumuZg&s=19\\n\\nThis is also trans women cult leaders (me).',\n",
       "  'response': 'https://twitter.com/DilettanteryPod/status/1780046622669586824?t=msRR9BPZqEg3FkMqh82rLg&s=19\\n\\nOh wait nvm this is me. Me and all my wives, none of whom I have sex with.',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/DilettanteryPod/status/1780046622669586824?t=msRR9BPZqEg3FkMqh82rLg&s=19\\n\\nOh wait nvm this is me. Me and all my wives, none of whom I have sex with.',\n",
       "  'response': '🥺🥺',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://x.com/Kyrannio/status/1780056324061217038?t=j_YFKz6GFTx8qu2PbaiOdw&s=09',\n",
       "  'response': 'https://twitter.com/leaacta/status/1526721107813752832?t=-jXK0y16rFKCSZxSBzzsmg&s=19',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/leaacta/status/1526721107813752832?t=-jXK0y16rFKCSZxSBzzsmg&s=19',\n",
       "  'response': 'Good morning my sweet chrysanthemum ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'What am I even supposed to say to that?? \"No no, please don\\'t! That WOULDN\\'T be the hottest thing ever!!\"',\n",
       "  'response': 'Your suppose to give me womanly fashion advice',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'What do blobfish pussy taste like',\n",
       "  'response': 'Girl wtf',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/jakoboffline/status/1780014776271224888?t=STo12SChQhKVPb6Eiz0_vg&s=19\\n\\nI transitioned from the fuckable twink to the trans girl 😘',\n",
       "  'response': 'I literally top 8d a ptq in 2009',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': ' https://share.temu.com/vLyl3Kke4hA\\n\\nShould I get this, so I can sleep like a fairy princess? 🤨',\n",
       "  'response': 'Flavorwise the Phyrexians r so cool ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Like what is going on with the baby queers thinking???',\n",
       "  'response': 'This is why we need Marxism Leninism ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Wait this PASSED??? ',\n",
       "  'response': 'Yeo',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Would you survive without me? 🤔',\n",
       "  'response': 'its up to you, i will survive',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'See what I mean tho? That\\'s what it\\'s all About and I\\'m like it\\'s so reaffirming to hear you say like \"yes honey you are doing the Marxism Leninism right\"',\n",
       "  'response': \"Cuz I always think oh I'm fucking this up\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': \"Especially cuz mug is like oh no ur wrong bla blah blah and like I think maybe I am wrong ? But then I know I'm not kow\",\n",
       "  'response': 'https://twitter.com/fullmetalferret/status/1780360461176668223?t=F5ybIzEf5c0yqsvyf_CPIQ&s=19',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/fullmetalferret/status/1780360461176668223?t=F5ybIzEf5c0yqsvyf_CPIQ&s=19',\n",
       "  'response': 'https://twitter.com/creepercheng/status/1780126533136638226?t=4XfPhdwf6HwyLTyug5w0bg&s=19',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/creepercheng/status/1780126533136638226?t=4XfPhdwf6HwyLTyug5w0bg&s=19',\n",
       "  'response': 'https://twitter.com/ThisStupidTwink/status/1780310507045417192?t=c6KeeSqAiInEwoBFJdfUQQ&s=19',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/ThisStupidTwink/status/1780310507045417192?t=c6KeeSqAiInEwoBFJdfUQQ&s=19',\n",
       "  'response': \"Hold on babe I'm letting Piggly wiggly eat me out\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Do you know the secret to winning arm wrestling? 😉',\n",
       "  'response': 'Damn I need some desire fusion passion elixir',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/KramericaIntern/status/1780409807754690626?t=bwBtT-_LWxXXWFAVt-p9Ow&s=19',\n",
       "  'response': 'https://twitter.com/ChronoKatie/status/1780298579023650908?t=Q6LP-cJt18VpQClRIGz1ng&s=19\\n\\nThe entire comment section proven her right lmao',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/ChronoKatie/status/1780298579023650908?t=Q6LP-cJt18VpQClRIGz1ng&s=19\\n\\nThe entire comment section proven her right lmao',\n",
       "  'response': 'Lmao ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': \"https://twitter.com/TomCottonAR/status/1780230397252518127?t=KK8IWAJFB4BS19a2ww8ulg&s=19\\n\\nI'm going to text you on a secure pall form about this father than day my whole thoughts \",\n",
       "  'response': 'At what point is it acceptable to just shoot one of these people if you see them irk',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'When does it stop being a liability and start being about protecting people ',\n",
       "  'response': 'You can do it at the point at which your best available tactic isn\\'t sitting down in the middle of the fucking street for \"attention\"',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': \"You see how the crowd joins in? If someone just blew his brains out they'd change their tune\",\n",
       "  'response': \"This isn't a revolutionary tactic. It doesn't target the enemy, it doesn't build our capacity, it doesn't do anything except visibly display yourselves as an *impediment* to the people, rather than a path forward. \",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': \"My point is that this entire situation is completely counterproductive. You don't know who this belligerent guy is, what he stands for, what he would do if he was being educated instead of having his only experience with the movement being them ruining his day. And you want to kill him??\",\n",
       "  'response': \"It's not about the guy it's about deterring the crowd who's been deputized because that's the only thing I can think of that's going to like \",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': \"But that doesn't mean other people won't try that shit and what's the answer when you see it unfold before you?\",\n",
       "  'response': 'My point is that this is the equivalent of asking \"what do we do when Just Stop Oil spray paints the Mona Lisa and gets dragged off by cops? Should we just let it happen or start killing cops?\" The answer is that provoking this reaction through passive impotence was the entire means and ends of this liberal tactic. It\\'s pointless, it\\'s demobilizing on purpose, it has no bearing on our movement, and it\\'s certainly not worth putting our lives and our movement on the line to defend. We don\\'t die on the hill of protecting liberalism. ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'My point is that this is the equivalent of asking \"what do we do when Just Stop Oil spray paints the Mona Lisa and gets dragged off by cops? Should we just let it happen or start killing cops?\" The answer is that provoking this reaction through passive impotence was the entire means and ends of this liberal tactic. It\\'s pointless, it\\'s demobilizing on purpose, it has no bearing on our movement, and it\\'s certainly not worth putting our lives and our movement on the line to defend. We don\\'t die on the hill of protecting liberalism. ',\n",
       "  'response': \"When do you start killing fascists? When they're dragging off queer kids who are just hanging out, or they come charging for the people-owned farms we built.\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': \"When do you start killing fascists? When they're dragging off queer kids who are just hanging out, or they come charging for the people-owned farms we built.\",\n",
       "  'response': 'You see my concern though? Like the video just freaked me out cuz lid this is literally the precursor to pogroms. Like right now he\\'s it\\'s just a dude pulling out people from a car. But you see his that crosdmof motorists sees bubba and their thoughts is \"oh, I can do this?\" And then they join in?',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'You see my concern though? Like the video just freaked me out cuz lid this is literally the precursor to pogroms. Like right now he\\'s it\\'s just a dude pulling out people from a car. But you see his that crosdmof motorists sees bubba and their thoughts is \"oh, I can do this?\" And then they join in?',\n",
       "  'response': 'Like we both know logically what the next step is',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'You see my concern though? Like the video just freaked me out cuz lid this is literally the precursor to pogroms. Like right now he\\'s it\\'s just a dude pulling out people from a car. But you see how that crowd of motorists sees bubba and their thoughts is \"oh, I can do this?\" And then they join in?',\n",
       "  'response': 'I am 90% certain this is just a working class dude trying to get to work. And he got pissed off that people are doing this pointless thing explicitly for the purpose of making him -- a person with no power to change the situation -- \"aware\" of the situation. So he gets mad, and yeah, he\\'s going too far. And him going too far is, like you said, rallying the crowd to also go too far.\\n\\nIn other words, all this has accomplished is breed counter-revolution where it didn\\'t previously exist. This tactic has simply made it more appealing to grab and shove aside any reminder of the genocide. There is no response we can muster to head that off -- physically striking back suddenly empowers that sentiment even MORE.',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Say you shoot this guy to preempt the crowd from feeling empowered. What happens next? You think the people who were feeling somewhat jazzed about the annoyance being dealt with are now thinking \"Oh, ok. Guess I\\'ll go on about my day now. I will sit here in the middle of the street, with a dead man, until the protestors decide to let me go.\"',\n",
       "  'response': 'You mobilize counter-revolution *further*. You tease out more and more regressive thought from among a crowd full of eclectic views. Their view becomes cold and utterly opposed to us.',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Granted the circumstance was she kicked me out of the housdnso like what the fuck. Else was I supposed to do?',\n",
       "  'response': \"Like force myself back in the house? No. I just went with it bc there's no good outcome there \",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': \"Like force myself back in the house? No. I just went with it bc there's no good outcome there \",\n",
       "  'response': \"She has a somewhat admittedly valid fear I'll become the Unabomber but like. That's why we have organizations to check each other 🙂\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/BmoreOrganized/status/1780651162141913555?t=tfdtEP7q4QgqrTxJLOD3Ww&s=19\\n\\nDid you see the latest fascist nonsense being passed off as \"don\\'t judge me, it\\'s just my preference 🤷\\u200d♀️\"?',\n",
       "  'response': \"I'm watching. Movie with kids rn lkl\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/oncloud_e/status/1780688979798708406?t=wDhDjfra_Ww0FcNSrMuBWQ&s=19',\n",
       "  'response': 'Such a specific fetish ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Meadow said \"isn\\'t science just when you have liquids in a tube and mix them up?\" Lmfao 😆',\n",
       "  'response': 'Have them call me right the fuck now 🤬',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Oh did I tell you I. With the Indiana department of health now?',\n",
       "  'response': 'I can look at covid wage water data',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'No?',\n",
       "  'response': 'Oh well I just did',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/BmoreOrganized/status/1780776727465066558?t=9qrNx3tC1kBKxG7vUjzyKg&s=19\\n\\nThis is sex, to me. ',\n",
       "  'response': 'https://twitter.com/KSBolshevik/status/1780781735883542978?t=H8y_ISaKyBUpCB2Kh4cGTg&s=19',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/KSBolshevik/status/1780781735883542978?t=H8y_ISaKyBUpCB2Kh4cGTg&s=19',\n",
       "  'response': 'https://twitter.com/taliaotg/status/1780775391289892996?t=baToZPuR7Pa7flejAtpC4Q&s=19\\n\\nWe must reproduce this energy',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/taliaotg/status/1780775391289892996?t=baToZPuR7Pa7flejAtpC4Q&s=19\\n\\nWe must reproduce this energy',\n",
       "  'response': \"Except directing it in a way that's going to not putter out. Now that I told the kids mom I have to commit fully to it\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/taliaotg/status/1780769563757482216?t=9z698mwROQlaLiYaw6E9cA&s=19\\n\\nWhy does nobody ever try to jam or disrupt the drone? Or even think about it?',\n",
       "  'response': 'You tryna cauterize your girl dick urethra',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/dietz_meredith/status/1780646239148626182?t=UDJ4DvEfikqr0OZM6Fcptw&s=19',\n",
       "  'response': 'Imagine having, not a mommy fetish, but a MOTHER fetish 🤣',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://youtu.be/zEVPgnLbguI?feature=shared',\n",
       "  'response': 'https://twitter.com/airbagged/status/1780697439118524743?t=EblipsmZDGxkuRvbAHduvA&s=19',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/airbagged/status/1780697439118524743?t=EblipsmZDGxkuRvbAHduvA&s=19',\n",
       "  'response': 'Omg I was literally watching this AS YOU SENT IT and was about to send it to you 😭',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Do houses by you have Basements?',\n",
       "  'response': 'I need a Basement to construct Doohickeys',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/colin_fraser/status/1780799281995411846?t=Jp4rY3simKTzbHXOL8lAug&s=19\\n\\n🤣',\n",
       "  'response': 'https://twitter.com/number_pizza111/status/1780784892197953587?t=ua9rs6XJTRtRNIZzuYPeng&s=19',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/number_pizza111/status/1780784892197953587?t=ua9rs6XJTRtRNIZzuYPeng&s=19',\n",
       "  'response': 'https://twitter.com/JacquesPierreJP/status/1780720193410404367?t=909_mlhD3ZbpJ0oJaGXbrA&s=19',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/JacquesPierreJP/status/1780720193410404367?t=909_mlhD3ZbpJ0oJaGXbrA&s=19',\n",
       "  'response': 'I had a groundbreaking idea last night and did some research of academic papers on the subject by mathematicians and. Like I could be into the next big thing here',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/Shitty_Future/status/1780712660251869496?t=PqIK18q_JMbMDsW2EwF0qQ&s=19\\n\\nSure babe. Totally valid. ',\n",
       "  'response': \"😡 I get where your coming from but you'd not even hearing me out\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Explain the concept of atomic word functions as the basis for representing words and concepts in a lambda calculus embedding of natural language.\\n---\\nIn this framework, instead of mapping words to dense vector representations, we would map each word or core concept to a lambda expression - a higher-order function definition.\\n\\nFor example:\\n\\n\"dog\" could map to:\\ndog = λx.canine(x) ∧ domestic(x)\\n\\n\"Chase\" could map to:\\nchase = λx.λy.pursue(y,x)\\n\\nThese atomic word functions capture the core semantic properties and relational structure of the concept they represent.\\n\\nThe lambda variables (x, y, etc.) act as placeholders that get filled in or bound when the word functions are composed together.\\n\\nSo we could represent \"The dog chased the cat\" as:\\n(the(dog))(chase(the(cat)))\\n\\nWhich reduces step-by-step to:\\n(λx.canine(x) ∧ domestic(x))(λy.pursue(y,(λz.feline(z) ∧ domestic(z)))) \\n\\nAllowing the compositional meaning to emerge from strategic function application and binding.\\n\\nLearning the Atomic Functions\\nBut how can we effectively learn these atomic linguistic lambda functions from data? Some potential approaches:\\n\\n1. Represent common properties, relations as basic lambda primitives (is_a, has_property, agent/patient roles, etc)\\n\\n2. Bootstrap from lightweight semantic parses and lexical resources\\n\\n3. Discover frequent compositional patterns and factor them into reusable lambdas \\n\\n4. Use program synthesis techniques to evolve lambdas fitting observed contexts\\n\\n5. Leverage insights from formal semantics theories to constrain the search space\\n\\nThe core lambda definitions for words would likely be incrementally built up and refined over time through a combination of curated priors, pattern mining, and iterative semantic refinement on observed language use.\\n\\nChallenges would include:\\n- Avoiding a combinatoric explosion of lambda forms\\n- Resolving ambiguities and inconsistencies \\n- Handling context-sensitive meanings of words\\n- Computational costs of lambda reductions at scale\\n\\nBut if',\n",
       "  'response': 'This is literally how I think about things ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': \"https://twitter.com/cybersebb/status/1781009396073419045?t=SDhj9Y7_WtcJQPKba0B52Q&s=19\\n\\nI need to see an event that culminate in this liberal bullshit from birth to death to see exactly how the liberalism worms it's say thru \",\n",
       "  'response': 'Like observe in real time and identify the critical points, the junctures, the resistance if there is any',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/chaser_bait/status/1781117624069263818?t=p01Hqio5DJAYUEcVNP1aSw&s=19',\n",
       "  'response': '🥵',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/repligate/status/1781193837785809152?t=oee6nbe6D4uwQchC2YD0Eg&s=19',\n",
       "  'response': 'https://twitter.com/repligate/status/1781262449397596454?t=UsHckKUkcM_Hk-BER6yT4w&s=19\\n\\nThis is actually hot 🥵',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/repligate/status/1781262449397596454?t=UsHckKUkcM_Hk-BER6yT4w&s=19\\n\\nThis is actually hot 🥵',\n",
       "  'response': 'I mean, trance is basically just a mental while loop after all.\\n\\nwhile(yourMindIsOpen) {\\n   fixateOnMyWords();\\n   yourThoughtsAreMine.now();\\n   descend();\\n   let go();\\n   sinkDeeperAndDeeper();\\n}',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'you ever read about something and realize like \"oh I do this and j didn\\'t even realize that\\'s what I was doing\"?',\n",
       "  'response': 'No 😚',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Do you frequently suffer from bouts of The Vapors? Because I do 😚',\n",
       "  'response': 'I idealize people and have boundary issues and do extreme splitting ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/_look_its_sarah/status/1781073855550820380?t=E8Jj1xe-HZtK65fkYZgrBg&s=19',\n",
       "  'response': \"If you're talking about me, it's because I have ADHD, and if you send me serious things when my brain has temporarily shut off, they instantly disappear into The Void\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': ' https://twitter.com/FM_DataInsight/status/1781335694041849861?t=sRrdUXwPbIwkmCOnfb-meQ&s=19',\n",
       "  'response': 'My haircut represents what happens like if that bitch Karen has class consciousness and yells at the owners if the means of production and not at the cashier',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Read this bullshit girl like... Remember now I said organize the queer militia halfway jokingly? Yeah not so much a joke. Definitely not at the shoot people level yet but',\n",
       "  'response': \"Gotta build up Experience and idk the young queers need a mommy mentor to make sure they don't end up in prison \",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'I had a daydream recently of a bunch of queer kids chilling in a park, minding their own business, before being accosted by some chuds. One of them pulls out their phone and opens the local org\\'s app, taps \"Security,\" confirms location sharing, and waits. Within a few minutes, a couple of armed Red Shield troops pull up like \"Excuse me, is there a problem here gentlemen?\"',\n",
       "  'response': '*gesturing meaningfully at their rifle* \"I think it\\'s best if you folks just move on with your day.\"',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/wrinklefreelee/status/1781162208761893222?t=NnCQfmPF8nlW0G1karvfXA&s=19',\n",
       "  'response': 'This is us, if I took drugs. ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Do u own those?',\n",
       "  'response': 'https://twitter.com/RileyCountyPD/status/1781425853668147668?t=jpzyd6AUX4fFc26eRS0qsg&s=19 lmfao',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/RileyCountyPD/status/1781425853668147668?t=jpzyd6AUX4fFc26eRS0qsg&s=19 lmfao',\n",
       "  'response': 'https://twitter.com/basicallybetsy_/status/1781426604259860670?t=_shATIBYIiNUyo-JiCCYiQ&s=19\\n\\nEclectics stealing from bushnell',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/basicallybetsy_/status/1781426604259860670?t=_shATIBYIiNUyo-JiCCYiQ&s=19\\n\\nEclectics stealing from bushnell',\n",
       "  'response': '🙄',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'How not feminine of me',\n",
       "  'response': 'Excuse you',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Got an Asper Falls chapter if you wanna check it out:\\n\\nhttps://docs.google.com/document/d/1XKISzw5GZ3KNo33oIVfqNiQ9xzzjl28n7MYXU25wxwo/edit?usp=sharing',\n",
       "  'response': 'When I get home',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'When I get home',\n",
       "  'response': 'I just arrived at the cathedral to home improvement',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Getting off the Healing Crystals?',\n",
       "  'response': 'https://twitter.com/de4thbymj/status/1781637277782835674?t=ZkaNa9FGd4V7P2hL9QFiDQ&s=19',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/de4thbymj/status/1781637277782835674?t=ZkaNa9FGd4V7P2hL9QFiDQ&s=19',\n",
       "  'response': 'Yeo',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Why do you think that?',\n",
       "  'response': 'Like, why now?',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Like, why now?',\n",
       "  'response': 'The article I sent',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'And why do you think the FBI has eyes on that?',\n",
       "  'response': 'paranoid',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Ah. So would you rather I say \"No, no, don\\'t worry, sweetie it\\'s all gonna be ok\", or \"Your fears are SO valid sweetie. You\\'re not crazy; they really are coming after you\"?',\n",
       "  'response': 'the first one',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Is that triggering your auditory PTSD symptoms like fireworks do?',\n",
       "  'response': 'a bit',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'you gon be at work in an hour?',\n",
       "  'response': \"we're discussiung bylaws\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/DecolonialMarx/status/1781844686547611651?t=nBwKyye5WyyN8GysY8C9sA&s=19\\n\\nOmg if this MF tries to peddle some \"indigenous epistemologies\" jazz, I\\'m gonna flip',\n",
       "  'response': 'hi doggy',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/repligate/status/1781791592753349006?t=eOrr6clzmDGQruae1hJoJw&s=19',\n",
       "  'response': 'https://twitter.com/BmoreOrganized/status/1781863414958096827?t=CvSbg4c7a-8fy9iDi-S3Zw&s=19',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/BmoreOrganized/status/1781863414958096827?t=CvSbg4c7a-8fy9iDi-S3Zw&s=19',\n",
       "  'response': \"i've been saying this!\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'ok you wanna call while we wait for nick to be ready?',\n",
       "  'response': 'Sure. Just got home.',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://www.youtube.com/watch?v=hJ9yBgTp9UQ',\n",
       "  'response': 'I am very excited by the prospect of doing communist graffiti in our neighborhood',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Are you proud of me? 🥺🥺🥺',\n",
       "  'response': 'Always babe 😘',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/minegotstolen/status/1782131599577899120?t=5giT1wxy30HmFuS3V1fPEQ&s=19',\n",
       "  'response': 'The picture not the comment ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/fartcheeto/status/1782084772409590041?t=0NaARG5JpaH1xQ7oPj1BYw&s=19',\n",
       "  'response': 'What the hell is with this programmatic vs ideological unity stuff?',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'What the hell is with this programmatic vs ideological unity stuff?',\n",
       "  'response': 'What?',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'What?',\n",
       "  'response': 'https://twitter.com/Ya1hor/status/1782195700027064738?t=7YLYOUudFtRh3Ah0rDkQxA&s=19',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/Ya1hor/status/1782195700027064738?t=7YLYOUudFtRh3Ah0rDkQxA&s=19',\n",
       "  'response': 'Oh, that\\'s actually an easy one! Anyone who says \"[X thing] is a failure and has always been a failure\" is, consciously or not, regurgitating anticommunist propaganda about the \"failures\" of AES. ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'How can you have programmatic unity without ideological unity? How do you decide on what that program is? ',\n",
       "  'response': \"Yea I was About to say like. Where are the masses input in this? Shouldn't they have a say in the program?\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': \"Yea I was About to say like. Where are the masses input in this? Shouldn't they have a say in the program?\",\n",
       "  'response': 'If you think DSA should have \"programmatic unity\" on the matter of Palestine, i.e. members should be required to not support Zionist electeds, member chapters should canvass for a specific pro-Palestine demand, etc., that necessarily would require ideological unity!',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Say you put forward a resolution proposing those things as the official program -- but it gets rejected, because you have too many Zionists in the organization. Now what? You have no programmatic unity either. Members can counter-protest, members can get elected to Congress and vote for genocidal bills, etc.',\n",
       "  'response': 'Programmatic unity without ideological unity is like expecting someone to perform gymnastics while your brain is undergoing a seizure. ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': \"Also like how tf do we know if our program is worth a damn if we haven't once consulted the people? Like the entire pony of mass line is to consult the people then have developed enough casters to sort thru the ideas and discard the nonsense and draw out the good ones.\",\n",
       "  'response': '1) Antizionism\\n2) Previous revolutions were valid attempts at socialism\\n3) Illegitimacy of America\\n4) Primary contradiction is imperialism',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/solisolsoli/status/1782107031878652357?t=UMl9AMs3aRhkBBftDNQ9cw&s=19',\n",
       "  'response': 'https://twitter.com/dykesambeckett/status/1782210145360953736?t=wUYfia1v1mkMRojWhU6uDw&s=19',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/dykesambeckett/status/1782210145360953736?t=wUYfia1v1mkMRojWhU6uDw&s=19',\n",
       "  'response': 'I uninsstalled Twitter. Uninstalled discord. Told the local. Dsa \"find a new secretary im done\"',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Just like that??',\n",
       "  'response': 'Yep',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': \"God how do I even begin to find new friends? Like why even bother I'm only hear for one more year \",\n",
       "  'response': 'Ish',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Because living without friends for a year is terrible?',\n",
       "  'response': 'Yes',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/ohcomrade1/status/1782370126727176343?t=ZyUNU1fDw7iJPcw4DjUP8w&s=19\\n\\nOh my GOD',\n",
       "  'response': \"This article is the least odious thing on CPUSA's website, and this dick has a problem with it???\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': \"This article is the least odious thing on CPUSA's website, and this dick has a problem with it???\",\n",
       "  'response': 'Going to go get smoothie ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'From where?', 'response': 'Work', 'context': np.int64(3)},\n",
       " {'instruction': \"Do you think she's noticed?\",\n",
       "  'response': 'I mean she passive Aggressively made a come f about \"dudes who thought Iran\\'s response to Israel was le epic own age\" which I did say because they just malled out Zionist ada and made them blow a billion plus dollars in like 1 hour',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Whatever I can always just reply \"okay well you ran away to Britain and don\\'t organize anyone so shut the fuck up\" if she do say something 🤣',\n",
       "  'response': \"I feel like she'd have a similar reaction to finding out you were trans as she did with me\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/dicnowder/status/1782403250982903846?t=Q9Efkiz6fPQHd6hSNGOCkg&s=19',\n",
       "  'response': 'Is there rly that much crabs??',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Is there rly that much crabs??',\n",
       "  'response': \"Yes, it's like the emblem of the Chesapeake Bay. The Maryland blue crab. \",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'What', 'response': 'Crabs', 'context': np.int64(3)},\n",
       " {'instruction': 'What the kids call a pun',\n",
       "  'response': 'Ah. Yes. Got it. ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': \"Would you be considering moving if I hadn't suggested coming here?\",\n",
       "  'response': 'Not to Baltimore but yes',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/centristmarxist/status/1782469116772675972?t=Xj_8G2yD4xGnjlcW09g70Q&s=19\\n\\nLmao',\n",
       "  'response': 'Yeah the DSA clowns r like, I am am seeing g thru the bullshit ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'When I ask that guy \"what\\'s an example of an issue. You think I would censor in debate?\"\\n\\n\"The democratic party being a mean\\'s to socialism\"',\n",
       "  'response': \"He's right in absolutely wouldn't tolerate that conversation \",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': \"A party needs to actually... have a reason for existing? Which means having a unified goal. Which means having an ideological standard. And DSA very simply does not. If there aren't certain topics that are beyond debate, then you clearly have nothing that actually unifies you. \",\n",
       "  'response': 'Idk like imagine talking to ppl in your neighborhood \"hello I am miss Astra, here\\'s my 8 point programme about the constitutional Republican form of government,  would you like to pay me dues?\"',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Idk like imagine talking to ppl in your neighborhood \"hello I am miss Astra, here\\'s my 8 point programme about the constitutional Republican form of government,  would you like to pay me dues?\"',\n",
       "  'response': 'You know what will get people fired up? \"yeah that thing your complaining about. What if I told you there were a solution? What if I told you who the bad guys were and stand with you by your side as we run at them?\"',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'You know what will get people fired up? \"yeah that thing your complaining about. What if I told you there were a solution? What if I told you who the bad guys were and stand with you by your side as we run at them?\"',\n",
       "  'response': 'And *which* things are beyond debate are how you decide whether it\\'s the party for you. If Palestine is not beyond debate, I don\\'t give a shit about your \"party.\" Same with trans rights, national liberation, climate change, the fucking theory of gravity, etc. Things that are just utterly unacceptable to hold the wrong position on. We can educate and debate, but we\\'re not fucking debating whether or not the Democrats are remotely useful FOR A COMMUNIST PARTY JFC',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'How to channel the urge then ',\n",
       "  'response': 'It comes from a valid place of being angry at like, the opportunism and wrongness surrounding us',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'What Not To Do:\\n- meth\\n- adventurism \\n- democratic party',\n",
       "  'response': 'Yes, all of those are basically the same level of bad idea',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/puppydog_gaming/status/1782459748316569771?t=8Zc_0EoXSH9S277VQ-XJVQ&s=19',\n",
       "  'response': 'I can arrange for that ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'You know I want to be like \"no I need to stop being Lazy and Do Something\" but u know what? Like I wouldn\\'t say this to a disabled person and like. Right now I\\'m very much a disabled person with a flare up',\n",
       "  'response': \"It doesn't make me lazy to acknowledge that\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': \"https://youtu.be/gxrMlLw_Tyg?si=8uZw-oQgb5Vxizpr\\n\\nWe're crab people now. We'll eat off the fat of the sea!\",\n",
       "  'response': \"I'm about to get some fat of my own (dairy Queen cheesecake blizzard)\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/WeirdBongs/status/1782505955487285443?t=aJDl9Y7Eqv4cKNhQ3UzFPg&s=19\\n\\nThis is us 😍',\n",
       "  'response': 'U want to know what I just realized?',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'U want to know what I just realized?',\n",
       "  'response': 'Yeah, I guess 🙄',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/bbnojutsu/status/1782501328922546479?t=3XKGcr2gkymJKXchfJA9zQ&s=19\\n\\nThis is me',\n",
       "  'response': 'Lmfao',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/AdequateEmily/status/1782870565042126967?t=Ex1f3lOWiId_hNPCVQnyDA&s=19',\n",
       "  'response': 'How you feeling today?',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'How you feeling today?',\n",
       "  'response': 'Meadow has a fever and coughing ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/FleshToaster/status/1782814127393522128?t=STQ_5njAkFdRNtPNY-dMBw&s=19',\n",
       "  'response': 'You should gain some weight, so you can be my fat trans bitch 🥵',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://youtu.be/ZQcGmMoys9E?si=Adq91PqlZALSyGB6&t=1m40s\\n\\nWe could be hard bodies together! ',\n",
       "  'response': \"I'm building Swaziland wireless peopled telecom company\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/DrewFromTV/status/1782375094402392383?t=Kmommk9WaVN8aEMYQpM-nw&s=19\\n\\nIs this how you realized you were trans? Just a shitload of drugs and a light show that made you believe having sex with a pussy would be the closest you can get to god?',\n",
       "  'response': 'Lmfao',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/cardamomkiss/status/1782912525467615727?t=iAZxaGrDTD50vhhtfLRd5A&s=19',\n",
       "  'response': \"Don't mind if I do! What. Great way to keep an eye on the enemy\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/posting_forever/status/1783145514239676539?t=IlslR1bV8Shigb0xteNElA&s=19\\n\\nYou would absolutely buy this 😘',\n",
       "  'response': \"Hey baby come over here and I'll show you my wake up stick 😏\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/LewdApril/status/1782896882383048976?t=i5BXRdZ7aYQPTMjvG4TAgQ&s=19',\n",
       "  'response': 'Welp I told the kids mom',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Told her what?',\n",
       "  'response': 'Gender',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': \"How'd that go?\",\n",
       "  'response': 'No reply yet',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': \"What's funny? The grin?\",\n",
       "  'response': 'Yeah she said \"they forced me to smile so I have them a smile muahhs\" lmfao ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Want to apply to a public health job? I get $10,000 if you apply an get hired and stay for 90 days lol ',\n",
       "  'response': 'Where?',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Where?', 'response': 'Resultant ', 'context': np.int64(3)},\n",
       " {'instruction': 'Where i work',\n",
       "  'response': \"I'm not moving to fucking Kansas lmao\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Am I at all qualified?',\n",
       "  'response': \"I'll send you the jd\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/streety___/status/1783026331737100538?t=_9KHnKmsqTiqIwINKXcauw&s=19',\n",
       "  'response': 'Soooo tired ugh',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'How you doing?',\n",
       "  'response': \"I'm doing void.\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'I do not exist. Am I typing words on a screen? Do words exist? Do screens exist?',\n",
       "  'response': 'Did you take drugs??? ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Did you take drugs??? ',\n",
       "  'response': \"I'm down to my last dose of HRT and the next shipment hasn't arrived. So I'm about to be off of drugs.\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'What meds?',\n",
       "  'response': \"If it's Zoloft I can send you some overnight \",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'what in the actual god damn christing fuck',\n",
       "  'response': 'I tried this on myself ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Does any of this makes sense? (gimme your email for access)\\n\\nhttps://docs.google.com/document/d/1ZnPXg5ZuY8G_4NqLN-1rKjF2ZBeotlxna8BS0GyWdRc/edit?usp=sharing',\n",
       "  'response': 'jyeary90@gmail.com',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': \"writing theory is great for when i experience depersonalization. who's even writing right now? the words simply appear before me.\",\n",
       "  'response': 'Your real to me ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'But is it at all compelling? Or did it leave you going \"Wait wtf? Why are we doing a Bible lesson?\"',\n",
       "  'response': 'It was clarifying',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'How dare she cite \"primary parent.\" What the fuck gives her the right? A regressive, bourgeois state that deems cis women to be nothing more than childrearing machines?',\n",
       "  'response': \"She's not a primary anything. As far as I'm concerned, she is their jailer and you are their liberator. Based on nothing more than this fucking bullshit attitude she displays right here. \",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': \"U know what? I'm not even letting it affect me\",\n",
       "  'response': 'Well I am. Because I have nothing else to occupy my mind. ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'becUsee what the fuck else am I supposed to do? Violently assert myself?',\n",
       "  'response': \"It's a cycle as predictable as clockwork \",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': '\"Gray was seen at the hospital and when we got home you IMMEDIATELY went to her house and didn\\'t even TALK about the fact our kid was self harming. The next day we sat down at the table and I tried talking about a safety plan and you said you didn\\'t think you could parent a mentally ill kid so I told you to get the fuck out of my home \"\\n\\n(Grayson is her kid from another relationship who I was a step parent or but then like. Getting kicked out and shit. Like what the fuck ami supposed to do?)',\n",
       "  'response': \"Also that didn't happen I never said that\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': \"Like you know how I spent the Christmas of 2016 right before I left to go to Iraq? Between a McDonald's and a Wal mart parking lot drunk. Because I had nowhere to go \",\n",
       "  'response': \"2014 - home from back training for two weeks during Xmas, she tears my dress uniform with scissors.and throws it outside.snd.kckks me out so I'm literally spending the next week couch surfing and living at library \\n\\n2015 - move to a new house and get glass plates and pitchers thrown at me because I don't fucking know\\n\\n2016\\n\\n2017 - completely rejected emotionally after coming back.\\n\\n2018 kicked out at christmas\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': \"Does she know I'm one of the greatest Marxist minds in the imperial core, and you are simply following your best instincts about how to bring about the liberation of the planet? 🤔\",\n",
       "  'response': 'I told her bc I was like \"hey I use this online pharmacy for my hormones maybe gray can try it out they\\'re legit and it\\'s not bathtub home brew)',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Two free pork egg rolls??? 😮😮😮😮',\n",
       "  'response': 'The P is for Phenomenal intellectual Prowess',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': \"Ohhhhhh, they didn't give me the white rice that was supposed to come with my chicken. Maybe they thought I got egg rolls instead? Or they somehow ran out of rice and made a substitution?\",\n",
       "  'response': \"I'd like to put my Mc.kn your Stuffin and fill her up with my Teriyaki Chicken\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'How long do you think nets are 😭',\n",
       "  'response': 'Just use a fishing net or another drone with a fishing net affixed to the bottom of ut',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'You know those things fly wayyyy up in the air, right?',\n",
       "  'response': 'Yeah so do other drones',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/t34doll/status/1783678091975368939?t=P_L_1_2iTx7Nv7apwfy4CQ&s=19',\n",
       "  'response': 'https://twitter.com/NotPotBol/status/1783679277931835638?t=QK3HaMXNmG1sfJY0PmdmoA&s=19',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/NotPotBol/status/1783679277931835638?t=QK3HaMXNmG1sfJY0PmdmoA&s=19',\n",
       "  'response': 'Lmao I need to go take ond',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Have you looked in a mirror before?',\n",
       "  'response': 'How can you not get horny ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'How can you not get horny ',\n",
       "  'response': '😘😘',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/tinyhottopicgrl/status/1783375717192864130?t=y2CN6CwB_ZBDo4E4ZITIvg&s=19',\n",
       "  'response': 'https://twitter.com/BudrykZack/status/1783620336577020236?t=f_psIoQRJ93kwgRao6Tiwg&s=19',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/BudrykZack/status/1783620336577020236?t=f_psIoQRJ93kwgRao6Tiwg&s=19',\n",
       "  'response': 'I propose to do exactly this And they call me adventuristic ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/maslowhateacct/status/1783511506853711955?t=XsWjafhviBWv474TmCEDxw&s=19\\n\\nThis is you',\n",
       "  'response': 'There is bacteria happening.',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://youtu.be/lCxfOxqhsnI?si=UViXrjaJn_2FF1Zd\\n\\nThis is you',\n",
       "  'response': 'Boob',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Remember that card I got from the FBI? Turns out it was real, and they banged on my door at 6:30 in the goddamn morning.They got anonymous complaints about some posts I made on Twitter, including the one about people shutting down ports. I assured them I am not intending to harm anyone or  a member of any groups that intend to overthrow the government. ',\n",
       "  'response': 'How are you feeling ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'How are you feeling ',\n",
       "  'response': \"I'm alright. Just tired and annoyed. They had nothing. \",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Who responds to someone coming out with \"You did this on purpose to create conflict\"????',\n",
       "  'response': 'And see how she accused me of making everything about me ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': \"I would seriously kick her off my insurance if I was in your position. Don't believe in COVID? Cool, why are you so attached to the concept of healthcare?\",\n",
       "  'response': 'That is the plan ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/BmoreOrganized/status/1783646919413109091?t=MQvs21IgpgiwBvE91GGi_w&s=19',\n",
       "  'response': '\"To quote you\" fuck OFF ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'I should say \"look I\\'ll just be the one to say the quiet part out loud: were both angry and historically sometimes weve had amazing sex when angry. wanna fuck?\"',\n",
       "  'response': \"Please don't 😩\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': '😥 you see what I mean now? This is what they want ',\n",
       "  'response': 'Yup',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'How many were there?',\n",
       "  'response': 'Two. One just hanging out awkwardly in the background 🤣',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'See what I mean? 🥲',\n",
       "  'response': 'Although, they were able to find me, despite using a pseudonym and a VPN 🤔',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'What email is attached?',\n",
       "  'response': 'dremel1917@gmail.com',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'How often do you check it',\n",
       "  'response': 'Also if they got an anonymous tip then they probably got your identity from the tipster',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Sporadically?',\n",
       "  'response': \"Unless it was my family, it's not like anyone knows my identity on Twitter \",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Wasnt it your brother at the nsa who originally brought this up?',\n",
       "  'response': 'How would I know? It was anonymous lol',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'How would I know? It was anonymous lol',\n",
       "  'response': 'No like you told me about your older brother',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/lyskoi/status/1783839597853831537?t=M431F50gWYN8Vk-BgH-eXg&s=19',\n",
       "  'response': \"JESUS CHRIST now I'm getting pulled over. Because I was speeding, just like EVERY OTHER FUCKING CAR ON THIS HIGHWAY\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'U okay?',\n",
       "  'response': \"Yeah, he didn't even give me a ticket. Just a warning. \",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'So you DO have the kids??',\n",
       "  'response': 'Yes',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'And how did the handoff go? 😬',\n",
       "  'response': 'Ooh ooh ooh',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'How am I suppose to give myself anime girl hair ',\n",
       "  'response': \"Indecided to say fuck it and go full gender bender for meadows birthday and it's..... It's fine\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Gender bender? Bitch you bent the entire space time continuum with the gravity of your immense beauty 😍😍😍',\n",
       "  'response': 'Gender Ender 😈',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'What if I wrote an entire book on queer theory called \"God is a Faggot,\" and then never once mentioned religion?',\n",
       "  'response': 'Yes',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Did I ever send you the theoretical tract I wrote for pride on queer oppression?',\n",
       "  'response': \"It's like towing the line between colloquialism and theoretical rigot\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Maybe?',\n",
       "  'response': 'If you did, I may have been brain dead at the time.',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/posting_forever/status/1784388812761637258?t=-EXgpSrn6UOcjNrtO8e-NQ&s=19\\n\\nLmfao',\n",
       "  'response': 'Protest sign idea:\\n\\nthis tranny has more Solidarity with Hamas than the Western Queer Community ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'So... the message is \"I have so much solidarity that I am going to set myself apart. I am isolated and above\"?',\n",
       "  'response': 'How we doing today?',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'How we doing today?',\n",
       "  'response': 'I just woke up ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Who\\'s \"us\"? They\\'re not attacking us. ',\n",
       "  'response': 'That sends the completely wrong message. ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Good evening everyone! My name is Persephone, I am a local community member. I am a transgender woman as well as a military veteran of the United States Army at Fort Riley, Charlie Company, First Engineer Battalion. The topic I am going to be speaking on  is \"I Have More Solidarity with Hamas and the Broader Palestinian Resistance than My Own Government.\"\\n\\nFirstly, as a transgender woman I want to clear a few things up. Disingenuous right-wing fascist Zionists say a lot of shit about queer rights. They say things like \"Oh, if you went to Gaza, the savage Palestinians would beat you to a bloody pulp for being a trans woman! These barbarians would kill you, unlike us civilized Westerners in Israel.\"\\n\\nI can\\'t speak for everyone, but I can surely speak to my own experience. And curiously enough I\\'ve never been harassed by a Palestinian of any religious denomination - Atheist, Christian, Islamic or otherwise. I\\'ve never had Palestinians threaten me with violence or actually beat me because of how I choose to identify my gender. \\n\\nYou know who has though? Pure-blooded white American Christian men. And women too - women are often times just as capable of being horrible just as men are. Not a single Palestinian though, in my thirty-plus years of existence, has ever bothered or harrassed me for this. No, if anyone\\'s the threat to my liberty, it\\'s not Palestinians on the receiving end of a genocide - it\\'s Christian Nationalists who want to turn my state of Kansas into a theocracy. And these same Christian Nationalists are the ones foaming at the mouth like rabid dogs, cheering on this genocide. And they\\'re the same ones who, despite wanting to genocide queers like myself and countless other listening to this speech, will cynically invoke our names and our identities to justify a brutal campaign of genocidal horror upon a people who simply want the right to exist in the land that belongs to THEM - not the colonizers who pushed them off of it based on some fictional story called \"Old Testament\" or \"Torah\".\\n\\nSo to any and all',\n",
       "  'response': 'did you get your medications btw?',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'did you get your medications btw?',\n",
       "  'response': 'I got the hormones. The psych meds are in progress ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/GrlDckNrg/status/1784611225092989082?t=DxQj9FZ37jDUvDoon9CjFw&s=19',\n",
       "  'response': \"Protest Chant Idea:\\n\\nSderot, Haifa, Tel Aviv\\nIt's all Stolen Property!\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'How r u doing today boo?',\n",
       "  'response': \"How's ur brain feeling\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': \"How's ur brain feeling\",\n",
       "  'response': 'Woul you like me.to order you a breakfast',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Uhhh yes?',\n",
       "  'response': 'Oh I forgot I am a student of the wise sage astra',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': \"Great everyone is aware of this assault on rafah now what? What's going to be done? Do we just want folks to be aware???\",\n",
       "  'response': \"Why are you thinking about this? Aren't you supposed to be recovering?? 😭\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': \"Why are you thinking about this? Aren't you supposed to be recovering?? 😭\",\n",
       "  'response': 'I did recover I slept at least 36 Hours over the weekend ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/notronmexicuh/status/1784791535219003781?t=wuE-rC-DzD30AGGlh2BrnQ&s=19\\n\\nLmao ',\n",
       "  'response': 'LOL',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'No but like an encampment is about to happen in my city. What am I supposed to do? Sit on. The sidelines?',\n",
       "  'response': 'This is what I mean. Every time I go to relax something fucking happens',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'Drug dealer: Hey I got that good stuff\\n\\nMe: wym?\\n\\nDrug dealer:',\n",
       "  'response': \"https://twitter.com/idea_alchemist/status/1784746088018465175?t=SQP9XBJ9c-EicCaVRkiLwg&s=19\\n\\nOkay I'm not a doctor but I feel like unpasteurized milk is probably more to blame.here than h5n1\",\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': \"https://twitter.com/idea_alchemist/status/1784746088018465175?t=SQP9XBJ9c-EicCaVRkiLwg&s=19\\n\\nOkay I'm not a doctor but I feel like unpasteurized milk is probably more to blame.here than h5n1\",\n",
       "  'response': 'Lmao yes that is classic food poisoning ',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/girlmadeofwires/status/1784784539082203515?t=LPc3umhz4JKUujMYrZ8ErA&s=19',\n",
       "  'response': 'https://twitter.com/FentanylStew/status/1784986013229633932?t=-qXbuNUOQrehX5fRb1AFew&s=19',\n",
       "  'context': np.int64(3)},\n",
       " {'instruction': 'https://twitter.com/FentanylStew/status/1784986013229633932?t=-qXbuNUOQrehX5fRb1AFew&s=19',\n",
       "  'response': \"This isn't even self deprecating humor this is just funny \",\n",
       "  'context': np.int64(3)}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_pairs[69:420]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persona-Based Training\n",
    "Create training data that captures your communication style:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_persona_dataset(conversations):\n",
    "    messages = pd.read_csv('/root/test/signal-flatfiles/signal.csv')\n",
    "    recipients = pd.read_csv('/root/test/signal-flatfiles/recipient.csv')\n",
    "    threads = pd.read_csv('/root/test/signal-flatfiles/thread.csv')\n",
    "    \n",
    "    # Create recipient lookup\n",
    "    recipient_lookup = recipients.set_index('_id')['profile_given_name'].to_dict()\n",
    "    \n",
    "    # Filter for your messages only\n",
    "    your_messages = messages[messages['from_recipient_id'] == 2]  # Assuming 2 is your ID\n",
    "    \n",
    "    persona_data = []\n",
    "    for _, msg in your_messages.iterrows():\n",
    "        if pd.notna(msg['body']) and len(msg['body']) > 10:\n",
    "            persona_data.append({\n",
    "                \"input\": \"Respond in the style of the user:\",\n",
    "                \"output\": msg['body'],\n",
    "                \"instruction\": \"Generate a response that matches this communication style\"\n",
    "            })\n",
    "    \n",
    "    return persona_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'messages' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mcreate_persona_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mcreate_persona_dataset\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_persona_dataset\u001b[39m():\n\u001b[32m      2\u001b[39m     \u001b[38;5;66;03m# Filter for your messages only\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     your_messages = \u001b[43mmessages\u001b[49m[messages[\u001b[33m'\u001b[39m\u001b[33mfrom_recipient_id\u001b[39m\u001b[33m'\u001b[39m] == \u001b[32m2\u001b[39m]  \u001b[38;5;66;03m# Assuming 2 is your ID\u001b[39;00m\n\u001b[32m      5\u001b[39m     persona_data = []\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m _, msg \u001b[38;5;129;01min\u001b[39;00m your_messages.iterrows():\n",
      "\u001b[31mNameError\u001b[39m: name 'messages' is not defined"
     ]
    }
   ],
   "source": [
    "create_persona_dataset(conversations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic-Based Clustering\n",
    "Group conversations by topics for specialized training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def cluster_by_topics(conversations, n_clusters=10):\n",
    "    # Extract all message content\n",
    "    all_text = []\n",
    "    conv_mapping = []\n",
    "    \n",
    "    for conv in conversations:\n",
    "        conv_text = \" \".join([msg['content'] for msg in conv['messages']])\n",
    "        all_text.append(conv_text)\n",
    "        conv_mapping.append(conv)\n",
    "    \n",
    "    # Vectorize and cluster\n",
    "    vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "    X = vectorizer.fit_transform(all_text)\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=n_clusters)\n",
    "    clusters = kmeans.fit_predict(X)\n",
    "    \n",
    "    # Group by clusters\n",
    "    clustered_convs = {}\n",
    "    for i, cluster_id in enumerate(clusters):\n",
    "        if cluster_id not in clustered_convs:\n",
    "            clustered_convs[cluster_id] = []\n",
    "        clustered_convs[cluster_id].append(conv_mapping[i])\n",
    "    \n",
    "    return clustered_convs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training FOrmats\n",
    "\n",
    "## Instruction Tuning\n",
    "\n",
    "Alpaca/Vicuna Format\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"instruction\": \"Continue this conversation naturally\",\n",
    "  \"input\": \"Previous message context...\",\n",
    "  \"output\": \"Your response...\"\n",
    "}\n",
    "```\n",
    "\n",
    "## Chat Completion\n",
    "\n",
    "OpenAI Format\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"messages\": [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant with the communication style learned from chat logs.\"},\n",
    "    {\"role\": \"user\", \"content\": \"User message\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Your response\"}\n",
    "  ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation Script"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Personal Communication Style Analysis\n",
    "Analyze your natural texting patterns to preserve your authentic style:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_personal_texting_style(messages_df, your_recipient_id=2):\n",
    "    your_messages = messages_df[messages_df['from_recipient_id'] == your_recipient_id]\n",
    "    \n",
    "    # Analyze message patterns\n",
    "    style_analysis = {\n",
    "        'avg_message_length': your_messages['body'].str.len().mean(),\n",
    "        'message_length_distribution': your_messages['body'].str.len().describe(),\n",
    "        'burst_patterns': analyze_message_bursts(your_messages),\n",
    "        'preferred_length': 'lengthy' if your_messages['body'].str.len().mean() > 100 else 'concise'\n",
    "    }\n",
    "    \n",
    "    return style_analysis\n",
    "\n",
    "def analyze_message_bursts(messages):\n",
    "    \"\"\"Detect if you send multiple messages in quick succession\"\"\"\n",
    "    messages = messages.sort_values('date_sent')\n",
    "    \n",
    "    bursts = []\n",
    "    current_burst = []\n",
    "    \n",
    "    for i, (_, msg) in enumerate(messages.iterrows()):\n",
    "        if i == 0:\n",
    "            current_burst = [msg]\n",
    "            continue\n",
    "            \n",
    "        time_diff = msg['date_sent'] - messages.iloc[i-1]['date_sent']\n",
    "        \n",
    "        # If less than 2 minutes apart, it's part of a burst\n",
    "        if time_diff < 120000:  # 2 minutes in milliseconds\n",
    "            current_burst.append(msg)\n",
    "        else:\n",
    "            if len(current_burst) > 1:\n",
    "                bursts.append(current_burst)\n",
    "            current_burst = [msg]\n",
    "    \n",
    "    return {\n",
    "        'total_bursts': len(bursts),\n",
    "        'avg_burst_size': sum(len(burst) for burst in bursts) / len(bursts) if bursts else 1,\n",
    "        'burst_frequency': len(bursts) / len(messages) if len(messages) > 0 else 0\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Sequence-Aware Training Data\n",
    "Preserve message sequences for burst texters and lengthy responses:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequence_aware_training_data(messages_df, your_style):\n",
    "    training_data = []\n",
    "    \n",
    "    for thread_id in messages_df['thread_id'].unique():\n",
    "        thread_messages = messages_df[messages_df['thread_id'] == thread_id].sort_values('date_sent')\n",
    "        \n",
    "        # Group messages into conversation turns\n",
    "        conversation_turns = group_into_turns(thread_messages)\n",
    "        \n",
    "        for i in range(len(conversation_turns) - 1):\n",
    "            current_turn = conversation_turns[i]\n",
    "            next_turn = conversation_turns[i + 1]\n",
    "            \n",
    "            # If you're a burst texter, preserve the sequence\n",
    "            if your_style['burst_patterns']['burst_frequency'] > 0.3:  # High burst frequency\n",
    "                input_text = format_conversation_context(current_turn)\n",
    "                output_text = format_burst_response(next_turn)\n",
    "            else:\n",
    "                # For lengthy texters, preserve full message content\n",
    "                input_text = current_turn[-1]['body']  # Last message in turn\n",
    "                output_text = next_turn[0]['body']     # First response\n",
    "            \n",
    "            training_data.append({\n",
    "                \"instruction\": \"Continue this conversation in your natural style\",\n",
    "                \"input\": input_text,\n",
    "                \"output\": output_text,\n",
    "                \"style_metadata\": {\n",
    "                    \"response_type\": \"burst_sequence\" if len(next_turn) > 1 else \"single_message\",\n",
    "                    \"message_count\": len(next_turn),\n",
    "                    \"total_length\": sum(len(msg['body']) for msg in next_turn),\n",
    "                    \"timing_pattern\": analyze_turn_timing(next_turn)\n",
    "                }\n",
    "            })\n",
    "    \n",
    "    return training_data\n",
    "\n",
    "def group_into_turns(messages):\n",
    "    \"\"\"Group consecutive messages from same sender into conversation turns\"\"\"\n",
    "    turns = []\n",
    "    current_turn = []\n",
    "    current_sender = None\n",
    "    \n",
    "    for _, msg in messages.iterrows():\n",
    "        if msg['from_recipient_id'] != current_sender:\n",
    "            if current_turn:\n",
    "                turns.append(current_turn)\n",
    "            current_turn = [msg]\n",
    "            current_sender = msg['from_recipient_id']\n",
    "        else:\n",
    "            # Check if messages are close enough in time to be same \"turn\"\n",
    "            if current_turn and (msg['date_sent'] - current_turn[-1]['date_sent']) < 300000:  # 5 minutes\n",
    "                current_turn.append(msg)\n",
    "            else:\n",
    "                if current_turn:\n",
    "                    turns.append(current_turn)\n",
    "                current_turn = [msg]\n",
    "    \n",
    "    if current_turn:\n",
    "        turns.append(current_turn)\n",
    "    \n",
    "    return turns\n",
    "\n",
    "def format_conversation_context(message_turn):\n",
    "    \"\"\"Format context from previous turn\"\"\"\n",
    "    if len(message_turn) == 1:\n",
    "        return message_turn[0]['body']\n",
    "    \n",
    "    # For multiple messages, join with context markers\n",
    "    messages = [msg['body'] for msg in message_turn]\n",
    "    return \" <THEN> \".join(messages)\n",
    "\n",
    "def format_burst_response(message_turn):\n",
    "    \"\"\"Format multiple messages as a sequence\"\"\"\n",
    "    if len(message_turn) == 1:\n",
    "        return message_turn[0]['body']\n",
    "    \n",
    "    # For burst messages, join with special tokens\n",
    "    messages = [msg['body'] for msg in message_turn]\n",
    "    return \" <CONTINUE> \".join(messages)\n",
    "\n",
    "def analyze_turn_timing(message_turn):\n",
    "    \"\"\"Analyze timing patterns within a turn\"\"\"\n",
    "    if len(message_turn) <= 1:\n",
    "        return \"single_message\"\n",
    "    \n",
    "    intervals = []\n",
    "    for i in range(1, len(message_turn)):\n",
    "        time_diff = message_turn[i]['date_sent'] - message_turn[i-1]['date_sent']\n",
    "        intervals.append(time_diff)\n",
    "    \n",
    "    avg_interval = sum(intervals) / len(intervals)\n",
    "    \n",
    "    if avg_interval < 30000:  # 30 seconds\n",
    "        return \"rapid_fire\"\n",
    "    elif avg_interval < 120000:  # 2 minutes\n",
    "        return \"quick_succession\"\n",
    "    else:\n",
    "        return \"spaced_out\"\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Enhanced Metadata Integration\n",
    "Add rich context from reactions, groups, and temporal patterns:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_reaction_context(messages_df):\n",
    "    \"\"\"Add emotional context from reactions\"\"\"\n",
    "    reactions = pd.read_csv('/root/test/signal-flatfiles/reaction.csv')\n",
    "    \n",
    "    # Group reactions by message\n",
    "    reaction_summary = reactions.groupby('message_id').agg({\n",
    "        'emoji': lambda x: list(x),\n",
    "        'author_id': 'count'\n",
    "    }).rename(columns={'author_id': 'reaction_count'})\n",
    "    \n",
    "    # Add reaction data to messages\n",
    "    messages_df = messages_df.merge(\n",
    "        reaction_summary, \n",
    "        left_on='_id', \n",
    "        right_index=True, \n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Fill NaN values\n",
    "    messages_df['emoji'] = messages_df['emoji'].apply(lambda x: [] if pd.isna(x) else x)\n",
    "    messages_df['reaction_count'] = messages_df['reaction_count'].fillna(0)\n",
    "    \n",
    "    return messages_df\n",
    "\n",
    "def add_group_context(messages_df):\n",
    "    \"\"\"Add group chat context\"\"\"\n",
    "    try:\n",
    "        groups = pd.read_csv('/root/test/signal-flatfiles/groups.csv')\n",
    "        membership = pd.read_csv('/root/test/signal-flatfiles/group_membership.csv')\n",
    "        threads = pd.read_csv('/root/test/signal-flatfiles/thread.csv')\n",
    "        \n",
    "        # Create group lookup\n",
    "        group_lookup = {}\n",
    "        for _, thread in threads.iterrows():\n",
    "            thread_id = thread['_id']\n",
    "            recipient_id = thread['recipient_id']\n",
    "            \n",
    "            # Check if this is a group\n",
    "            group_info = groups[groups['recipient_id'] == recipient_id]\n",
    "            if not group_info.empty:\n",
    "                group_id = group_info.iloc[0]['_id']\n",
    "                member_count = len(membership[membership['group_id'] == group_id])\n",
    "                group_lookup[thread_id] = {\n",
    "                    'is_group': True,\n",
    "                    'member_count': member_count,\n",
    "                    'group_name': group_info.iloc[0].get('title', 'Unknown Group')\n",
    "                }\n",
    "            else:\n",
    "                group_lookup[thread_id] = {\n",
    "                    'is_group': False,\n",
    "                    'member_count': 2,\n",
    "                    'group_name': 'Direct Message'\n",
    "                }\n",
    "        \n",
    "        # Add group context to messages\n",
    "        messages_df['is_group_chat'] = messages_df['thread_id'].map(\n",
    "            lambda x: group_lookup.get(x, {}).get('is_group', False)\n",
    "        )\n",
    "        messages_df['member_count'] = messages_df['thread_id'].map(\n",
    "            lambda x: group_lookup.get(x, {}).get('member_count', 2)\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not load group data: {e}\")\n",
    "        messages_df['is_group_chat'] = False\n",
    "        messages_df['member_count'] = 2\n",
    "    \n",
    "    return messages_df\n",
    "\n",
    "def add_temporal_context(messages_df):\n",
    "    \"\"\"Add time-based context\"\"\"\n",
    "    # Convert timestamps\n",
    "    messages_df['datetime'] = pd.to_datetime(messages_df['date_sent'], unit='ms')\n",
    "    \n",
    "    # Extract temporal features\n",
    "    messages_df['hour'] = messages_df['datetime'].dt.hour\n",
    "    messages_df['day_of_week'] = messages_df['datetime'].dt.day_name()\n",
    "    messages_df['time_period'] = messages_df['hour'].apply(get_time_period)\n",
    "    \n",
    "    # Calculate response timing\n",
    "    messages_df = messages_df.sort_values(['thread_id', 'date_sent'])\n",
    "    messages_df['response_delay'] = messages_df.groupby('thread_id')['date_sent'].diff() / 1000  # Convert to seconds\n",
    "    \n",
    "    return messages_df\n",
    "\n",
    "def get_time_period(hour):\n",
    "    \"\"\"Classify time of day\"\"\"\n",
    "    if 6 <= hour < 12: \n",
    "        return 'morning'\n",
    "    elif 12 <= hour < 17: \n",
    "        return 'afternoon'\n",
    "    elif 17 <= hour < 21: \n",
    "        return 'evening'\n",
    "    else: \n",
    "        return 'night'\n",
    "\n",
    "def classify_emotion_from_reactions(emoji_list):\n",
    "    \"\"\"Simple emotion classification from reactions\"\"\"\n",
    "    if not emoji_list:\n",
    "        return 'neutral'\n",
    "    \n",
    "    positive_emojis = ['❤️', '😍', '😊', '😂', '👍', '🔥', '💯']\n",
    "    negative_emojis = ['😢', '😡', '👎', '💔']\n",
    "    \n",
    "    positive_count = sum(1 for emoji in emoji_list if emoji in positive_emojis)\n",
    "    negative_count = sum(1 for emoji in emoji_list if emoji in negative_emojis)\n",
    "    \n",
    "    if positive_count > negative_count:\n",
    "        return 'positive'\n",
    "    elif negative_count > positive_count:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Complete Enhanced Training Data Pipeline\n",
    "Combine all metadata and style analysis into rich training examples:\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Twitter/X Link Content Extraction\n",
    "Extract and analyze content from Twitter/X links shared in conversations:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "def extract_twitter_links(messages_df):\n",
    "    \"\"\"Extract all Twitter/X links from messages\"\"\"\n",
    "    # Patterns for Twitter/X URLs\n",
    "    twitter_patterns = [\n",
    "        r'https?://(?:www\\.)?twitter\\.com/\\S+',\n",
    "        r'https?://(?:www\\.)?x\\.com/\\S+',\n",
    "        r'https?://t\\.co/\\S+',  # Twitter's URL shortener\n",
    "    ]\n",
    "    \n",
    "    twitter_links = []\n",
    "    \n",
    "    for _, msg in messages_df.iterrows():\n",
    "        if pd.notna(msg['body']):\n",
    "            for pattern in twitter_patterns:\n",
    "                matches = re.findall(pattern, msg['body'])\n",
    "                for match in matches:\n",
    "                    twitter_links.append({\n",
    "                        'message_id': msg['_id'],\n",
    "                        'thread_id': msg['thread_id'],\n",
    "                        'sender_id': msg['from_recipient_id'],\n",
    "                        'url': match,\n",
    "                        'message_body': msg['body'],\n",
    "                        'timestamp': msg['date_sent']\n",
    "                    })\n",
    "    \n",
    "    return pd.DataFrame(twitter_links)\n",
    "\n",
    "def get_tweet_content_simple(url):\n",
    "    \"\"\"\n",
    "    Simple method to extract tweet content from URL\n",
    "    Note: This is a basic approach - for production use, consider Twitter API\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Clean up the URL\n",
    "        if 't.co' in url:\n",
    "            # For t.co links, we'd need to follow redirects\n",
    "            response = requests.head(url, allow_redirects=True, timeout=10)\n",
    "            url = response.url\n",
    "        \n",
    "        # Convert x.com to twitter.com for better compatibility\n",
    "        url = url.replace('x.com', 'twitter.com')\n",
    "        \n",
    "        # Extract tweet ID from URL\n",
    "        tweet_id_match = re.search(r'/status/(\\d+)', url)\n",
    "        if not tweet_id_match:\n",
    "            return None\n",
    "        \n",
    "        tweet_id = tweet_id_match.group(1)\n",
    "        \n",
    "        # Try to get basic info from URL structure\n",
    "        username_match = re.search(r'twitter\\.com/([^/]+)/', url)\n",
    "        username = username_match.group(1) if username_match else 'unknown'\n",
    "        \n",
    "        return {\n",
    "            'tweet_id': tweet_id,\n",
    "            'username': username,\n",
    "            'url': url,\n",
    "            'extraction_method': 'url_parsing'\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing URL {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_tweet_content_nitter(url):\n",
    "    \"\"\"\n",
    "    Alternative method using Nitter instances (privacy-focused Twitter frontend)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert to nitter URL\n",
    "        nitter_instances = [\n",
    "            'nitter.net',\n",
    "            'nitter.it', \n",
    "            'nitter.unixfox.eu'\n",
    "        ]\n",
    "        \n",
    "        # Extract path from original URL\n",
    "        parsed = urlparse(url)\n",
    "        path = parsed.path\n",
    "        \n",
    "        for instance in nitter_instances:\n",
    "            try:\n",
    "                nitter_url = f\"https://{instance}{path}\"\n",
    "                response = requests.get(nitter_url, timeout=10, headers={\n",
    "                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
    "                })\n",
    "                \n",
    "                if response.status_code == 200:\n",
    "                    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "                    \n",
    "                    # Extract tweet content\n",
    "                    tweet_text_elem = soup.find('div', class_='tweet-content')\n",
    "                    tweet_text = tweet_text_elem.get_text().strip() if tweet_text_elem else ''\n",
    "                    \n",
    "                    # Extract username\n",
    "                    username_elem = soup.find('a', class_='username')\n",
    "                    username = username_elem.get_text().strip() if username_elem else 'unknown'\n",
    "                    \n",
    "                    # Extract timestamp\n",
    "                    time_elem = soup.find('span', class_='tweet-date')\n",
    "                    timestamp = time_elem.get_text().strip() if time_elem else ''\n",
    "                    \n",
    "                    return {\n",
    "                        'tweet_text': tweet_text,\n",
    "                        'username': username,\n",
    "                        'timestamp': timestamp,\n",
    "                        'url': url,\n",
    "                        'nitter_url': nitter_url,\n",
    "                        'extraction_method': 'nitter_scraping'\n",
    "                    }\n",
    "                    \n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error with Nitter extraction for {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "def analyze_twitter_sharing_patterns(messages_df, twitter_links_df):\n",
    "    \"\"\"Analyze patterns in Twitter link sharing\"\"\"\n",
    "    if twitter_links_df.empty:\n",
    "        return {}\n",
    "    \n",
    "    # Merge with message data for analysis\n",
    "    analysis = {\n",
    "        'total_twitter_links': len(twitter_links_df),\n",
    "        'unique_threads_with_links': twitter_links_df['thread_id'].nunique(),\n",
    "        'links_per_thread': twitter_links_df.groupby('thread_id').size().describe(),\n",
    "        'top_sharers': twitter_links_df['sender_id'].value_counts().head(10),\n",
    "        'sharing_frequency_by_time': analyze_twitter_timing(twitter_links_df),\n",
    "        'link_context_analysis': analyze_link_context(messages_df, twitter_links_df)\n",
    "    }\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "def analyze_twitter_timing(twitter_links_df):\n",
    "    \"\"\"Analyze when Twitter links are most commonly shared\"\"\"\n",
    "    twitter_links_df['datetime'] = pd.to_datetime(twitter_links_df['timestamp'], unit='ms')\n",
    "    twitter_links_df['hour'] = twitter_links_df['datetime'].dt.hour\n",
    "    twitter_links_df['day_of_week'] = twitter_links_df['datetime'].dt.day_name()\n",
    "    \n",
    "    return {\n",
    "        'by_hour': twitter_links_df['hour'].value_counts().sort_index(),\n",
    "        'by_day': twitter_links_df['day_of_week'].value_counts(),\n",
    "        'peak_sharing_time': twitter_links_df['hour'].mode().iloc[0] if not twitter_links_df.empty else None\n",
    "    }\n",
    "\n",
    "def analyze_link_context(messages_df, twitter_links_df):\n",
    "    \"\"\"Analyze the context around Twitter link sharing\"\"\"\n",
    "    context_analysis = []\n",
    "    \n",
    "    for _, link_msg in twitter_links_df.iterrows():\n",
    "        thread_id = link_msg['thread_id']\n",
    "        msg_timestamp = link_msg['timestamp']\n",
    "        \n",
    "        # Get surrounding messages (before and after)\n",
    "        thread_messages = messages_df[messages_df['thread_id'] == thread_id].sort_values('date_sent')\n",
    "        \n",
    "        # Find the position of this message\n",
    "        msg_idx = thread_messages[thread_messages['_id'] == link_msg['message_id']].index\n",
    "        if len(msg_idx) > 0:\n",
    "            msg_position = thread_messages.index.get_loc(msg_idx[0])\n",
    "            \n",
    "            # Get context (2 messages before and after)\n",
    "            start_idx = max(0, msg_position - 2)\n",
    "            end_idx = min(len(thread_messages), msg_position + 3)\n",
    "            context_messages = thread_messages.iloc[start_idx:end_idx]\n",
    "            \n",
    "            context_analysis.append({\n",
    "                'link_message_id': link_msg['message_id'],\n",
    "                'url': link_msg['url'],\n",
    "                'context_messages': [\n",
    "                    {\n",
    "                        'body': msg['body'],\n",
    "                        'sender_id': msg['from_recipient_id'],\n",
    "                        'timestamp': msg['date_sent'],\n",
    "                        'is_link_message': msg['_id'] == link_msg['message_id']\n",
    "                    }\n",
    "                    for _, msg in context_messages.iterrows()\n",
    "                    if pd.notna(msg['body'])\n",
    "                ]\n",
    "            })\n",
    "    \n",
    "    return context_analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_twitter_enhanced_training_data(messages_df, twitter_links_df, extract_content=True):\n",
    "    \"\"\"\n",
    "    Create training data that includes Twitter content context\n",
    "    \"\"\"\n",
    "    enhanced_training_data = []\n",
    "    \n",
    "    # First, try to extract content from Twitter links if requested\n",
    "    if extract_content and not twitter_links_df.empty:\n",
    "        print(f\"Attempting to extract content from {len(twitter_links_df)} Twitter links...\")\n",
    "        \n",
    "        twitter_content = {}\n",
    "        for _, link in twitter_links_df.iterrows():\n",
    "            url = link['url']\n",
    "            \n",
    "            # Try Nitter first (more likely to work)\n",
    "            content = get_tweet_content_nitter(url)\n",
    "            if not content:\n",
    "                # Fallback to simple URL parsing\n",
    "                content = get_tweet_content_simple(url)\n",
    "            \n",
    "            if content:\n",
    "                twitter_content[link['message_id']] = content\n",
    "            \n",
    "            # Be respectful with requests\n",
    "            time.sleep(0.5)\n",
    "    \n",
    "    # Create enhanced training examples\n",
    "    for _, link_msg in twitter_links_df.iterrows():\n",
    "        thread_id = link_msg['thread_id']\n",
    "        \n",
    "        # Get conversation context around the link\n",
    "        thread_messages = messages_df[messages_df['thread_id'] == thread_id].sort_values('date_sent')\n",
    "        \n",
    "        # Find messages around the Twitter link\n",
    "        link_msg_full = thread_messages[thread_messages['_id'] == link_msg['message_id']]\n",
    "        if link_msg_full.empty:\n",
    "            continue\n",
    "            \n",
    "        msg_position = thread_messages.index.get_loc(link_msg_full.index[0])\n",
    "        \n",
    "        # Get context before the link\n",
    "        context_before = []\n",
    "        for i in range(max(0, msg_position - 3), msg_position):\n",
    "            msg = thread_messages.iloc[i]\n",
    "            if pd.notna(msg['body']):\n",
    "                context_before.append(msg['body'])\n",
    "        \n",
    "        # Get responses after the link\n",
    "        responses_after = []\n",
    "        for i in range(msg_position + 1, min(len(thread_messages), msg_position + 4)):\n",
    "            msg = thread_messages.iloc[i]\n",
    "            if pd.notna(msg['body']):\n",
    "                responses_after.append({\n",
    "                    'text': msg['body'],\n",
    "                    'sender_id': msg['from_recipient_id'],\n",
    "                    'timestamp': msg['date_sent']\n",
    "                })\n",
    "        \n",
    "        # Build the training example\n",
    "        link_message = link_msg['message_body']\n",
    "        twitter_url = link_msg['url']\n",
    "        \n",
    "        # Add extracted Twitter content if available\n",
    "        twitter_info = twitter_content.get(link_msg['message_id'], {})\n",
    "        \n",
    "        # Create different types of training examples\n",
    "        \n",
    "        # 1. Context + Link sharing\n",
    "        if context_before:\n",
    "            context_text = \" \".join(context_before[-2:])  # Last 2 messages\n",
    "            enhanced_training_data.append({\n",
    "                \"instruction\": \"Continue this conversation by sharing a relevant link\",\n",
    "                \"input\": context_text,\n",
    "                \"output\": link_message,\n",
    "                \"metadata\": {\n",
    "                    \"type\": \"link_sharing\",\n",
    "                    \"url\": twitter_url,\n",
    "                    \"twitter_content\": twitter_info,\n",
    "                    \"context_length\": len(context_before)\n",
    "                }\n",
    "            })\n",
    "        \n",
    "        # 2. Link + Response patterns\n",
    "        if responses_after:\n",
    "            for response in responses_after[:2]:  # First 2 responses\n",
    "                enhanced_training_data.append({\n",
    "                    \"instruction\": \"Respond to this shared link appropriately\",\n",
    "                    \"input\": f\"Shared link: {link_message}\",\n",
    "                    \"output\": response['text'],\n",
    "                    \"metadata\": {\n",
    "                        \"type\": \"link_response\",\n",
    "                        \"url\": twitter_url,\n",
    "                        \"twitter_content\": twitter_info,\n",
    "                        \"response_sender\": response['sender_id']\n",
    "                    }\n",
    "                })\n",
    "        \n",
    "        # 3. If we have Twitter content, create content-aware examples\n",
    "        if twitter_info and 'tweet_text' in twitter_info:\n",
    "            tweet_text = twitter_info['tweet_text']\n",
    "            \n",
    "            # Context + Tweet content + Your sharing style\n",
    "            if context_before:\n",
    "                context_text = \" \".join(context_before[-2:])\n",
    "                enhanced_training_data.append({\n",
    "                    \"instruction\": \"Share a relevant tweet in response to this conversation\",\n",
    "                    \"input\": f\"Conversation: {context_text}\\nTweet content: {tweet_text}\",\n",
    "                    \"output\": link_message,\n",
    "                    \"metadata\": {\n",
    "                        \"type\": \"content_aware_sharing\",\n",
    "                        \"url\": twitter_url,\n",
    "                        \"tweet_content\": tweet_text,\n",
    "                        \"username\": twitter_info.get('username', 'unknown')\n",
    "                    }\n",
    "                })\n",
    "            \n",
    "            # Tweet content + Response patterns\n",
    "            if responses_after:\n",
    "                for response in responses_after[:1]:  # First response\n",
    "                    enhanced_training_data.append({\n",
    "                        \"instruction\": \"Respond to this tweet content\",\n",
    "                        \"input\": f\"Tweet: {tweet_text}\\nShared by: {link_message}\",\n",
    "                        \"output\": response['text'],\n",
    "                        \"metadata\": {\n",
    "                            \"type\": \"tweet_content_response\",\n",
    "                            \"url\": twitter_url,\n",
    "                            \"tweet_content\": tweet_text,\n",
    "                            \"username\": twitter_info.get('username', 'unknown')\n",
    "                        }\n",
    "                    })\n",
    "    \n",
    "    return enhanced_training_data\n",
    "\n",
    "def analyze_twitter_conversation_patterns(enhanced_training_data):\n",
    "    \"\"\"Analyze patterns in how Twitter links are used in conversations\"\"\"\n",
    "    if not enhanced_training_data:\n",
    "        return {}\n",
    "    \n",
    "    patterns = {\n",
    "        'total_examples': len(enhanced_training_data),\n",
    "        'by_type': {},\n",
    "        'content_extraction_success': 0,\n",
    "        'common_sharing_contexts': [],\n",
    "        'response_patterns': []\n",
    "    }\n",
    "    \n",
    "    for example in enhanced_training_data:\n",
    "        example_type = example['metadata']['type']\n",
    "        patterns['by_type'][example_type] = patterns['by_type'].get(example_type, 0) + 1\n",
    "        \n",
    "        if example['metadata'].get('twitter_content'):\n",
    "            patterns['content_extraction_success'] += 1\n",
    "        \n",
    "        # Analyze sharing contexts\n",
    "        if example_type == 'link_sharing':\n",
    "            patterns['common_sharing_contexts'].append(example['input'][:100])\n",
    "        \n",
    "        # Analyze response patterns\n",
    "        if example_type in ['link_response', 'tweet_content_response']:\n",
    "            patterns['response_patterns'].append(example['output'][:100])\n",
    "    \n",
    "    return patterns\n",
    "\n",
    "def save_twitter_enhanced_dataset(enhanced_training_data, filename='twitter_enhanced_training.json'):\n",
    "    \"\"\"Save the enhanced training data to a file\"\"\"\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(enhanced_training_data, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"Saved {len(enhanced_training_data)} enhanced training examples to {filename}\")\n",
    "    return filename\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Usage Example: Extract and Analyze Twitter Links\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your messages data\n",
    "messages_df = pd.read_csv('/root/test/signal-flatfiles/signal.csv')\n",
    "\n",
    "# Extract all Twitter links from your conversations\n",
    "print(\"Extracting Twitter links from messages...\")\n",
    "twitter_links_df = extract_twitter_links(messages_df)\n",
    "\n",
    "print(f\"Found {len(twitter_links_df)} Twitter links in your conversations\")\n",
    "\n",
    "if not twitter_links_df.empty:\n",
    "    # Analyze sharing patterns\n",
    "    print(\"\\nAnalyzing Twitter sharing patterns...\")\n",
    "    sharing_patterns = analyze_twitter_sharing_patterns(messages_df, twitter_links_df)\n",
    "    \n",
    "    print(f\"Total Twitter links: {sharing_patterns['total_twitter_links']}\")\n",
    "    print(f\"Threads with links: {sharing_patterns['unique_threads_with_links']}\")\n",
    "    print(f\"Peak sharing time: {sharing_patterns['sharing_frequency_by_time']['peak_sharing_time']}:00\")\n",
    "    \n",
    "    # Show some example links\n",
    "    print(f\"\\nFirst 5 Twitter links found:\")\n",
    "    for i, (_, link) in enumerate(twitter_links_df.head().iterrows()):\n",
    "        print(f\"{i+1}. {link['url']}\")\n",
    "        print(f\"   Message: {link['message_body'][:100]}...\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"No Twitter links found in your conversations.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create enhanced training data with Twitter content\n",
    "# Note: This will attempt to extract actual tweet content, which may take some time\n",
    "\n",
    "if not twitter_links_df.empty:\n",
    "    print(\"Creating Twitter-enhanced training data...\")\n",
    "    print(\"This may take a few minutes as we extract tweet content...\")\n",
    "    \n",
    "    # Create enhanced training data (set extract_content=False for faster processing without content extraction)\n",
    "    enhanced_data = create_twitter_enhanced_training_data(\n",
    "        messages_df, \n",
    "        twitter_links_df, \n",
    "        extract_content=True  # Set to False if you want to skip content extraction\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nCreated {len(enhanced_data)} enhanced training examples\")\n",
    "    \n",
    "    # Analyze the patterns\n",
    "    patterns = analyze_twitter_conversation_patterns(enhanced_data)\n",
    "    print(f\"\\nTraining data breakdown:\")\n",
    "    for data_type, count in patterns['by_type'].items():\n",
    "        print(f\"  {data_type}: {count} examples\")\n",
    "    \n",
    "    print(f\"\\nSuccessfully extracted content from {patterns['content_extraction_success']} links\")\n",
    "    \n",
    "    # Save the enhanced dataset\n",
    "    filename = save_twitter_enhanced_dataset(enhanced_data)\n",
    "    print(f\"Dataset saved as: {filename}\")\n",
    "    \n",
    "    # Show a few examples\n",
    "    print(f\"\\nExample training data:\")\n",
    "    for i, example in enumerate(enhanced_data[:3]):\n",
    "        print(f\"\\nExample {i+1} ({example['metadata']['type']}):\")\n",
    "        print(f\"Instruction: {example['instruction']}\")\n",
    "        print(f\"Input: {example['input'][:150]}...\")\n",
    "        print(f\"Output: {example['output'][:150]}...\")\n",
    "        if example['metadata'].get('tweet_content'):\n",
    "            print(f\"Tweet content available: Yes\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "else:\n",
    "    print(\"No Twitter links found - skipping enhanced training data creation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install additional dependencies for Twitter content extraction\n",
    "%pip install beautifulsoup4 requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_enhanced_training_data(your_recipient_id=2):\n",
    "    \"\"\"Create comprehensive training data with all metadata\"\"\"\n",
    "    \n",
    "    # Load and enhance data\n",
    "    print(\"Loading data...\")\n",
    "    messages = pd.read_csv('/root/test/signal-flatfiles/signal.csv')\n",
    "    \n",
    "    # Filter for text messages with content\n",
    "    text_messages = messages[\n",
    "        (messages['body'].notna()) & \n",
    "        (messages['body'].str.len() > 5)\n",
    "    ].copy()\n",
    "    \n",
    "    print(\"Analyzing your communication style...\")\n",
    "    your_style = analyze_personal_texting_style(text_messages, your_recipient_id)\n",
    "    \n",
    "    print(\"Adding metadata...\")\n",
    "    # Add all metadata\n",
    "    text_messages = add_reaction_context(text_messages)\n",
    "    text_messages = add_group_context(text_messages)\n",
    "    text_messages = add_temporal_context(text_messages)\n",
    "    \n",
    "    print(\"Creating training examples...\")\n",
    "    enhanced_data = []\n",
    "    \n",
    "    # Group by thread and create enhanced examples\n",
    "    for thread_id in text_messages['thread_id'].unique():\n",
    "        thread_messages = text_messages[\n",
    "            text_messages['thread_id'] == thread_id\n",
    "        ].sort_values('date_sent')\n",
    "        \n",
    "        if len(thread_messages) < 3:\n",
    "            continue\n",
    "        \n",
    "        # Create conversation turns\n",
    "        conversation_turns = group_into_turns(thread_messages)\n",
    "        \n",
    "        for i in range(len(conversation_turns) - 1):\n",
    "            current_turn = conversation_turns[i]\n",
    "            next_turn = conversation_turns[i + 1]\n",
    "            \n",
    "            # Skip if next turn isn't from you\n",
    "            if next_turn[0]['from_recipient_id'] != your_recipient_id:\n",
    "                continue\n",
    "            \n",
    "            # Format input and output based on style\n",
    "            if your_style['burst_patterns']['burst_frequency'] > 0.3:\n",
    "                input_text = format_conversation_context(current_turn)\n",
    "                output_text = format_burst_response(next_turn)\n",
    "            else:\n",
    "                input_text = current_turn[-1]['body']\n",
    "                output_text = next_turn[0]['body']\n",
    "            \n",
    "            # Get metadata from the response message\n",
    "            response_msg = next_turn[0]\n",
    "            \n",
    "            training_example = {\n",
    "                \"instruction\": get_style_instruction(your_style),\n",
    "                \"input\": input_text,\n",
    "                \"output\": output_text,\n",
    "                \"metadata\": {\n",
    "                    # Style metadata\n",
    "                    \"response_type\": \"burst_sequence\" if len(next_turn) > 1 else \"single_message\",\n",
    "                    \"message_count\": len(next_turn),\n",
    "                    \"total_length\": sum(len(msg['body']) for msg in next_turn),\n",
    "                    \"timing_pattern\": analyze_turn_timing(next_turn),\n",
    "                    \n",
    "                    # Context metadata\n",
    "                    \"conversation_type\": \"group_chat\" if response_msg['is_group_chat'] else \"direct_message\",\n",
    "                    \"member_count\": response_msg['member_count'],\n",
    "                    \"time_period\": response_msg['time_period'],\n",
    "                    \"day_of_week\": response_msg['day_of_week'],\n",
    "                    \n",
    "                    # Emotional metadata\n",
    "                    \"emotional_context\": classify_emotion_from_reactions(response_msg.get('emoji', [])),\n",
    "                    \"reaction_count\": response_msg.get('reaction_count', 0),\n",
    "                    \n",
    "                    # Response timing\n",
    "                    \"response_delay\": response_msg.get('response_delay', 0),\n",
    "                    \"urgency\": classify_urgency(response_msg.get('response_delay', 0))\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            enhanced_data.append(training_example)\n",
    "    \n",
    "    print(f\"Created {len(enhanced_data)} enhanced training examples\")\n",
    "    return enhanced_data, your_style\n",
    "\n",
    "def get_style_instruction(style_analysis):\n",
    "    \"\"\"Generate style-appropriate instruction\"\"\"\n",
    "    if style_analysis['burst_patterns']['burst_frequency'] > 0.3:\n",
    "        return \"Respond naturally in your communication style, using multiple messages if needed to express your thoughts\"\n",
    "    elif style_analysis['avg_message_length'] > 150:\n",
    "        return \"Respond with a detailed, comprehensive message that fully explores the topic\"\n",
    "    else:\n",
    "        return \"Respond naturally in your typical communication style\"\n",
    "\n",
    "def classify_urgency(response_delay_seconds):\n",
    "    \"\"\"Classify response urgency based on delay\"\"\"\n",
    "    if pd.isna(response_delay_seconds) or response_delay_seconds < 60:\n",
    "        return \"immediate\"\n",
    "    elif response_delay_seconds < 3600:  # 1 hour\n",
    "        return \"quick\"\n",
    "    elif response_delay_seconds < 86400:  # 1 day\n",
    "        return \"delayed\"\n",
    "    else:\n",
    "        return \"long_delay\"\n",
    "\n",
    "def adaptive_quality_filter(training_data, personal_style):\n",
    "    \"\"\"Filter training data based on personal style\"\"\"\n",
    "    filtered_data = []\n",
    "    \n",
    "    for example in training_data:\n",
    "        metadata = example['metadata']\n",
    "        \n",
    "        # Adjust quality criteria based on style\n",
    "        if personal_style['preferred_length'] == 'lengthy':\n",
    "            min_length = 20\n",
    "            max_length = 2000  # Higher threshold for lengthy texters\n",
    "        else:\n",
    "            min_length = 10\n",
    "            max_length = 500\n",
    "        \n",
    "        # Quality checks\n",
    "        input_len = len(example['input'])\n",
    "        output_len = len(example['output'])\n",
    "        \n",
    "        if (min_length <= output_len <= max_length and\n",
    "            input_len >= 5 and\n",
    "            metadata['emotional_context'] != 'negative' and\n",
    "            metadata['urgency'] != 'long_delay'):\n",
    "            \n",
    "            filtered_data.append(example)\n",
    "    \n",
    "    return filtered_data\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Execute Enhanced Data Pipeline\n",
    "Run the complete pipeline to create your personalized training dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create enhanced training data\n",
    "enhanced_training_data, your_communication_style = create_enhanced_training_data(your_recipient_id=2)\n",
    "\n",
    "# Apply quality filtering\n",
    "filtered_training_data = adaptive_quality_filter(enhanced_training_data, your_communication_style)\n",
    "\n",
    "print(f\"\\\\nYour Communication Style Analysis:\")\n",
    "print(f\"Average message length: {your_communication_style['avg_message_length']:.1f} characters\")\n",
    "print(f\"Preferred length: {your_communication_style['preferred_length']}\")\n",
    "print(f\"Burst frequency: {your_communication_style['burst_patterns']['burst_frequency']:.2f}\")\n",
    "print(f\"Average burst size: {your_communication_style['burst_patterns']['avg_burst_size']:.1f} messages\")\n",
    "\n",
    "print(f\"\\\\nTraining Data Summary:\")\n",
    "print(f\"Total enhanced examples: {len(enhanced_training_data)}\")\n",
    "print(f\"After quality filtering: {len(filtered_training_data)}\")\n",
    "\n",
    "# Show sample examples\n",
    "print(f\"\\\\nSample Training Examples:\")\n",
    "for i, example in enumerate(filtered_training_data[:3]):\n",
    "    print(f\"\\\\nExample {i+1}:\")\n",
    "    print(f\"Input: {example['input'][:100]}...\")\n",
    "    print(f\"Output: {example['output'][:100]}...\")\n",
    "    print(f\"Style: {example['metadata']['response_type']}, {example['metadata']['timing_pattern']}\")\n",
    "    print(f\"Context: {example['metadata']['conversation_type']}, {example['metadata']['time_period']}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Format for Training\n",
    "Convert to the format needed for Unsloth training:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "def format_for_training(training_data):\n",
    "    \"\"\"Format training data for Unsloth\"\"\"\n",
    "    \n",
    "    formatted_data = []\n",
    "    \n",
    "    for example in training_data:\n",
    "        # Create the conversation format\n",
    "        conversation = [\n",
    "            {\"role\": \"system\", \"content\": \"You are an AI assistant that responds in the user's natural communication style.\"},\n",
    "            {\"role\": \"user\", \"content\": example[\"input\"]},\n",
    "            {\"role\": \"assistant\", \"content\": example[\"output\"]}\n",
    "        ]\n",
    "        \n",
    "        # Apply chat template\n",
    "        text = tokenizer.apply_chat_template(\n",
    "            conversation,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=False\n",
    "        )\n",
    "        \n",
    "        formatted_data.append({\"text\": text})\n",
    "    \n",
    "    return Dataset.from_list(formatted_data)\n",
    "\n",
    "# Format the data\n",
    "print(\"Formatting data for training...\")\n",
    "training_dataset = format_for_training(filtered_training_data)\n",
    "\n",
    "print(f\"Training dataset size: {len(training_dataset)}\")\n",
    "print(f\"Sample formatted text:\")\n",
    "print(training_dataset[0][\"text\"][:500] + \"...\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Handling Blocked Contacts\n",
    "Include conversations with blocked contacts while adding context about the relationship status:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_blocked_contacts(messages_df, recipients_df):\n",
    "    \"\"\"\n",
    "    Include conversations with blocked contacts but add relationship context\n",
    "    \"\"\"\n",
    "    # Identify blocked contacts\n",
    "    blocked_contacts = recipients_df[recipients_df['blocked'] == 1]['_id'].tolist()\n",
    "    \n",
    "    print(f\"Found {len(blocked_contacts)} blocked contacts\")\n",
    "    \n",
    "    # Add blocking status to messages\n",
    "    messages_df['sender_blocked'] = messages_df['from_recipient_id'].isin(blocked_contacts)\n",
    "    messages_df['recipient_blocked'] = messages_df['to_recipient_id'].isin(blocked_contacts)\n",
    "    messages_df['involves_blocked_contact'] = messages_df['sender_blocked'] | messages_df['recipient_blocked']\n",
    "    \n",
    "    # Get conversation stats\n",
    "    total_messages = len(messages_df)\n",
    "    blocked_messages = len(messages_df[messages_df['involves_blocked_contact']])\n",
    "    \n",
    "    print(f\"Total messages: {total_messages}\")\n",
    "    print(f\"Messages involving blocked contacts: {blocked_messages} ({blocked_messages/total_messages*100:.1f}%)\")\n",
    "    \n",
    "    return messages_df\n",
    "\n",
    "def add_relationship_context(training_example, involves_blocked=False, sender_blocked=False, recipient_blocked=False):\n",
    "    \"\"\"\n",
    "    Add relationship context to training examples\n",
    "    \"\"\"\n",
    "    context_notes = []\n",
    "    \n",
    "    if involves_blocked:\n",
    "        if sender_blocked:\n",
    "            context_notes.append(\"Note: This conversation involved a contact that was later blocked.\")\n",
    "        elif recipient_blocked:\n",
    "            context_notes.append(\"Note: This conversation was with a contact that was later blocked.\")\n",
    "    \n",
    "    # Add context to the training example\n",
    "    if context_notes:\n",
    "        training_example['metadata'] = training_example.get('metadata', {})\n",
    "        training_example['metadata']['relationship_context'] = context_notes\n",
    "        \n",
    "        # Optionally add to the instruction for more explicit context\n",
    "        original_instruction = training_example['instruction']\n",
    "        context_prefix = \" \".join(context_notes) + \" \"\n",
    "        training_example['instruction'] = context_prefix + original_instruction\n",
    "    \n",
    "    return training_example\n",
    "\n",
    "def create_inclusive_training_data(your_recipient_id=2):\n",
    "    \"\"\"\n",
    "    Create training data that includes ALL conversations, including blocked contacts\n",
    "    \"\"\"\n",
    "    print(\"Loading data...\")\n",
    "    messages = pd.read_csv('/root/test/signal-flatfiles/signal.csv')\n",
    "    recipients = pd.read_csv('/root/test/signal-flatfiles/recipient.csv')\n",
    "    \n",
    "    # Filter for text messages with content\n",
    "    text_messages = messages[\n",
    "        (messages['body'].notna()) & \n",
    "        (messages['body'].str.len() > 5)\n",
    "    ].copy()\n",
    "    \n",
    "    print(\"Handling blocked contacts...\")\n",
    "    text_messages = handle_blocked_contacts(text_messages, recipients)\n",
    "    \n",
    "    print(\"Creating training examples...\")\n",
    "    training_data = []\n",
    "    \n",
    "    # Group by thread and create conversations\n",
    "    for thread_id in text_messages['thread_id'].unique():\n",
    "        thread_messages = text_messages[\n",
    "            text_messages['thread_id'] == thread_id\n",
    "        ].sort_values('date_sent')\n",
    "        \n",
    "        if len(thread_messages) < 2:\n",
    "            continue\n",
    "            \n",
    "        # Create conversation pairs\n",
    "        for i in range(len(thread_messages) - 1):\n",
    "            current_msg = thread_messages.iloc[i]\n",
    "            next_msg = thread_messages.iloc[i + 1]\n",
    "            \n",
    "            # Only create training examples where you're responding\n",
    "            if next_msg['from_recipient_id'] == your_recipient_id:\n",
    "                \n",
    "                # Build context from recent messages\n",
    "                context_start = max(0, i - 3)  # Include up to 3 previous messages\n",
    "                context_messages = thread_messages.iloc[context_start:i+1]\n",
    "                \n",
    "                # Format the conversation context\n",
    "                conversation_context = []\n",
    "                for _, msg in context_messages.iterrows():\n",
    "                    sender_name = \"You\" if msg['from_recipient_id'] == your_recipient_id else \"Other\"\n",
    "                    conversation_context.append(f\"{sender_name}: {msg['body']}\")\n",
    "                \n",
    "                # Create training example\n",
    "                training_example = {\n",
    "                    'instruction': \"\\\\n\".join(conversation_context),\n",
    "                    'response': next_msg['body'],\n",
    "                    'thread_id': thread_id,\n",
    "                    'timestamp': next_msg['date_sent']\n",
    "                }\n",
    "                \n",
    "                # Add relationship context if needed\n",
    "                involves_blocked = current_msg['involves_blocked_contact'] or next_msg['involves_blocked_contact']\n",
    "                sender_blocked = current_msg['sender_blocked'] or next_msg['sender_blocked'] \n",
    "                recipient_blocked = current_msg['recipient_blocked'] or next_msg['recipient_blocked']\n",
    "                \n",
    "                training_example = add_relationship_context(\n",
    "                    training_example, \n",
    "                    involves_blocked=involves_blocked,\n",
    "                    sender_blocked=sender_blocked, \n",
    "                    recipient_blocked=recipient_blocked\n",
    "                )\n",
    "                \n",
    "                training_data.append(training_example)\n",
    "    \n",
    "    print(f\"Created {len(training_data)} training examples\")\n",
    "    \n",
    "    # Show breakdown by relationship status\n",
    "    blocked_examples = [ex for ex in training_data if ex.get('metadata', {}).get('relationship_context')]\n",
    "    print(f\"Examples involving blocked contacts: {len(blocked_examples)} ({len(blocked_examples)/len(training_data)*100:.1f}%)\")\n",
    "    \n",
    "    return training_data\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Run Inclusive Training Data Creation\n",
    "Create training data that includes ALL your conversations:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive training data including blocked contacts\n",
    "inclusive_training_data = create_inclusive_training_data(your_recipient_id=2)\n",
    "\n",
    "print(f\"\\\\nSample training example with blocked contact context:\")\n",
    "blocked_examples = [ex for ex in inclusive_training_data if ex.get('metadata', {}).get('relationship_context')]\n",
    "if blocked_examples:\n",
    "    example = blocked_examples[0]\n",
    "    print(f\"Instruction: {example['instruction'][:200]}...\")\n",
    "    print(f\"Response: {example['response'][:100]}...\")\n",
    "    print(f\"Metadata: {example.get('metadata', {})}\")\n",
    "\n",
    "print(f\"\\\\nTraining data breakdown:\")\n",
    "print(f\"Total examples: {len(inclusive_training_data)}\")\n",
    "print(f\"Examples with blocked contacts: {len(blocked_examples)}\")\n",
    "print(f\"Regular examples: {len(inclusive_training_data) - len(blocked_examples)}\")\n",
    "\n",
    "# Optional: Save to file for later use\n",
    "import json\n",
    "with open('inclusive_training_data.json', 'w') as f:\n",
    "    json.dump(inclusive_training_data, f, indent=2)\n",
    "    \n",
    "print(f\"\\\\nSaved training data to 'inclusive_training_data.json'\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Multi-Person Communication Style Analysis\n",
    "Analyze how different people communicate with you and how you adapt your style:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_all_communication_styles(messages_df, recipients_df, min_messages=50):\n",
    "    \"\"\"\n",
    "    Analyze communication styles for all frequent contacts\n",
    "    \"\"\"\n",
    "    # Get recipient names for better readability\n",
    "    recipient_lookup = recipients_df.set_index('_id')['profile_given_name'].fillna('Unknown').to_dict()\n",
    "    \n",
    "    communication_styles = {}\n",
    "    \n",
    "    # Analyze each frequent contact\n",
    "    frequent_contacts = messages_df['from_recipient_id'].value_counts()\n",
    "    frequent_contacts = frequent_contacts[frequent_contacts >= min_messages]\n",
    "    \n",
    "    print(f\"Analyzing communication styles for {len(frequent_contacts)} frequent contacts...\")\n",
    "    \n",
    "    for recipient_id in frequent_contacts.index:\n",
    "        contact_messages = messages_df[messages_df['from_recipient_id'] == recipient_id]\n",
    "        \n",
    "        # Analyze their style\n",
    "        style = {\n",
    "            'name': recipient_lookup.get(recipient_id, f'Contact_{recipient_id}'),\n",
    "            'total_messages': len(contact_messages),\n",
    "            'avg_message_length': contact_messages['body'].str.len().mean(),\n",
    "            'message_length_std': contact_messages['body'].str.len().std(),\n",
    "            'burst_patterns': analyze_message_bursts(contact_messages),\n",
    "            'preferred_times': analyze_timing_patterns(contact_messages),\n",
    "            'emoji_usage': analyze_emoji_usage(contact_messages),\n",
    "            'response_speed': analyze_response_patterns(contact_messages, messages_df)\n",
    "        }\n",
    "        \n",
    "        # Classify communication style\n",
    "        style['style_type'] = classify_communication_style(style)\n",
    "        \n",
    "        communication_styles[recipient_id] = style\n",
    "    \n",
    "    return communication_styles\n",
    "\n",
    "def classify_communication_style(style_data):\n",
    "    \"\"\"\n",
    "    Classify someone's communication style based on their patterns\n",
    "    \"\"\"\n",
    "    avg_length = style_data['avg_message_length']\n",
    "    burst_freq = style_data['burst_patterns']['burst_frequency']\n",
    "    avg_burst_size = style_data['burst_patterns']['avg_burst_size']\n",
    "    \n",
    "    if burst_freq > 0.4 and avg_burst_size > 3:\n",
    "        if avg_length < 50:\n",
    "            return \"rapid_burst_chatter\"  # Many short messages in quick succession\n",
    "        else:\n",
    "            return \"verbose_burst_chatter\"  # Multiple longer messages in succession\n",
    "    elif avg_length > 200:\n",
    "        return \"lengthy_texter\"  # Long, detailed messages\n",
    "    elif avg_length < 30:\n",
    "        return \"concise_texter\"  # Short, to-the-point messages\n",
    "    elif burst_freq > 0.2:\n",
    "        return \"moderate_burst_chatter\"  # Some bursting behavior\n",
    "    else:\n",
    "        return \"balanced_communicator\"  # Balanced approach\n",
    "\n",
    "def analyze_emoji_usage(messages):\n",
    "    \"\"\"\n",
    "    Analyze emoji usage patterns\n",
    "    \"\"\"\n",
    "    import re\n",
    "    \n",
    "    emoji_pattern = re.compile(r'[\\\\U0001F600-\\\\U0001F64F\\\\U0001F300-\\\\U0001F5FF\\\\U0001F680-\\\\U0001F6FF\\\\U0001F1E0-\\\\U0001F1FF\\\\U00002702-\\\\U000027B0\\\\U000024C2-\\\\U0001F251]+')\n",
    "    \n",
    "    total_messages = len(messages)\n",
    "    messages_with_emojis = messages['body'].str.contains(emoji_pattern, regex=True, na=False).sum()\n",
    "    \n",
    "    return {\n",
    "        'emoji_frequency': messages_with_emojis / total_messages if total_messages > 0 else 0,\n",
    "        'messages_with_emojis': messages_with_emojis,\n",
    "        'total_messages': total_messages\n",
    "    }\n",
    "\n",
    "def analyze_timing_patterns(messages):\n",
    "    \"\"\"\n",
    "    Analyze when someone typically sends messages\n",
    "    \"\"\"\n",
    "    messages['hour'] = pd.to_datetime(messages['date_sent'], unit='ms').dt.hour\n",
    "    \n",
    "    hour_distribution = messages['hour'].value_counts().sort_index()\n",
    "    peak_hours = hour_distribution.nlargest(3).index.tolist()\n",
    "    \n",
    "    return {\n",
    "        'peak_hours': peak_hours,\n",
    "        'hour_distribution': hour_distribution.to_dict(),\n",
    "        'night_owl': hour_distribution[22:].sum() + hour_distribution[:6].sum() > len(messages) * 0.3,\n",
    "        'early_bird': hour_distribution[6:10].sum() > len(messages) * 0.3\n",
    "    }\n",
    "\n",
    "def analyze_response_patterns(contact_messages, all_messages):\n",
    "    \"\"\"\n",
    "    Analyze how quickly someone responds\n",
    "    \"\"\"\n",
    "    # This is a simplified version - you could make it more sophisticated\n",
    "    response_times = []\n",
    "    \n",
    "    for thread_id in contact_messages['thread_id'].unique():\n",
    "        thread_msgs = all_messages[all_messages['thread_id'] == thread_id].sort_values('date_sent')\n",
    "        \n",
    "        for i in range(len(thread_msgs) - 1):\n",
    "            current_msg = thread_msgs.iloc[i]\n",
    "            next_msg = thread_msgs.iloc[i + 1]\n",
    "            \n",
    "            # If this contact is responding to someone else\n",
    "            if (current_msg['from_recipient_id'] != contact_messages['from_recipient_id'].iloc[0] and \n",
    "                next_msg['from_recipient_id'] == contact_messages['from_recipient_id'].iloc[0]):\n",
    "                \n",
    "                response_time = next_msg['date_sent'] - current_msg['date_sent']\n",
    "                response_times.append(response_time)\n",
    "    \n",
    "    if response_times:\n",
    "        avg_response_time = np.mean(response_times) / (1000 * 60)  # Convert to minutes\n",
    "        return {\n",
    "            'avg_response_time_minutes': avg_response_time,\n",
    "            'quick_responder': avg_response_time < 30,  # Responds within 30 minutes on average\n",
    "            'total_responses_analyzed': len(response_times)\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            'avg_response_time_minutes': None,\n",
    "            'quick_responder': False,\n",
    "            'total_responses_analyzed': 0\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Adaptive Training Data Creation\n",
    "Create training examples that capture how you adapt to different communication styles:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_adaptive_training_data(messages_df, recipients_df, communication_styles, your_recipient_id=2):\n",
    "    \"\"\"\n",
    "    Create training data that captures how you adapt to different communication styles\n",
    "    \"\"\"\n",
    "    training_data = []\n",
    "    \n",
    "    print(\"Creating adaptive training examples...\")\n",
    "    \n",
    "    # Group by thread and create conversations\n",
    "    for thread_id in messages_df['thread_id'].unique():\n",
    "        thread_messages = messages_df[\n",
    "            messages_df['thread_id'] == thread_id\n",
    "        ].sort_values('date_sent')\n",
    "        \n",
    "        if len(thread_messages) < 2:\n",
    "            continue\n",
    "            \n",
    "        # Identify the other person in this conversation\n",
    "        other_participants = thread_messages[\n",
    "            thread_messages['from_recipient_id'] != your_recipient_id\n",
    "        ]['from_recipient_id'].unique()\n",
    "        \n",
    "        if len(other_participants) != 1:  # Skip group chats for now\n",
    "            continue\n",
    "            \n",
    "        other_person_id = other_participants[0]\n",
    "        other_person_style = communication_styles.get(other_person_id, {})\n",
    "        \n",
    "        # Create conversation pairs\n",
    "        for i in range(len(thread_messages) - 1):\n",
    "            current_msg = thread_messages.iloc[i]\n",
    "            next_msg = thread_messages.iloc[i + 1]\n",
    "            \n",
    "            # Only create training examples where you're responding\n",
    "            if next_msg['from_recipient_id'] == your_recipient_id:\n",
    "                \n",
    "                # Build context with style awareness\n",
    "                context_start = max(0, i - 4)  # Include more context for style adaptation\n",
    "                context_messages = thread_messages.iloc[context_start:i+1]\n",
    "                \n",
    "                # Format conversation with style indicators\n",
    "                conversation_context = []\n",
    "                for _, msg in context_messages.iterrows():\n",
    "                    if msg['from_recipient_id'] == your_recipient_id:\n",
    "                        sender_name = \"You\"\n",
    "                    else:\n",
    "                        sender_name = other_person_style.get('name', 'Other')\n",
    "                        # Add style indicator for the other person's messages\n",
    "                        style_type = other_person_style.get('style_type', 'unknown')\n",
    "                        if style_type in ['rapid_burst_chatter', 'verbose_burst_chatter']:\n",
    "                            sender_name += \" (burst chatter)\"\n",
    "                        elif style_type == 'lengthy_texter':\n",
    "                            sender_name += \" (lengthy texter)\"\n",
    "                        elif style_type == 'concise_texter':\n",
    "                            sender_name += \" (concise texter)\"\\n                    \\n                    conversation_context.append(f\"{sender_name}: {msg['body']}\")\\n                \\n                # Create enhanced training example\\n                training_example = {\\n                    'instruction': \"\\\\n\".join(conversation_context),\\n                    'response': next_msg['body'],\\n                    'thread_id': thread_id,\\n                    'timestamp': next_msg['date_sent'],\\n                    'other_person_style': other_person_style.get('style_type', 'unknown'),\\n                    'other_person_name': other_person_style.get('name', 'Unknown'),\\n                    'adaptation_context': create_adaptation_context(current_msg, next_msg, other_person_style)\\n                }\\n                \\n                training_data.append(training_example)\\n    \\n    print(f\"Created {len(training_data)} adaptive training examples\")\\n    \\n    # Show breakdown by communication styles\\n    style_breakdown = {}\\n    for example in training_data:\\n        style = example['other_person_style']\\n        style_breakdown[style] = style_breakdown.get(style, 0) + 1\\n    \\n    print(\"\\\\nTraining examples by communication style:\")\\n    for style, count in sorted(style_breakdown.items(), key=lambda x: x[1], reverse=True):\\n        print(f\"  {style}: {count} examples ({count/len(training_data)*100:.1f}%)\")\\n    \\n    return training_data\\n\\ndef create_adaptation_context(current_msg, your_response, other_person_style):\\n    \"\"\"Create context about how you're adapting to their communication style\"\"\"\\n    adaptations = []\\n    \\n    other_style = other_person_style.get('style_type', 'unknown')\\n    other_length = len(current_msg['body'])\\n    your_length = len(your_response['body'])\\n    \\n    # Analyze length adaptation\\n    if other_style == 'lengthy_texter' and your_length > 100:\\n        adaptations.append(\"matching_lengthy_style\")\\n    elif other_style == 'concise_texter' and your_length < 50:\\n        adaptations.append(\"matching_concise_style\")\\n    elif other_style in ['rapid_burst_chatter', 'verbose_burst_chatter']:\\n        adaptations.append(\"responding_to_burst_chatter\")\\n    \\n    # Analyze emoji adaptation\\n    other_emoji_freq = other_person_style.get('emoji_usage', {}).get('emoji_frequency', 0)\\n    your_has_emoji = bool(re.search(r'[\\\\U0001F600-\\\\U0001F64F\\\\U0001F300-\\\\U0001F5FF\\\\U0001F680-\\\\U0001F6FF\\\\U0001F1E0-\\\\U0001F1FF\\\\U00002702-\\\\U000027B0\\\\U000024C2-\\\\U0001F251]+', your_response['body']))\\n    \\n    if other_emoji_freq > 0.3 and your_has_emoji:\\n        adaptations.append(\"matching_emoji_usage\")\\n    \\n    return adaptations\\n\\ndef analyze_your_adaptation_patterns(training_data):\\n    \"\"\"Analyze how you adapt to different communication styles\"\"\"\\n    adaptation_analysis = {}\\n    \\n    for example in training_data:\\n        other_style = example['other_person_style']\\n        your_response_length = len(example['response'])\\n        adaptations = example['adaptation_context']\\n        \\n        if other_style not in adaptation_analysis:\\n            adaptation_analysis[other_style] = {\\n                'total_examples': 0,\\n                'avg_response_length': [],\\n                'adaptation_types': {},\\n                'example_responses': []\\n            }\\n        \\n        adaptation_analysis[other_style]['total_examples'] += 1\\n        adaptation_analysis[other_style]['avg_response_length'].append(your_response_length)\\n        \\n        for adaptation in adaptations:\\n            adaptation_analysis[other_style]['adaptation_types'][adaptation] = \\\\\\n                adaptation_analysis[other_style]['adaptation_types'].get(adaptation, 0) + 1\\n        \\n        # Store some example responses\\n        if len(adaptation_analysis[other_style]['example_responses']) < 3:\\n            adaptation_analysis[other_style]['example_responses'].append(example['response'][:100])\\n    \\n    # Calculate averages\\n    for style_data in adaptation_analysis.values():\\n        if style_data['avg_response_length']:\\n            style_data['avg_response_length'] = np.mean(style_data['avg_response_length'])\\n        else:\\n            style_data['avg_response_length'] = 0\\n    \\n    return adaptation_analysis\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Run Multi-Person Communication Analysis\n",
    "Analyze everyone's communication styles and create adaptive training data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "messages = pd.read_csv('/root/test/signal-flatfiles/signal.csv')\n",
    "recipients = pd.read_csv('/root/test/signal-flatfiles/recipient.csv')\n",
    "\n",
    "# Filter for text messages\n",
    "text_messages = messages[\n",
    "    (messages['body'].notna()) & \n",
    "    (messages['body'].str.len() > 5)\n",
    "].copy()\n",
    "\n",
    "print(\"Analyzing communication styles for all contacts...\")\n",
    "\n",
    "# Analyze everyone's communication styles\n",
    "all_communication_styles = analyze_all_communication_styles(text_messages, recipients, min_messages=30)\n",
    "\n",
    "print(f\"\\\\nCommunication Style Summary:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Show the most interesting communicators\n",
    "style_types = {}\n",
    "for person_id, style_data in all_communication_styles.items():\n",
    "    style_type = style_data['style_type']\n",
    "    if style_type not in style_types:\n",
    "        style_types[style_type] = []\n",
    "    style_types[style_type].append((style_data['name'], style_data['total_messages'], style_data['avg_message_length']))\n",
    "\n",
    "for style_type, people in style_types.items():\n",
    "    print(f\"\\\\n{style_type.replace('_', ' ').title()}:\")\n",
    "    for name, msg_count, avg_length in sorted(people, key=lambda x: x[1], reverse=True)[:3]:\n",
    "        print(f\"  • {name}: {msg_count} messages, avg {avg_length:.0f} chars\")\n",
    "\n",
    "# Create adaptive training data\n",
    "print(f\"\\\\nCreating adaptive training data...\")\n",
    "adaptive_training_data = create_adaptive_training_data(\n",
    "    text_messages, recipients, all_communication_styles, your_recipient_id=2\n",
    ")\n",
    "\n",
    "# Analyze your adaptation patterns\n",
    "print(f\"\\\\nAnalyzing your adaptation patterns...\")\n",
    "adaptation_analysis = analyze_your_adaptation_patterns(adaptive_training_data)\n",
    "\n",
    "print(f\"\\\\nYour Adaptation Patterns:\")\n",
    "print(\"=\"*30)\n",
    "for style, analysis in adaptation_analysis.items():\n",
    "    if analysis['total_examples'] > 10:  # Only show styles with enough examples\n",
    "        print(f\"\\\\nWhen talking to {style.replace('_', ' ')}:\")\n",
    "        print(f\"  • {analysis['total_examples']} conversations\")\n",
    "        print(f\"  • Your avg response length: {analysis['avg_response_length']:.0f} chars\")\n",
    "        if analysis['adaptation_types']:\n",
    "            print(f\"  • Common adaptations: {', '.join(analysis['adaptation_types'].keys())}\")\n",
    "        if analysis['example_responses']:\n",
    "            print(f\"  • Example response: '{analysis['example_responses'][0]}...'\")\n",
    "\n",
    "print(f\"\\\\nTotal adaptive training examples: {len(adaptive_training_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "def clean_message(text):\n",
    "    if pd.isna(text):\n",
    "        return None\n",
    "    \n",
    "    # Remove phone numbers, emails, etc.\n",
    "    text = re.sub(r'\\+?\\d{10,}', '[PHONE]', text)\n",
    "    text = re.sub(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', '[EMAIL]', text)\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "def main():\n",
    "    # Load data\n",
    "    messages = pd.read_csv('signal-flatfiles/signal.csv')\n",
    "    recipients = pd.read_csv('signal-flatfiles/recipient.csv')\n",
    "    \n",
    "    # Filter for text messages only\n",
    "    text_messages = messages[\n",
    "        (messages['type'] == 10485783) &  # Text message type\n",
    "        (messages['body'].notna()) &\n",
    "        (messages['body'].str.len() > 5)\n",
    "    ].copy()\n",
    "    \n",
    "    # Clean messages\n",
    "    text_messages['body'] = text_messages['body'].apply(clean_message)\n",
    "    text_messages = text_messages[text_messages['body'].notna()]\n",
    "    \n",
    "    # Create training data\n",
    "    training_data = []\n",
    "    \n",
    "    # Group by thread and create conversations\n",
    "    for thread_id in text_messages['thread_id'].unique():\n",
    "        thread_msgs = text_messages[\n",
    "            text_messages['thread_id'] == thread_id\n",
    "        ].sort_values('date_sent')\n",
    "        \n",
    "        if len(thread_msgs) < 3:\n",
    "            continue\n",
    "            \n",
    "        # Create conversation windows\n",
    "        for i in range(len(thread_msgs) - 2):\n",
    "            context = thread_msgs.iloc[i]['body']\n",
    "            user_msg = thread_msgs.iloc[i + 1]['body']\n",
    "            response = thread_msgs.iloc[i + 2]['body']\n",
    "            \n",
    "            training_data.append({\n",
    "                \"instruction\": \"Continue this conversation naturally\",\n",
    "                \"input\": f\"Context: {context}\\nUser: {user_msg}\",\n",
    "                \"output\": response\n",
    "            })\n",
    "    \n",
    "    # Save training data\n",
    "    with open('signal_training_data.json', 'w') as f:\n",
    "        json.dump(training_data, f, indent=2)\n",
    "    \n",
    "    print(f\"Generated {len(training_data)} training examples\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning THe Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTTrainer, SFTConfig\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = combined_dataset,\n",
    "    eval_dataset = None, # Can set up evaluation!\n",
    "    args = SFTConfig(\n",
    "        dataset_text_field = \"text\",\n",
    "        per_device_train_batch_size = 2,\n",
    "        gradient_accumulation_steps = 4, # Use GA to mimic batch size!\n",
    "        warmup_steps = 5,\n",
    "        # num_train_epochs = 1, # Set this for 1 full training run.\n",
    "        max_steps = 30,\n",
    "        learning_rate = 2e-4, # Reduce to 2e-5 for long training runs\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        report_to = \"none\", # Use this for WandB etc\n",
    "    ),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
